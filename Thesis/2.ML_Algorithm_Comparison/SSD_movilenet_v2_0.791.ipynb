{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF8ysCfYKgTP"
      },
      "source": [
        "# In-Process Defect Monitoring Using Computer Vision for FDM Using TensorFlow Lite Object Detection API\n",
        "\n",
        "**GitHub:** [TensorFlow Lite Object Detection](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi)\n",
        "\n",
        "#1.&nbsp;Introduction\n",
        "\n",
        "This notebook uses [the TensorFlow 2 Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) to train an SSD-MobileNet model with a Our **FDM anomalies dataset**. By working through this Colab, you'll be able to create and download a TFLite model that you can run on your PC, an Android phone, or an edge device like the Raspberry Pi. Since we're still in the process of evolving, we haven’t made further progress in this saved file.\n",
        "\n",
        "\n",
        "This is a long notebook! Each step of the training process has its own section. Click the arrow next to the heading for each section to expand it. You can use the table of contents in the left sidebar to jump from section to section."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.&nbsp;Install TensorFlow Object Detection Dependencies"
      ],
      "metadata": {
        "id": "sxb8_h-QFErO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7EOtpvlLeS0"
      },
      "source": [
        "First, we'll install the TensorFlow Object Detection API in this Google Colab instance. This requires cloning the [TensorFlow models repository](https://github.com/tensorflow/models) and running a couple installation commands. Click the play button to run the following sections of code.\n",
        "\n",
        "The latest version of TensorFlow this Colab has been verified to work with is TF v2.8.0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypWGYdPlLRUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e54104-a1d0-4203-a938-d4db4e20fcf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Cython 3.0.11\n",
            "Uninstalling Cython-3.0.11:\n",
            "  Successfully uninstalled Cython-3.0.11\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 4305, done.\u001b[K\n",
            "remote: Counting objects: 100% (4305/4305), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3324/3324), done.\u001b[K\n",
            "remote: Total 4305 (delta 1207), reused 2097 (delta 908), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (4305/4305), 53.17 MiB | 11.18 MiB/s, done.\n",
            "Resolving deltas: 100% (1207/1207), done.\n",
            "Updating files: 100% (3875/3875), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the tensorflow models repository from GitHub\n",
        "!pip uninstall Cython -y # Temporary fix for \"No module named 'object_detection'\" error\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QPmVBSlLTzM"
      },
      "outputs": [],
      "source": [
        "# Copy setup files into models/research folder\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "#cp object_detection/packages/tf2/setup.py ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify setup.py file to install the tf-models-official repository targeted at TF v2.8.0\n",
        "import re\n",
        "with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:\n",
        "    s = f.read()\n",
        "\n",
        "with open('/content/models/research/setup.py', 'w') as f:\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('tf-models-official>=2.5.1',\n",
        "               'tf-models-official==2.8.0', s)\n",
        "    f.write(s)"
      ],
      "metadata": {
        "id": "NRBnuCKjM4Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLDnCkLLwLr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8886da6-e8c6-4a8a-8a17-e4fcc88b2436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.3\n",
            "  Downloading PyYAML-5.3.tar.gz (268 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/268.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m256.0/268.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.2/268.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3-cp310-cp310-linux_x86_64.whl size=44244 sha256=903917482849c02a97dbfcdc4309d657e657b0dd941624efff76fb1deb7b52d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/72/68/a263cfc14175636cf26bada99f13b735be1b60a11318e08bfc\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2024.10.0 requires pyyaml>=5.3.1, but you have pyyaml 5.3 which is incompatible.\n",
            "flax 0.8.5 requires PyYAML>=5.4.1, but you have pyyaml 5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyyaml-5.3\n",
            "Processing ./models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object_detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object_detection==0.1)\n",
            "  Downloading apache_beam-2.61.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (11.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.8.0)\n",
            "Collecting Cython (from object_detection==0.1)\n",
            "  Downloading Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting contextlib2 (from object_detection==0.1)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.17.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.0.8)\n",
            "Collecting lvis (from object_detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.2)\n",
            "Collecting tf-models-official==2.8.0 (from object_detection==0.1)\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tensorflow_io (from object_detection==0.1)\n",
            "  Downloading tensorflow_io-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.5.0)\n",
            "Collecting pyparsing==2.4.7 (from object_detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (2.155.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (1.6.17)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (1.26.4)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.10.0.84)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\n",
            "Collecting seqeval (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-addons (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.9.7)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.16.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Collecting tensorflow-text~=2.8.0 (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tensorflow~=2.8.0 (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow-2.8.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.2)\n",
            "Collecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.10.12)\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cloudpickle~=2.2.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.23.0)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (24.2)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.25.5)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.32.3)\n",
            "Collecting sortedcontainers>=2.4.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow<17.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (1.4.7)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (4.55.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.22.3)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (2024.12.14)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (6.2.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.10)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.4.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow~=2.8.0 (from tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow-2.8.3-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "  Downloading tensorflow-2.8.2-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "  Downloading tensorflow-2.8.1-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.17.0)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8 (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras (from object_detection==0.1)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official==2.8.0->object_detection==0.1) (2.17.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.8.0->object_detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.8.0->object_detection==0.1) (1.6.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (2.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (1.13.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (1.11.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.45.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (3.21.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (5.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.8.0->object_detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.8.0->object_detection==0.1) (3.5.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.7)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.1.3)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.6.0->tf-models-official==2.8.0->object_detection==0.1)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.16)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.0.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\n",
            "Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_beam-2.61.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Downloading tensorflow_io-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tensorflow-2.8.1-cp310-cp310-manylinux2010_x86_64.whl (498.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: object_detection, avro-python3, crcmod, dill, hdfs, seqeval, docopt\n",
            "  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697355 sha256=97339cffdadd0b3fde18377234a4e93548cc17c15fd1813e5a87f853b81e5ed5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j8iz2e0t/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43994 sha256=0450e9dbab6658e378f7b3b4e61a7558685ee5aebf793898fc30d6c7ebc9156c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=36961798ecf41eb3a7bcb3b05f6855054c7641c49815d409efbba2e6bb4cf820\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=9421c135045135fe5364d4a3e0ee6cd7cb47f4bc5ac01377754f60a03f0a259f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=4b4f3cea2466f0c4f2f1fff6477a34270b8cebcb5dc90de22ba0651ce154df93\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=170cae8e66438a1350a24b01097480d45617c7357425393e35389ca140b41e06\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=a987cfadc89e3b13679d4032ddd883c776fd60822a1ebd0328e2de9aaa3245ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object_detection avro-python3 crcmod dill hdfs seqeval docopt\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-plugin-wit, sortedcontainers, keras, docopt, crcmod, zstandard, typeguard, tf-keras, tensorflow-model-optimization, tensorflow_io, tensorboard-data-server, redis, pyparsing, pyarrow-hotfix, pyarrow, portalocker, objsize, keras-preprocessing, jsonpickle, grpcio, fasteners, fastavro, dnspython, dill, Cython, contextlib2, colorama, cloudpickle, avro-python3, tensorflow-addons, sacrebleu, pymongo, pydot, hdfs, seqeval, lvis, google-auth-oauthlib, tensorboard, apache-beam, tensorflow, tensorflow-text, tf-models-official, object_detection\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.0\n",
            "    Uninstalling pyparsing-3.2.0:\n",
            "      Successfully uninstalled pyparsing-3.2.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 17.0.0\n",
            "    Uninstalling pyarrow-17.0.0:\n",
            "      Successfully uninstalled pyarrow-17.0.0\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.0.1\n",
            "    Uninstalling jsonpickle-4.0.1:\n",
            "      Successfully uninstalled jsonpickle-4.0.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.68.1\n",
            "    Uninstalling grpcio-1.68.1:\n",
            "      Successfully uninstalled grpcio-1.68.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.0\n",
            "    Uninstalling cloudpickle-3.1.0:\n",
            "      Successfully uninstalled cloudpickle-3.1.0\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.3\n",
            "    Uninstalling pydot-3.0.3:\n",
            "      Successfully uninstalled pydot-3.0.3\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "dask 2024.10.0 requires pyyaml>=5.3.1, but you have pyyaml 5.3 which is incompatible.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "pandas-gbq 0.25.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Cython-3.0.11 apache-beam-2.61.0 avro-python3-1.10.2 cloudpickle-2.2.1 colorama-0.4.6 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 google-auth-oauthlib-0.4.6 grpcio-1.65.5 hdfs-2.7.3 jsonpickle-3.4.2 keras-2.8.0 keras-preprocessing-1.1.2 lvis-0.5.3 object_detection-0.1 objsize-0.7.0 portalocker-3.0.0 pyarrow-16.1.0 pyarrow-hotfix-0.6 pydot-1.4.2 pymongo-4.10.1 pyparsing-2.4.7 redis-5.2.1 sacrebleu-2.2.0 seqeval-1.2.2 sortedcontainers-2.4.0 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.1 tensorflow-addons-0.23.0 tensorflow-estimator-2.8.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.8.2 tensorflow_io-0.37.1 tf-keras-2.15.0 tf-models-official-2.8.0 typeguard-2.13.3 zstandard-0.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyparsing"
                ]
              },
              "id": "ba2b93d8ac2a45e6a2a2efe4b3107846"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.65.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
            "Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf-estimator-nightly, tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.1\n",
            "    Uninstalling tensorflow-2.8.1:\n",
            "      Successfully uninstalled tensorflow-2.8.1\n",
            "Successfully installed tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Collecting tensorflow_io==0.23.1\n",
            "  Downloading tensorflow_io-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.23.1 (from tensorflow_io==0.23.1)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
            "Downloading tensorflow_io-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow_io\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorflow_io\n",
            "    Found existing installation: tensorflow-io 0.37.1\n",
            "    Uninstalling tensorflow-io-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-0.37.1\n",
            "Successfully installed tensorflow-io-gcs-filesystem-0.23.1 tensorflow_io-0.23.1\n",
            "--2024-12-24 16:54:40--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 190 [application/octet-stream]\n",
            "Saving to: ‘cuda-ubuntu1804.pin’\n",
            "\n",
            "cuda-ubuntu1804.pin 100%[===================>]     190  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-24 16:54:40 (5.99 MB/s) - ‘cuda-ubuntu1804.pin’ saved [190/190]\n",
            "\n",
            "--2024-12-24 16:54:40--  http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb [following]\n",
            "--2024-12-24 16:54:40--  https://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2273753684 (2.1G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb’\n",
            "\n",
            "cuda-repo-ubuntu180 100%[===================>]   2.12G   192MB/s    in 13s     \n",
            "\n",
            "2024-12-24 16:54:54 (167 MB/s) - ‘cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb’ saved [2273753684/2273753684]\n",
            "\n",
            "Selecting previously unselected package cuda-repo-ubuntu1804-11-0-local.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb ...\n",
            "Unpacking cuda-repo-ubuntu1804-11-0-local (11.0.2-450.51.05-1) ...\n",
            "Setting up cuda-repo-ubuntu1804-11-0-local (11.0.2-450.51.05-1) ...\n",
            "\n",
            "The public CUDA GPG key does not appear to be installed.\n",
            "To install the key, run this command:\n",
            "sudo apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n",
            "\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "Get:1 file:/var/cuda-repo-ubuntu1804-11-0-local  InRelease\n",
            "Ign:1 file:/var/cuda-repo-ubuntu1804-11-0-local  InRelease\n",
            "Get:2 file:/var/cuda-repo-ubuntu1804-11-0-local  Release [564 B]\n",
            "Get:2 file:/var/cuda-repo-ubuntu1804-11-0-local  Release [564 B]\n",
            "Get:3 file:/var/cuda-repo-ubuntu1804-11-0-local  Release.gpg [836 B]\n",
            "Get:3 file:/var/cuda-repo-ubuntu1804-11-0-local  Release.gpg [836 B]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 file:/var/cuda-repo-ubuntu1804-11-0-local  Packages [23.9 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,566 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,448 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,517 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,630 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,517 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,830 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,614 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Fetched 26.9 MB in 3s (10.3 MB/s)\n",
            "Reading package lists... Done\n",
            "W: file:/var/cuda-repo-ubuntu1804-11-0-local/Release.gpg: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-11-0 cuda-cudart-11-0\n",
            "  cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0 cuda-cupti-dev-11-0\n",
            "  cuda-documentation-11-0 cuda-driver-dev-11-0 cuda-gdb-11-0\n",
            "  cuda-libraries-11-0 cuda-libraries-dev-11-0 cuda-memcheck-11-0\n",
            "  cuda-nsight-11-0 cuda-nsight-compute-11-0 cuda-nsight-systems-11-0\n",
            "  cuda-nvcc-11-0 cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0\n",
            "  cuda-nvprune-11-0 cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0\n",
            "  cuda-nvvp-11-0 cuda-samples-11-0 cuda-sanitizer-11-0 cuda-tools-11-0\n",
            "  cuda-visual-tools-11-0 default-jre default-jre-headless fonts-dejavu-core\n",
            "  fonts-dejavu-extra freeglut3 freeglut3-dev libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libcublas-11-0 libcublas-dev-11-0 libcufft-11-0\n",
            "  libcufft-dev-11-0 libcurand-11-0 libcurand-dev-11-0 libcusolver-11-0\n",
            "  libcusolver-dev-11-0 libcusparse-11-0 libcusparse-dev-11-0 libegl-dev\n",
            "  libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglu1-mesa\n",
            "  libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libice-dev\n",
            "  libnpp-11-0 libnpp-dev-11-0 libnvjpeg-11-0 libnvjpeg-dev-11-0 libopengl-dev\n",
            "  libsm-dev libxcb-cursor0 libxcb-icccm4 libxcb-image0 libxcb-keysyms1\n",
            "  libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1\n",
            "  libxfixes-dev libxi-dev libxkbcommon-x11-0 libxkbfile1 libxmu-dev\n",
            "  libxmu-headers libxt-dev libxtst6 libxxf86dga1 nsight-systems-2024.5.1\n",
            "  openjdk-11-jre x11-utils\n",
            "Suggested packages:\n",
            "  libice-doc libsm-doc libxt-doc mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-11-0 cuda-cudart-11-0\n",
            "  cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0 cuda-cupti-dev-11-0\n",
            "  cuda-documentation-11-0 cuda-driver-dev-11-0 cuda-gdb-11-0\n",
            "  cuda-libraries-11-0 cuda-libraries-dev-11-0 cuda-memcheck-11-0\n",
            "  cuda-nsight-11-0 cuda-nsight-compute-11-0 cuda-nsight-systems-11-0\n",
            "  cuda-nvcc-11-0 cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0\n",
            "  cuda-nvprune-11-0 cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0\n",
            "  cuda-nvvp-11-0 cuda-samples-11-0 cuda-sanitizer-11-0 cuda-toolkit-11-0\n",
            "  cuda-tools-11-0 cuda-visual-tools-11-0 default-jre default-jre-headless\n",
            "  fonts-dejavu-core fonts-dejavu-extra freeglut3 freeglut3-dev\n",
            "  libatk-wrapper-java libatk-wrapper-java-jni libcublas-11-0\n",
            "  libcublas-dev-11-0 libcufft-11-0 libcufft-dev-11-0 libcurand-11-0\n",
            "  libcurand-dev-11-0 libcusolver-11-0 libcusolver-dev-11-0 libcusparse-11-0\n",
            "  libcusparse-dev-11-0 libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev\n",
            "  libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev\n",
            "  libglvnd-dev libglx-dev libice-dev libnpp-11-0 libnpp-dev-11-0\n",
            "  libnvjpeg-11-0 libnvjpeg-dev-11-0 libopengl-dev libsm-dev libxcb-cursor0\n",
            "  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxfixes-dev libxi-dev\n",
            "  libxkbcommon-x11-0 libxkbfile1 libxmu-dev libxmu-headers libxt-dev libxtst6\n",
            "  libxxf86dga1 nsight-systems-2024.5.1 openjdk-11-jre x11-utils\n",
            "0 upgraded, 87 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 361 MB/1,943 MB of archives.\n",
            "After this operation, 4,022 MB of additional disk space will be used.\n",
            "Get:1 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cudart-11-0 11.0.194-1 [129 kB]\n",
            "Get:2 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-driver-dev-11-0 11.0.194-1 [25.0 kB]\n",
            "Get:3 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cudart-dev-11-0 11.0.194-1 [1,662 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-systems-2024.5.1 2024.5.1.113-245134619542v0 [356 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:6 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvcc-11-0 11.0.194-1 [21.1 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.3 [6,848 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n",
            "Get:22 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cupti-11-0 11.0.194-1 [10.5 MB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxmu-headers all 2:1.1.3-3 [54.1 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxmu-dev amd64 2:1.1.3-3 [54.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfixes-dev amd64 1:6.0.0-1 [12.2 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxi-dev amd64 2:1.8-1build1 [193 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre-headless amd64 2:1.11-72build2 [3,042 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.25+9-1ubuntu1~22.04 [216 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre amd64 2:1.11-72build2 [896 B]\n",
            "Get:31 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cupti-dev-11-0 11.0.194-1 [2,276 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libxcb-cursor0 amd64 0.1.1-4ubuntu1 [10.5 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:50 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvdisasm-11-0 11.0.194-1 [27.3 MB]\n",
            "Get:51 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cuobjdump-11-0 11.0.194-1 [103 kB]\n",
            "Get:52 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-gdb-11-0 11.0.194-1 [3,891 kB]\n",
            "Get:53 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-memcheck-11-0 11.0.194-1 [144 kB]\n",
            "Get:54 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvprof-11-0 11.0.194-1 [1,911 kB]\n",
            "Get:55 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvtx-11-0 11.0.167-1 [51.1 kB]\n",
            "Get:56 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-sanitizer-11-0 11.0.194-1 [7,220 kB]\n",
            "Get:57 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-command-line-tools-11-0 11.0.2-1 [2,474 B]\n",
            "Get:58 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvprune-11-0 11.0.167-1 [53.1 kB]\n",
            "Get:59 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-compiler-11-0 11.0.2-1 [2,416 B]\n",
            "Get:60 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvrtc-11-0 11.0.194-1 [6,521 kB]\n",
            "Get:61 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvrtc-dev-11-0 11.0.194-1 [22.1 kB]\n",
            "Get:62 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusolver-11-0 10.5.0.218-1 [277 MB]\n",
            "Get:63 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusolver-dev-11-0 10.5.0.218-1 [17.6 MB]\n",
            "Get:64 file:/var/cuda-repo-ubuntu1804-11-0-local  libcublas-11-0 11.1.0.229-1 [118 MB]\n",
            "Get:65 file:/var/cuda-repo-ubuntu1804-11-0-local  libcublas-dev-11-0 11.1.0.229-1 [120 MB]\n",
            "Get:66 file:/var/cuda-repo-ubuntu1804-11-0-local  libcufft-11-0 10.2.0.218-1 [94.1 MB]\n",
            "Get:67 file:/var/cuda-repo-ubuntu1804-11-0-local  libcufft-dev-11-0 10.2.0.218-1 [172 MB]\n",
            "Get:68 file:/var/cuda-repo-ubuntu1804-11-0-local  libcurand-11-0 10.2.1.218-1 [39.2 MB]\n",
            "Get:69 file:/var/cuda-repo-ubuntu1804-11-0-local  libcurand-dev-11-0 10.2.1.218-1 [39.2 MB]\n",
            "Get:70 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusparse-11-0 11.1.0.218-1 [71.2 MB]\n",
            "Get:71 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusparse-dev-11-0 11.1.0.218-1 [71.4 MB]\n",
            "Get:72 file:/var/cuda-repo-ubuntu1804-11-0-local  libnpp-11-0 11.1.0.218-1 [56.6 MB]\n",
            "Get:73 file:/var/cuda-repo-ubuntu1804-11-0-local  libnpp-dev-11-0 11.1.0.218-1 [57.4 MB]\n",
            "Get:74 file:/var/cuda-repo-ubuntu1804-11-0-local  libnvjpeg-11-0 11.1.0.218-1 [1,391 kB]\n",
            "Get:75 file:/var/cuda-repo-ubuntu1804-11-0-local  libnvjpeg-dev-11-0 11.1.0.218-1 [1,321 kB]\n",
            "Get:76 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-samples-11-0 11.0.194-1 [68.1 MB]\n",
            "Get:77 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-documentation-11-0 11.0.207-1 [59.6 MB]\n",
            "Get:78 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-libraries-11-0 11.0.2-1 [2,490 B]\n",
            "Get:79 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-libraries-dev-11-0 11.0.2-1 [2,514 B]\n",
            "Get:80 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-11-0 11.0.194-1 [119 MB]\n",
            "Get:81 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-compute-11-0 11.0.2-1 [3,718 B]\n",
            "Get:82 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-systems-11-0 11.0.2-1 [3,280 B]\n",
            "Get:83 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvml-dev-11-0 11.0.167-1 [71.9 kB]\n",
            "Get:84 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvvp-11-0 11.0.194-1 [115 MB]\n",
            "Get:85 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-visual-tools-11-0 11.0.2-1 [2,942 B]\n",
            "Get:86 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-tools-11-0 11.0.2-1 [2,380 B]\n",
            "Get:87 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-toolkit-11-0 11.0.2-1 [2,728 B]\n",
            "Fetched 361 MB in 17s (21.3 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 87.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cuda-cudart-11-0.\n",
            "(Reading database ... 123721 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-cudart-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-11-0.\n",
            "Preparing to unpack .../01-cuda-driver-dev-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-11-0.\n",
            "Preparing to unpack .../02-cuda-cudart-dev-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nvcc-11-0.\n",
            "Preparing to unpack .../03-cuda-nvcc-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvcc-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-cupti-11-0.\n",
            "Preparing to unpack .../04-cuda-cupti-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-cupti-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-cupti-dev-11-0.\n",
            "Preparing to unpack .../05-cuda-cupti-dev-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-cupti-dev-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nvdisasm-11-0.\n",
            "Preparing to unpack .../06-cuda-nvdisasm-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvdisasm-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-cuobjdump-11-0.\n",
            "Preparing to unpack .../07-cuda-cuobjdump-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-cuobjdump-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-gdb-11-0.\n",
            "Preparing to unpack .../08-cuda-gdb-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-gdb-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-memcheck-11-0.\n",
            "Preparing to unpack .../09-cuda-memcheck-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-memcheck-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nvprof-11-0.\n",
            "Preparing to unpack .../10-cuda-nvprof-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvprof-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nvtx-11-0.\n",
            "Preparing to unpack .../11-cuda-nvtx-11-0_11.0.167-1_amd64.deb ...\n",
            "Unpacking cuda-nvtx-11-0 (11.0.167-1) ...\n",
            "Selecting previously unselected package cuda-sanitizer-11-0.\n",
            "Preparing to unpack .../12-cuda-sanitizer-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-sanitizer-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-command-line-tools-11-0.\n",
            "Preparing to unpack .../13-cuda-command-line-tools-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-command-line-tools-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package cuda-nvprune-11-0.\n",
            "Preparing to unpack .../14-cuda-nvprune-11-0_11.0.167-1_amd64.deb ...\n",
            "Unpacking cuda-nvprune-11-0 (11.0.167-1) ...\n",
            "Selecting previously unselected package cuda-compiler-11-0.\n",
            "Preparing to unpack .../15-cuda-compiler-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-compiler-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "Preparing to unpack .../16-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../17-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../18-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../19-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../20-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../21-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../22-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../23-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../24-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../25-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../26-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../27-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../28-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../29-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../30-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../31-freeglut3-dev_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libxmu-headers.\n",
            "Preparing to unpack .../32-libxmu-headers_2%3a1.1.3-3_all.deb ...\n",
            "Unpacking libxmu-headers (2:1.1.3-3) ...\n",
            "Selecting previously unselected package libxmu-dev:amd64.\n",
            "Preparing to unpack .../33-libxmu-dev_2%3a1.1.3-3_amd64.deb ...\n",
            "Unpacking libxmu-dev:amd64 (2:1.1.3-3) ...\n",
            "Selecting previously unselected package libxfixes-dev:amd64.\n",
            "Preparing to unpack .../34-libxfixes-dev_1%3a6.0.0-1_amd64.deb ...\n",
            "Unpacking libxfixes-dev:amd64 (1:6.0.0-1) ...\n",
            "Selecting previously unselected package libxi-dev:amd64.\n",
            "Preparing to unpack .../35-libxi-dev_2%3a1.8-1build1_amd64.deb ...\n",
            "Unpacking libxi-dev:amd64 (2:1.8-1build1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-11-0.\n",
            "Preparing to unpack .../36-cuda-nvrtc-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-11-0.\n",
            "Preparing to unpack .../37-cuda-nvrtc-dev-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package libcusolver-11-0.\n",
            "Preparing to unpack .../38-libcusolver-11-0_10.5.0.218-1_amd64.deb ...\n",
            "Unpacking libcusolver-11-0 (10.5.0.218-1) ...\n",
            "Selecting previously unselected package libcusolver-dev-11-0.\n",
            "Preparing to unpack .../39-libcusolver-dev-11-0_10.5.0.218-1_amd64.deb ...\n",
            "Unpacking libcusolver-dev-11-0 (10.5.0.218-1) ...\n",
            "Selecting previously unselected package libcublas-11-0.\n",
            "Preparing to unpack .../40-libcublas-11-0_11.1.0.229-1_amd64.deb ...\n",
            "Unpacking libcublas-11-0 (11.1.0.229-1) ...\n",
            "Selecting previously unselected package libcublas-dev-11-0.\n",
            "Preparing to unpack .../41-libcublas-dev-11-0_11.1.0.229-1_amd64.deb ...\n",
            "Unpacking libcublas-dev-11-0 (11.1.0.229-1) ...\n",
            "Selecting previously unselected package libcufft-11-0.\n",
            "Preparing to unpack .../42-libcufft-11-0_10.2.0.218-1_amd64.deb ...\n",
            "Unpacking libcufft-11-0 (10.2.0.218-1) ...\n",
            "Selecting previously unselected package libcufft-dev-11-0.\n",
            "Preparing to unpack .../43-libcufft-dev-11-0_10.2.0.218-1_amd64.deb ...\n",
            "Unpacking libcufft-dev-11-0 (10.2.0.218-1) ...\n",
            "Selecting previously unselected package libcurand-11-0.\n",
            "Preparing to unpack .../44-libcurand-11-0_10.2.1.218-1_amd64.deb ...\n",
            "Unpacking libcurand-11-0 (10.2.1.218-1) ...\n",
            "Selecting previously unselected package libcurand-dev-11-0.\n",
            "Preparing to unpack .../45-libcurand-dev-11-0_10.2.1.218-1_amd64.deb ...\n",
            "Unpacking libcurand-dev-11-0 (10.2.1.218-1) ...\n",
            "Selecting previously unselected package libcusparse-11-0.\n",
            "Preparing to unpack .../46-libcusparse-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libcusparse-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package libcusparse-dev-11-0.\n",
            "Preparing to unpack .../47-libcusparse-dev-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libcusparse-dev-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package libnpp-11-0.\n",
            "Preparing to unpack .../48-libnpp-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libnpp-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package libnpp-dev-11-0.\n",
            "Preparing to unpack .../49-libnpp-dev-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libnpp-dev-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package libnvjpeg-11-0.\n",
            "Preparing to unpack .../50-libnvjpeg-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libnvjpeg-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package libnvjpeg-dev-11-0.\n",
            "Preparing to unpack .../51-libnvjpeg-dev-11-0_11.1.0.218-1_amd64.deb ...\n",
            "Unpacking libnvjpeg-dev-11-0 (11.1.0.218-1) ...\n",
            "Selecting previously unselected package cuda-samples-11-0.\n",
            "Preparing to unpack .../52-cuda-samples-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-samples-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-documentation-11-0.\n",
            "Preparing to unpack .../53-cuda-documentation-11-0_11.0.207-1_amd64.deb ...\n",
            "Unpacking cuda-documentation-11-0 (11.0.207-1) ...\n",
            "Selecting previously unselected package cuda-libraries-11-0.\n",
            "Preparing to unpack .../54-cuda-libraries-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-11-0.\n",
            "Preparing to unpack .../55-cuda-libraries-dev-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package default-jre-headless.\n",
            "Preparing to unpack .../56-default-jre-headless_2%3a1.11-72build2_amd64.deb ...\n",
            "Unpacking default-jre-headless (2:1.11-72build2) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../57-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-11-jre:amd64.\n",
            "Preparing to unpack .../58-openjdk-11-jre_11.0.25+9-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jre:amd64 (11.0.25+9-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package default-jre.\n",
            "Preparing to unpack .../59-default-jre_2%3a1.11-72build2_amd64.deb ...\n",
            "Unpacking default-jre (2:1.11-72build2) ...\n",
            "Selecting previously unselected package cuda-nsight-11-0.\n",
            "Preparing to unpack .../60-cuda-nsight-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-nsight-compute-11-0.\n",
            "Preparing to unpack .../61-cuda-nsight-compute-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-compute-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../62-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../63-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../64-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../65-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../66-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../67-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../68-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../69-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../70-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-cursor0:amd64.\n",
            "Preparing to unpack .../71-libxcb-cursor0_0.1.1-4ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-cursor0:amd64 (0.1.1-4ubuntu1) ...\n",
            "Selecting previously unselected package nsight-systems-2024.5.1.\n",
            "Preparing to unpack .../72-nsight-systems-2024.5.1_2024.5.1.113-245134619542v0_amd64.deb ...\n",
            "Unpacking nsight-systems-2024.5.1 (2024.5.1.113-245134619542v0) ...\n",
            "Selecting previously unselected package cuda-nsight-systems-11-0.\n",
            "Preparing to unpack .../73-cuda-nsight-systems-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-systems-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package cuda-nvml-dev-11-0.\n",
            "Preparing to unpack .../74-cuda-nvml-dev-11-0_11.0.167-1_amd64.deb ...\n",
            "Unpacking cuda-nvml-dev-11-0 (11.0.167-1) ...\n",
            "Selecting previously unselected package cuda-nvvp-11-0.\n",
            "Preparing to unpack .../75-cuda-nvvp-11-0_11.0.194-1_amd64.deb ...\n",
            "Unpacking cuda-nvvp-11-0 (11.0.194-1) ...\n",
            "Selecting previously unselected package cuda-visual-tools-11-0.\n",
            "Preparing to unpack .../76-cuda-visual-tools-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-visual-tools-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package cuda-tools-11-0.\n",
            "Preparing to unpack .../77-cuda-tools-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-tools-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package cuda-toolkit-11-0.\n",
            "Preparing to unpack .../78-cuda-toolkit-11-0_11.0.2-1_amd64.deb ...\n",
            "Unpacking cuda-toolkit-11-0 (11.0.2-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../79-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../80-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../81-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../82-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../83-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../84-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../85-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../86-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up libcurand-11-0 (10.2.1.218-1) ...\n",
            "Setting up libcublas-11-0 (11.1.0.229-1) ...\n",
            "Setting up libxmu-headers (2:1.1.3-3) ...\n",
            "Setting up cuda-nvtx-11-0 (11.0.167-1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up default-jre-headless (2:1.11-72build2) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libcusolver-11-0 (10.5.0.218-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up cuda-driver-dev-11-0 (11.0.194-1) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up cuda-nsight-compute-11-0 (11.0.2-1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up cuda-memcheck-11-0 (11.0.194-1) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up openjdk-11-jre:amd64 (11.0.25+9-1ubuntu1~22.04) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up default-jre (2:1.11-72build2) ...\n",
            "Setting up cuda-nvprune-11-0 (11.0.167-1) ...\n",
            "Setting up libnvjpeg-11-0 (11.1.0.218-1) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up cuda-cudart-11-0 (11.0.194-1) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxfixes-dev:amd64 (1:6.0.0-1) ...\n",
            "Setting up cuda-nvprof-11-0 (11.0.194-1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up cuda-nvml-dev-11-0 (11.0.167-1) ...\n",
            "Setting up libxcb-cursor0:amd64 (0.1.1-4ubuntu1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up libcusparse-11-0 (11.1.0.218-1) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up cuda-cuobjdump-11-0 (11.0.194-1) ...\n",
            "Setting up libcufft-11-0 (10.2.0.218-1) ...\n",
            "Setting up cuda-cudart-dev-11-0 (11.0.194-1) ...\n",
            "Setting up cuda-nvrtc-11-0 (11.0.194-1) ...\n",
            "Setting up cuda-sanitizer-11-0 (11.0.194-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libcufft-dev-11-0 (10.2.0.218-1) ...\n",
            "Setting up libnpp-11-0 (11.1.0.218-1) ...\n",
            "Setting up libcusolver-dev-11-0 (10.5.0.218-1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up cuda-nvdisasm-11-0 (11.0.194-1) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libxi-dev:amd64 (2:1.8-1build1) ...\n",
            "Setting up libcublas-dev-11-0 (11.1.0.229-1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libcusparse-dev-11-0 (11.1.0.218-1) ...\n",
            "Setting up cuda-nvvp-11-0 (11.0.194-1) ...\n",
            "Setting up libcurand-dev-11-0 (10.2.1.218-1) ...\n",
            "Setting up libnpp-dev-11-0 (11.1.0.218-1) ...\n",
            "Setting up cuda-libraries-11-0 (11.0.2-1) ...\n",
            "Setting up cuda-gdb-11-0 (11.0.194-1) ...\n",
            "Setting up cuda-nvrtc-dev-11-0 (11.0.194-1) ...\n",
            "Setting up nsight-systems-2024.5.1 (2024.5.1.113-245134619542v0) ...\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2024.5.1/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2024.5.1/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up cuda-nsight-11-0 (11.0.194-1) ...\n",
            "Setting up libnvjpeg-dev-11-0 (11.1.0.218-1) ...\n",
            "Setting up libxmu-dev:amd64 (2:1.1.3-3) ...\n",
            "Setting up cuda-nvcc-11-0 (11.0.194-1) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up cuda-libraries-dev-11-0 (11.0.2-1) ...\n",
            "Setting up cuda-cupti-11-0 (11.0.194-1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up cuda-nsight-systems-11-0 (11.0.2-1) ...\n",
            "Setting up cuda-visual-tools-11-0 (11.0.2-1) ...\n",
            "Setting up cuda-compiler-11-0 (11.0.2-1) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up cuda-cupti-dev-11-0 (11.0.194-1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up cuda-command-line-tools-11-0 (11.0.2-1) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Setting up cuda-tools-11-0 (11.0.2-1) ...\n",
            "Setting up cuda-samples-11-0 (11.0.194-1) ...\n",
            "Setting up cuda-documentation-11-0 (11.0.207-1) ...\n",
            "Setting up cuda-toolkit-11-0 (11.0.2-1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "# Install the Object Detection API (NOTE: This block takes about 10 minutes to finish executing)\n",
        "\n",
        "# Need to do a temporary fix with PyYAML because Colab isn't able to install PyYAML v5.4.1\n",
        "!pip install pyyaml==5.3\n",
        "!pip install /content/models/research/\n",
        "\n",
        "# Need to downgrade to TF v2.8.0 due to Colab compatibility bug with TF v2.10 (as of 10/03/22)\n",
        "!pip install tensorflow==2.8.0\n",
        "\n",
        "# Install CUDA version 11.0 (to maintain compatibility with TF v2.8.0)\n",
        "!pip install tensorflow_io==0.23.1\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
        "!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n",
        "!apt-get update && sudo apt-get install cuda-toolkit-11-0\n",
        "!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V7TrfUos-9E"
      },
      "source": [
        "You may get warnings or errors related to package dependencies in the previous code block, but you can ignore them for now.\n",
        "\n",
        "Let's test our installation by running `model_builder_tf2_test.py` to make sure everything is working as expected. Run the following code block and confirm that it finishes without errors. If you get errors, try Googling them or checking the FAQ at the end of this Colab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "9iHGMgt3pNXb",
        "outputId": "68178748-5f6a-40a2-c0d9-8c98822361b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf==3.20.3\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.1 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "pandas-gbq 0.25.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "7fe8e8c799b746328c036a26e88c79d9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh_HPMOqWH9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a9df21-d84a-4075-a22b-f2dc5bf510ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2024-12-24 17:09:53.350066: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W1224 17:09:53.596038 136810019336192 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.74s\n",
            "I1224 17:09:53.995171 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.74s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.49s\n",
            "I1224 17:09:54.490131 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.49s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.24s\n",
            "I1224 17:09:54.728435 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.21s\n",
            "I1224 17:09:54.942876 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.21s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.34s\n",
            "I1224 17:09:57.281787 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.34s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1224 17:09:57.283435 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "I1224 17:09:57.320562 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I1224 17:09:57.341448 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I1224 17:09:57.362908 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "I1224 17:09:57.499469 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "I1224 17:09:57.630305 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "I1224 17:09:57.772111 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
            "I1224 17:09:57.905220 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "I1224 17:09:58.042499 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I1224 17:09:58.082806 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1224 17:09:58.341548 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1224 17:09:58.341756 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I1224 17:09:58.341847 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I1224 17:09:58.345473 136810019336192 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1224 17:09:58.376345 136810019336192 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1224 17:09:58.377699 136810019336192 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1224 17:09:58.444975 136810019336192 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1224 17:09:58.445116 136810019336192 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1224 17:09:58.584215 136810019336192 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1224 17:09:58.584384 136810019336192 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1224 17:09:58.733563 136810019336192 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1224 17:09:58.733722 136810019336192 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1224 17:09:58.945693 136810019336192 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1224 17:09:58.945850 136810019336192 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1224 17:09:59.161783 136810019336192 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1224 17:09:59.161946 136810019336192 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1224 17:09:59.458747 136810019336192 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1224 17:09:59.458914 136810019336192 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I1224 17:09:59.526239 136810019336192 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I1224 17:09:59.557811 136810019336192 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 17:09:59.608589 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1224 17:09:59.608753 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I1224 17:09:59.608821 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I1224 17:09:59.610352 136810019336192 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1224 17:09:59.624670 136810019336192 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1224 17:09:59.624790 136810019336192 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1224 17:09:59.745568 136810019336192 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1224 17:09:59.745734 136810019336192 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1224 17:09:59.955428 136810019336192 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1224 17:09:59.955582 136810019336192 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1224 17:10:00.167043 136810019336192 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I1224 17:10:00.167196 136810019336192 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1224 17:10:00.654031 136810019336192 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I1224 17:10:00.654227 136810019336192 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1224 17:10:00.938196 136810019336192 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I1224 17:10:00.938371 136810019336192 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1224 17:10:01.292948 136810019336192 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I1224 17:10:01.293106 136810019336192 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I1224 17:10:01.430527 136810019336192 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I1224 17:10:01.457872 136810019336192 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 17:10:01.522387 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1224 17:10:01.522522 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I1224 17:10:01.522608 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I1224 17:10:01.524054 136810019336192 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1224 17:10:01.537829 136810019336192 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I1224 17:10:01.537931 136810019336192 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1224 17:10:01.660336 136810019336192 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I1224 17:10:01.660521 136810019336192 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1224 17:10:01.878597 136810019336192 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I1224 17:10:01.878811 136810019336192 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1224 17:10:02.086597 136810019336192 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1224 17:10:02.086759 136810019336192 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I1224 17:10:02.368334 136810019336192 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I1224 17:10:02.368483 136810019336192 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I1224 17:10:02.658640 136810019336192 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I1224 17:10:02.658800 136810019336192 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I1224 17:10:03.014090 136810019336192 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I1224 17:10:03.014258 136810019336192 efficientnet_model.py:144] round_filter input=320 output=352\n",
            "I1224 17:10:03.155158 136810019336192 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
            "I1224 17:10:03.181605 136810019336192 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 17:10:03.238989 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1224 17:10:03.239123 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I1224 17:10:03.239200 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I1224 17:10:03.240630 136810019336192 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I1224 17:10:03.254742 136810019336192 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I1224 17:10:03.254844 136810019336192 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1224 17:10:03.367148 136810019336192 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1224 17:10:03.367264 136810019336192 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1224 17:10:03.587289 136810019336192 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1224 17:10:03.587475 136810019336192 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1224 17:10:03.798460 136810019336192 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I1224 17:10:03.798620 136810019336192 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I1224 17:10:04.151500 136810019336192 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I1224 17:10:04.151663 136810019336192 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I1224 17:10:04.502557 136810019336192 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I1224 17:10:04.502708 136810019336192 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I1224 17:10:04.937042 136810019336192 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I1224 17:10:04.937203 136810019336192 efficientnet_model.py:144] round_filter input=320 output=384\n",
            "I1224 17:10:05.081336 136810019336192 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
            "I1224 17:10:05.108836 136810019336192 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 17:10:05.170069 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1224 17:10:05.170207 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I1224 17:10:05.170277 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1224 17:10:05.171726 136810019336192 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1224 17:10:05.451758 136810019336192 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1224 17:10:05.451919 136810019336192 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1224 17:10:05.566966 136810019336192 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1224 17:10:05.567151 136810019336192 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1224 17:10:05.869432 136810019336192 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I1224 17:10:05.869591 136810019336192 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I1224 17:10:06.166123 136810019336192 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I1224 17:10:06.166285 136810019336192 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I1224 17:10:06.593034 136810019336192 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I1224 17:10:06.593226 136810019336192 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I1224 17:10:07.027587 136810019336192 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I1224 17:10:07.027744 136810019336192 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I1224 17:10:07.609892 136810019336192 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I1224 17:10:07.610067 136810019336192 efficientnet_model.py:144] round_filter input=320 output=448\n",
            "I1224 17:10:07.765675 136810019336192 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
            "I1224 17:10:07.792196 136810019336192 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 17:10:07.862790 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1224 17:10:07.862940 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I1224 17:10:07.863015 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1224 17:10:07.864503 136810019336192 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1224 17:10:07.878852 136810019336192 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I1224 17:10:07.878955 136810019336192 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1224 17:10:08.054098 136810019336192 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I1224 17:10:08.054265 136810019336192 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1224 17:10:08.413729 136810019336192 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1224 17:10:08.413937 136810019336192 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I1224 17:10:08.922388 136810019336192 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I1224 17:10:08.922590 136810019336192 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I1224 17:10:09.574201 136810019336192 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I1224 17:10:09.574406 136810019336192 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I1224 17:10:10.307082 136810019336192 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I1224 17:10:10.307283 136810019336192 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I1224 17:10:11.242779 136810019336192 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I1224 17:10:11.242972 136810019336192 efficientnet_model.py:144] round_filter input=320 output=512\n",
            "I1224 17:10:11.798327 136810019336192 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
            "I1224 17:10:11.841060 136810019336192 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 17:10:11.922326 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1224 17:10:11.922474 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1224 17:10:11.922561 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1224 17:10:11.924002 136810019336192 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I1224 17:10:11.938262 136810019336192 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I1224 17:10:11.938374 136810019336192 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1224 17:10:12.113063 136810019336192 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1224 17:10:12.113236 136810019336192 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1224 17:10:12.541940 136810019336192 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I1224 17:10:12.542103 136810019336192 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I1224 17:10:12.979949 136810019336192 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I1224 17:10:12.980113 136810019336192 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I1224 17:10:13.550349 136810019336192 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I1224 17:10:13.550524 136810019336192 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I1224 17:10:14.126128 136810019336192 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I1224 17:10:14.126308 136810019336192 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I1224 17:10:14.911319 136810019336192 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I1224 17:10:14.911493 136810019336192 efficientnet_model.py:144] round_filter input=320 output=576\n",
            "I1224 17:10:15.118337 136810019336192 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
            "I1224 17:10:15.146594 136810019336192 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 17:10:15.241353 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1224 17:10:15.241515 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1224 17:10:15.241590 136810019336192 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1224 17:10:15.243072 136810019336192 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I1224 17:10:15.257306 136810019336192 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I1224 17:10:15.257420 136810019336192 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1224 17:10:15.486713 136810019336192 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I1224 17:10:15.486873 136810019336192 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I1224 17:10:15.995984 136810019336192 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I1224 17:10:15.996151 136810019336192 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I1224 17:10:16.503958 136810019336192 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I1224 17:10:16.504122 136810019336192 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I1224 17:10:17.546489 136810019336192 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I1224 17:10:17.546650 136810019336192 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I1224 17:10:18.293972 136810019336192 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I1224 17:10:18.294174 136810019336192 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I1224 17:10:19.255973 136810019336192 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I1224 17:10:19.256138 136810019336192 efficientnet_model.py:144] round_filter input=320 output=640\n",
            "I1224 17:10:19.538066 136810019336192 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
            "I1224 17:10:19.577891 136810019336192 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 21.61s\n",
            "I1224 17:10:19.689662 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 21.61s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "I1224 17:10:19.703120 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1224 17:10:19.704710 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1224 17:10:19.705159 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1224 17:10:19.706559 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1224 17:10:19.707823 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1224 17:10:19.708229 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1224 17:10:19.709153 136810019336192 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 28.461s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "# Run Model Bulider Test file, just to verify everything's working properly\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.&nbsp;Upload Image Dataset and Prepare Training Data"
      ],
      "metadata": {
        "id": "eydREUsMGUUR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSZVCxE4nSVI"
      },
      "source": [
        "In this section, we'll complete the final step, as we have the Roboflow API, which generates a dataset specifically for TensorFlow. Or upload our data and prepare it for training with TensorFlow. We'll upload our images, split them into train, validation, and test folders, and then run scripts for creating TFRecords from our data.\n",
        "\n",
        "First, on your local PC, zip all your training images and XML files into a single folder called \"images.zip\". The files should be directly inside the zip folder, or in a nested folder as shown below:\n",
        "```\n",
        "images.zip\n",
        "-- images\n",
        "  -- img1.jpg\n",
        "  -- img1.xml\n",
        "  -- img2.jpg\n",
        "  -- img2.xml\n",
        "  ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Upload images\n",
        "There are three options for moving the image files to this Colab instance."
      ],
      "metadata": {
        "id": "LE1MtX4HGQA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Option 1. Upload through Google Colab**\n",
        "\n",
        "Upload the \"images.zip\" file to the Google Colab instance by clicking the \"Files\" icon on the left hand side of the browser, and then the \"Upload to session storage\" icon. Select the zip folder to upload it.\n",
        "\n",
        "![](https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/doc/colab_upload_button.png)"
      ],
      "metadata": {
        "id": "sFSJoDEnJotN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Option 2. Copy from Google Drive**\n",
        "\n",
        "You can also upload your images to your personal Google Drive, mount the drive on this Colab session, and copy them over to the Colab filesystem. This option works well if you want to upload the images beforehand so you don't have to wait for them to upload each time you restart this Colab. If you have more than 50MB worth of images, I recommend using this option.\n",
        "\n",
        "First, upload the \"images.zip\" file to your Google Drive, and make note of the folder you uploaded them to. Replace `MyDrive/path/to/images.zip` with the path to your zip file. (For example, I uploaded the zip file to folder called \"change-counter1\", so I would use `MyDrive/change-counter1/images.zip` for the path). Then, run the following block of code to mount your Google Drive to this Colab session and copy the folder to this filesystem."
      ],
      "metadata": {
        "id": "hGsPlloAGIXB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLgAPsQsfTLs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/MyDrive/path/to/images.zip /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHjOhoSGYwT7"
      },
      "source": [
        "## 3.2 Split images into train, validation, and test folders\n",
        "At this point, whether you used Option 1, 2, or 3, you should be able to click the folder icon on the left and see your \"images.zip\" file in the list of files. Now that the dataset is uploaded, let's unzip it and create some folders to hold the images. These directories are created in the /content folder in this instance's filesystem. You can browse the filesystem by clicking the \"Files\" icon on the left."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGvoHH-unSVO"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/images\n",
        "!unzip -q images.zip -d /content/images/all\n",
        "!mkdir /content/images/train; mkdir /content/images/validation; mkdir /content/images/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-6RIcrwbQMh"
      },
      "source": [
        "Next, we'll split the images into train, validation, and test sets. Here's what each set is used for:\n",
        "\n",
        "\n",
        "\n",
        "*   **Train**: These are the actual images used to train the model. In each step of training, a batch of images from the \"train\" set is passed into the neural network. The network predicts classes and locations of objects in the images. The training algorithm calculates the loss (i.e. how \"wrong\" the predictions were) and adjusts the network weights through backpropagation.\n",
        "\n",
        "\n",
        "*   **Validation**: Images from the \"validation\" set can be used by the training algorithm to check the progress of training and adjust hyperparameters (like learning rate). Unlike \"train\" images, these images are only used periodically during training (i.e. once every certain number of training steps).\n",
        "\n",
        "\n",
        "* **Test**: These images are never seen by the neural network during training. They are intended to be used by a human to perform final testing of the model to check how accurate the model is.\n",
        "\n",
        "I wrote a Python script to randomly move 80% of the images to the \"train\" folder, 10% to the \"validation\" folder, and 10% to the \"test\" folder. Click play on the following block to download the script and execute it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/train_val_test_split.py\n",
        "!python train_val_test_split.py"
      ],
      "metadata": {
        "id": "PfuZpmdBLjh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p--K1PJXEgNo"
      },
      "source": [
        "## 3.3 Create Labelmap and TFRecords\n",
        "Finally, we need to create a labelmap for the detector and convert the images into a data file format called TFRecords, which are used by TensorFlow for training. We'll use Python scripts to automatically convert the data into TFRecord format. Before running them, we need to define a labelmap for our classes.\n",
        "\n",
        "The code section below will create a \"labelmap.txt\" file that contains a list of classes. Replace the `class1`, `class2`, `class3` text with your own classes (for example, `penny`, `nickel`, `dime`, `quarter`), adding a new line for each class. Then, click play to execute the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DE_r4MKY7ln"
      },
      "outputs": [],
      "source": [
        "### This creates a a \"labelmap.txt\" file with a list of classes the object detection model will detect.\n",
        "%%bash\n",
        "cat <<EOF >> /content/labelmap.txt\n",
        "class1\n",
        "class2\n",
        "class3\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pa2VYhTIT1l"
      },
      "source": [
        "Download and run the data conversion scripts from the [GitHub repository](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi) by clicking play on the following three sections of code. They will create TFRecord files for the train and validation datasets, as well as a `labelmap.pbtxt` file which contains the labelmap in a different format."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data conversion scripts\n",
        "! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_csv.py\n",
        "! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_tfrecord.py"
      ],
      "metadata": {
        "id": "laZZE0TlEeUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tdDbTmHYwu-"
      },
      "outputs": [],
      "source": [
        "# Create CSV data files and TFRecord files\n",
        "!python3 create_csv.py\n",
        "!python3 create_tfrecord.py --csv_input=images/train_labels.csv --labelmap=labelmap.txt --image_dir=images/train --output_path=train.tfrecord\n",
        "!python3 create_tfrecord.py --csv_input=images/validation_labels.csv --labelmap=labelmap.txt --image_dir=images/validation --output_path=val.tfrecord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNyv_YyDXwMs"
      },
      "source": [
        "We'll store the locations of the TFRecord and labelmap files as variables so we can reference them later in this Colab session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUd2wtfrqedy"
      },
      "outputs": [],
      "source": [
        "train_record_fname = '/content/train.tfrecord'\n",
        "val_record_fname = '/content/val.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/labelmap.pbtxt'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We've used our FDM Anomalies dataset from Roboflow, which is compatible with TensorFlow, and generated an API for easy integration."
      ],
      "metadata": {
        "id": "Aypn-OM5A2fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/d0LMi29TYZ?key=N3zkznYcXU\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSOlflUeiOwL",
        "outputId": "5f4446bd-ea4b-4356-e8c2-9b680e218bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   897  100   897    0     0   3098      0 --:--:-- --:--:-- --:--:--  3093\n",
            "100 95.4M  100 95.4M    0     0  38.3M      0  0:00:02  0:00:02 --:--:-- 58.8M\n",
            "Archive:  roboflow.zip\n",
            "  inflating: README.dataset.txt      \n",
            "  inflating: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/Defect-Stringing.tfrecord  \n",
            "  inflating: test/Defect-Stringing_label_map.pbtxt  \n",
            "   creating: train/\n",
            " extracting: train/Defect-Stringing.tfrecord  \n",
            "  inflating: train/Defect-Stringing_label_map.pbtxt  \n",
            "   creating: valid/\n",
            " extracting: valid/Defect-Stringing.tfrecord  \n",
            "  inflating: valid/Defect-Stringing_label_map.pbtxt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2v2KX0_pmW6",
        "outputId": "d75a4ce1-c019-40fb-c614-2f29c39b7159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defect-Stringing_label_map.pbtxt  Defect-Stringing.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Try loading the TFRecord\n",
        "raw_dataset = tf.data.TFRecordDataset(\"/content/train/Defect-Stringing.tfrecord\")\n",
        "for record in raw_dataset.take(1):\n",
        "    print(record)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcUonbSrqLq6",
        "outputId": "711eebf4-dd3c-4c6e-f024-7388b1604459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'\\n\\xd3\\x93\\x02\\n\\xd8\\x90\\x02\\n\\rimage/encoded\\x12\\xc5\\x90\\x02\\n\\xc1\\x90\\x02\\n\\xbd\\x90\\x02\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x08\\x06\\x06\\x07\\x06\\x05\\x08\\x07\\x07\\x07\\t\\t\\x08\\n\\x0c\\x14\\r\\x0c\\x0b\\x0b\\x0c\\x19\\x12\\x13\\x0f\\x14\\x1d\\x1a\\x1f\\x1e\\x1d\\x1a\\x1c\\x1c $.\\' \",#\\x1c\\x1c(7),01444\\x1f\\'9=82<.342\\xff\\xdb\\x00C\\x01\\t\\t\\t\\x0c\\x0b\\x0c\\x18\\r\\r\\x182!\\x1c!22222222222222222222222222222222222222222222222222\\xff\\xc0\\x00\\x11\\x08\\x02\\x80\\x02\\x80\\x03\\x01\"\\x00\\x02\\x11\\x01\\x03\\x11\\x01\\xff\\xc4\\x00\\x1f\\x00\\x00\\x01\\x05\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\xff\\xc4\\x00\\xb5\\x10\\x00\\x02\\x01\\x03\\x03\\x02\\x04\\x03\\x05\\x05\\x04\\x04\\x00\\x00\\x01}\\x01\\x02\\x03\\x00\\x04\\x11\\x05\\x12!1A\\x06\\x13Qa\\x07\"q\\x142\\x81\\x91\\xa1\\x08#B\\xb1\\xc1\\x15R\\xd1\\xf0$3br\\x82\\t\\n\\x16\\x17\\x18\\x19\\x1a%&\\'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x83\\x84\\x85\\x86\\x87\\x88\\x89\\x8a\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6\\xa7\\xa8\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4\\xc5\\xc6\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe1\\xe2\\xe3\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf1\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9\\xfa\\xff\\xc4\\x00\\x1f\\x01\\x00\\x03\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\xff\\xc4\\x00\\xb5\\x11\\x00\\x02\\x01\\x02\\x04\\x04\\x03\\x04\\x07\\x05\\x04\\x04\\x00\\x01\\x02w\\x00\\x01\\x02\\x03\\x11\\x04\\x05!1\\x06\\x12AQ\\x07aq\\x13\"2\\x81\\x08\\x14B\\x91\\xa1\\xb1\\xc1\\t#3R\\xf0\\x15br\\xd1\\n\\x16$4\\xe1%\\xf1\\x17\\x18\\x19\\x1a&\\'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x82\\x83\\x84\\x85\\x86\\x87\\x88\\x89\\x8a\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6\\xa7\\xa8\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4\\xc5\\xc6\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe2\\xe3\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9\\xfa\\xff\\xda\\x00\\x0c\\x03\\x01\\x00\\x02\\x11\\x03\\x11\\x00?\\x00\\xec<\\xc3\\x9ar\\xc9S\\x1b^:Tf\\x02\\xbd\\xab\\xcd\\xb1\\xea)&L\\xb2T\\xf1\\xcd\\xc0\\xe6\\xa9\\x15aOS\\x8cS\\x1bW5c\\x9a\\xad#\\xe6\\xb1\\x91\\xf9\\xebW!\\x9b\\xd4\\xd3L\\xcaP4A\\xcd-E\\x1b\\xee\\xa9j\\x8c\\x1a\\xb0\\xb4QE1\\x00\\xa5\\xa4\\xa5\\xa0\\x04\\xa2\\x96\\x92\\x80\\x18\\xe34\\xca\\x9a\\xa3a\\x8a@ 8\\xa9\\x94\\xe6\\xa0\\xa7\\xa1\\xe6\\x80&\\xcd-%\\x14\\xc4-!m\\xb4\\xd7\\x90\\n\\xa5=\\xd0N\\xf4\\x0c\\xb2\\xf3\\x85\\x15Rk\\xd5Py\\xac=K[\\x8a\\xd5\\x0b<\\x98\\x15\\xc7\\xea^2\\xde\\x8c\\xb0\\xfef\\x95\\x9b%\\xbb\\x1dN\\xab\\xafCn\\ty\\x00\\x03\\xaf5\\xc4j^2g$Bp\\xa3\\xa9\\xf5\\xfaW5\\x7f\\xa8M\\xa8Hr\\xcd\\x83\\xd6\\xb3g\\x85\\x960\\xa2\\xb5\\x8c\\x12\\xd4\\x9b\\xb2\\xe5\\xce\\xad=\\xfc\\xc4\\xb3\\xb1S\\xd8\\xd7=\\xab \\x8er\\x07z\\xd9\\xb4\\x80\\x05\\xdd\\xfa\\xd6\\x16\\xa8sx\\xc3>\\xf8\\xad\\xa3m\\x85\\xd0\\xa7\\x8f\\x974\\xd3\\xd6\\x97<R}i\\x92\\x19\\xe6\\x94zS@\\xe6\\x94\\xd0\\x01\\x9fQH:\\xf4\\xa5\\x1d)\\t\\xc7~h\\x00#&\\x9d\\xd8\\x1ah\\xe4R\\xe7\\x18 P4;8\\x07\\xde\\xa39\\xe7\\xd2\\xa4f\\xdcA\\xc0\\x02\\x93h\\xc1$q@\\rXwD\\xd2\\x06\\x1cv\\xa6\\x03\\x84*F}*H\\xa7x\\xa1\\x960\\x17k\\x8c\\x1c\\xaeH\\xfaT@q\\x93@\\x89\\xa0\\x99bG]\\x80\\x96\\x18\\x078\\xc5Bz\\xf2hr\\x0fO\\xca\\x9f\\x04^k\\xe1\\x88\\x1fZ\\x00`\\xf9\\xbaR\\x1c\\x8c\\xe7\\xadH\\xeb\\xb2B\\x8b\\x82=A\\xa6\\xed\\xc8\\xa0\\x06\\xaes\\xc5<1O\\xbapi\\x17\\xe5\\xe9H\\xdf7Z\\x00\\x18\\xe7$\\xf54\\xc21\\xc9\\xa5\\xc1\\xfc\\xa9\\xdfZ\\x009+\\x8e\\xd4\\x8b\\xc0\\xc5\\x01\\x884\\x84\\xf3\\x8a\\x00\\x0bd\\xd2\\x83\\x93\\xc5#P8\\x14\\x01;\\\\1]\\xb8\\x00\\x1a\\x88\\x02\\x05&sK\\x9e9\\xa1\\x80\\x83\\xf9\\xd3\\x98\\xf4\\xa5\\x03\\x8e)\\x0f\\xad\\x006\\x9c\\xac\\x03d\\xf4\\xa1\\xc0\\xc7\\x14\\xd1\\xc7\\xd6\\x80,\\xda<q\\\\\\x07e,\\x9d\\x08\\xa9o\\xf5+\\x8b\\xd9\\x93\\xcd\\x99\\xa4X\\xc6\\xd4\\xdcz\\n\\x86\\x08\\xfc\\xc5\\xed\\x8a\\x87a\\xcb\\x0fJv\\x04\\xec{7\\xc1R\\x1bF\\xd6\\x87\\x01\\x83/\\xe3\\xc1\\xac\\x88\\x90\\x19f\\xc9\\xfe3\\x8f\\xce\\xb5\\xbe\\x0c@\\x0f\\x875\\x99C|\\xfe`S\\xf8/\\xff\\x00^\\xb2m\\xb8iG}\\xe7\\xf9\\xd1_\\xf8h\\xda\\x9e\\xef\\xe4K\\xb4\\x9c\\x93\\xd8b\\xaa\\xde\\xe5\\xe3H\\xd7\\x92H\\x00\\x0e\\xa4\\x9e\\xd5|7\\xeb^\\x89\\xe0=\\x0e\\xc1t\\xe8\\xb5W\\x80=\\xe3\\x16\\xc3\\xbf;0H\\xf9Go\\xadq=OG\\t\\x8a\\xfa\\xb4\\xddO#\\x94\\xf0\\xc7\\xc3\\x1b\\x9d@\\x0b\\xadh\\xc9knyX\\x80\\xfd\\xe3\\xff\\x00\\x80\\xafE\\x02\\xcfF\\x82=7K\\xb6\\x8e2\\xa3\\xa0\\x1c(\\xf5c\\xdc\\xd4\\xd7\\xfa\\xa1\\x0e\\xd6\\xf6\\xa44\\xa0|\\xef\\xd9?\\xfa\\xf5\\x1e\\x93\\xa6\\xa4\\xe5\\xa5\\x95\\x88\\xb7C\\xbaI\\x18\\xf2\\xde\\xb5\\xbd*7\\xd6FX\\x8cMJ\\xcf\\x9a\\xa3\\xf9\\x13A\\x9bH\\x06\\xa1(/!%-\\xd4\\xf5,\\x7f\\x8a\\xb8\\x1f\\x18\\xea7\\xbcZ\\xc3)A\\'\\xfa\\xd9\\x01\\xf9\\x98\\x9e\\xbc\\xf6\\xafD\\x92Sv\\xc6\\xed\\x97l`m\\x81\\x08\\xe8\\xbe\\xbfS^e\\xe2\\xe9\\x91o\\xd5G\\'\\xa9\\xaa\\xabY\\xafv\\'#\\xd7Vg\\xe9\\xf6\\x81d\\x8d\\x0f$\\x91\\x92k\\xd4\\x9f\\xcb\\x1aj\\xb6~\\xea\\x01^[krL\\xb0\\xec\\x1c\\xe4d\\xd7\\xa7M\\x1et\\xe5\\xe3\\x96A\\xc5U\\x1d\\x88g\\x80x\\xd6\\xe0\\xcb\\xa8LG\\xa9\\xe6\\xb0t\\xddx\\xc1 \\x86\\xe0\\x92\\x9d7w\\x15\\xd0\\xf8\\xda!\\x15\\xe4\\xdc\\xf3\\xbb\\x1cW\\x05$.K\\x1ar\\xb3fi\\xd8\\xef\\xe4\\x92+\\x9but \\xa3t\"\\xb9\\xeb\\xfbE,\\xd8\\\\\\xd6M\\x8e\\xa1sa\\xb9C\\x16\\x8c\\xf5C[I}\\x1d\\xd2\\xe4\\x1e}*\\x1a\\xb1M\\xdc\\xe7\\xa7\\x81\\x91\\xb8\\xe9Q\\x0e\\xb5\\xbd5\\xb0nGJ\\xcd\\x9a\\xd3i\\xc84\\xd4\\x84\\xe2D\\x84b\\xa4V\\xcd@\\x14\\xaf\\x14\\xf0\\xd88\\xefZ\\\\\\x92L\\xfc\\xd9\\xef]\\x97\\x81\\x94\\xfd\\xa8\\x128\\xae1r\\xcc\\x00\\xae\\xeb\\xc1\\x08V\\xe0\\x03S\"\\xa2{\\xce\\xc1A\\x88\\x1e\\xd5].\\x81\\xab)(\"\\xb8.w8\\xb4F\\xd0\\x03\\xda\\xab\\xbc89\\xc5hd\\x1ac-0M\\xa3<\\x0c\\x1a\\x95\\x1a\\x9d\"s\\xc5C\\x9c\\x1aF\\xabSB\\t}j\\xe2\\xbf\\x15\\x92\\x92s\\xd6\\xad\\xa4\\xdcu\\xa6\\x99\\x9c\\xe0\\\\/J\\x1a\\xa94\\xe3\\xd6\\x95&\\xdcz\\xd3\\xb9\\x9f%\\x8b\\xe2\\x96\\xa3\\x8d\\xb2*ZfbQKE\\x02\\x12\\x9a\\xcb\\x9au\\x14\\x01\\t\\x184\\xa3\\x8as-6\\x80$\\rL\\x92P\\xa3\\xadD\\xf2m\\x15\\x95\\x7f\\xa8,1\\x96-\\x8cP\\x05\\x8b\\x9b\\xd5@~j\\xe4u\\xcf\\x13Em\\x1b\\x05\\x90\\x17\\xec3X\\x1a\\xe7\\x8c\\x03\\xbb\\xc5l\\xd9\\xc1\\xc6\\xe1\\xd35\\xc6Kq-\\xdc\\x85\\x9c\\x92s\\xebW\\x18_VC\\x93\\xe8[\\xd4\\xb5\\x8b\\xadFfvc\\xb0\\x1e\\x07\\xade\\xeeye\\x19\\xe4\\xd5\\xcd\\x81c\\xc56 \\xbe`\\xe0qZ\\x13bh\\xa1\\x0b\\x8c\\x8ej\\x19\\xd7,Gj\\xb0\\xcf\\x8a\\x8d\\x86\\xe1\\x9a\\x11V\\x1b\\x01P\\x98\\xae[Rc\\xfd\\xa1(+\\xd0\\xe2\\xba`q Z\\xe6\\xf5u\\x03V\\x9cw\\xcf5Q\\xdcMhS\\xa4\\xe0u\\xa7`m\\xc0\\xebI\\x8c\\x8ej\\xc9cG4\\xac\\xc1\\xbbt\\xa4\\x18\\xe9JE\\x02\\x00\\x01\\xa4\\xda;\\xf5\\xa0Ph\\x01z\\x0cRd\\x9e\\x05\\x18\\xc5\\x03 \\xd0\\x03\\x86\\xe3\\xd4S\\xb2v0\\x18\\xc5\\x00\\x8c\\xf2p;\\xd3\\xa4\\x10\\xecfY1\\x8e\\xc7\\xbd\\x03+\\x85\\xc9\\xc09&\\x9a\\xea\\xcay\\x18\\xa9\\xa3\\x8d\\xa4\\xf9\\x94\\xe3\\x03\\xadFNI\\xdcM\\x02\\x1b\\xd6\\x95X\\xe0\\xf3I\\x9e\\xd8\\xa74\\x0e\\x88\\x1d\\x81\\xdaz\\x1a\\x061N\\xdc\\x9e\\xf4\\xec\\x93\\xda\\x95\\x13vA8 f\\x9a\\t\\xe9@\\x87\\x05 \\x13\\x8an9\\xa9\\x10\\x95\\x07\\xde\\x9a\\xc3\\xb9\\xa0\\x04#\\xbfjR\\xc0\\x801I\\x9c\\x0cSs\\xd6\\x98\\x07z\\x08\\xe34\\x1c\\x8a\\\\\\xfc\\xbd)\\x00\\x01\\x9cSH\\xc0\\xa7c\\x8eh>\\xf4\\x00u\\x1cRv\\xe6\\x9c\\x8f\\xb0\\x9c\\x80A\\x18\\xa6\\xb1\\xe7\\x8e\\x94\\x00\\xaax\\xa5\\x14\\x80\\x1e\\xf4\\xf58\\xa0Cr\\x0f\\xd6\\x820);\\x9a\\x19\\x8bsB\\x18\\x07e\\xf9A\\xe0\\x9e\\x94\\xaa\\xcc\\xad\\xb8\\xf3\\x91\\x83LQ\\x97\\x15vX\\x81\\xb5\\xf3P|\\xb9\\xc50=\\x7f\\xe0\\xcc_\\xf1L\\xeb\\x13)9iv0\\xff\\x00\\x80\\xe4\\x1f\\xd6\\xb2\"\\x8fd\\xd2g\\xfb\\xc7\\xa5i\\xfc\\x1c\\x93\\x1e\\x14\\xd6FJ\\xe6P\\x7f\\xf1\\xda\\xca\\xb0\\xe4\\xb8c\\x9eO4\\xab\\xfc\\x08\\xda\\x9e\\xef\\xe4O(;2;W{\\xe1mBC\\xe1\\x88-\\xa3\\xca\\xf2\\xdb\\x98u9c\\xd2\\xb8F\\xe4\\x11\\xeb[^\\x1a\\xbf\\xb9\\x83N\\x08\\x8b\\xb4#\\xb6\\xd7\\xeaz\\xf6\\xa8\\xc3\\xc1NZ\\x9aJJ*\\xec\\xf4;\\x0b\\x12\\xed\\xe58\\x11\\xc6\\x06\\xe7\\xcf\\x07\\x1e\\xa6\\xb4\\x0c\\x8b\\x7f\\x12E\\x00)\\xa7\\xa1\\xe3\\x8c\\x19\\x88\\xef\\xfe\\xef\\xf3\\xac\\xcd\"\\xde\\xf6\\xea\\xdf7\\x83\\xcb\\xb7s\\xb8\\xc6~\\xf4\\xa7\\xd5\\xcf\\xa7\\xb5n\\x00\\x14`\\x00\\x00\\xec*\\xebT\\xe5\\xf7bg~mY\\x1c\\xe0y\\x0c=\\xab\\xcb<S\\x007\\xe0\\x9e\\xf5\\xea\\x93\\x9cD\\xd5\\xe5\\xde,r/\\x86\\x06\\x05q=\\xc6\\x8a\\xba|\\x08\\xb7Q\\x03\\x8c\\x12\\x05ze\\xcc\\x8a\\x9aq\\xe3\\x95\\\\b\\xbc\\xba\\xcd\\xa4ia r\\x18W\\xa8\\\\\\xa1m=F9(2\\x7f\\n\\xec\\xa3\\xb1,\\xf9\\xf3\\xc5{\\xae5IK\\x8f\\xe2\\xe9\\\\\\xf9\\xb4\\x18<v\\xae\\x9f\\xc6\\x0f\\x1d\\xbe\\xa3.?\\xbeA\\xaea\\xb5(\\x82c\\x078\\xa6\\xf73V+Ij\\xac\\x0f\\x15\\x02\\xc4bm\\xcaH\\xc5Z\\xfbtN\\x08\\xa43F\\xcbE\\x80\\xb1kr\\x18mq\\xcdK:#!#\\xade<\\xc8\\xbft\\xfeT\\xd5\\xd4\\x08\\x18c\\x91Y\\xb8\\xeah\\xa4\\xac$\\xe8\\x03\\x1cUr\\xa7vO\\xe7S\\x99\\x84\\xef\\x81V\\x04Co5w\\xb1\\x9d\\xae\\x16p\\xf7>\\xb5\\xdcxB0.X\\x81\\x8a\\xe2\\xbc\\xe5\\x81:W]\\xe0y\\xc4\\xf3\\xb1\\xe7\\x8aW\\xb9H\\xf4\\x8bm]X\\x81\\xba\\xb5\\xa1\\xbf\\x07\\x1f5y|wRG0!\\x8dmY\\xea\\xce0\\x1b\\xd6\\xbc\\xcev\\x8f\\xa8\\xa9\\x81M]\\x1e\\x89\\x1d\\xd8#\\xadL\\xb7\\x00\\xf1\\x9a\\xe4!\\xd5A\\x03\\xe6\\xab\\xb1jk\\x9f\\xbdT\\xa7s\\x82XY.\\x87F\\xcc\\rS\\x98\\xe2\\xabG~\\xac>\\xf5\\x13N\\n\\x92\\r\\x0eD\\xc2\\x9bLx\\xb8\\xc7z\\x91n\\xc0\\x1c\\x9a\\xc3\\xb8\\xb9\\xd8O5\\x02\\xdfg\\x8c\\xd4)\\x9do\\ruszK\\xcc\\xb6\\x01\\xabV\\x93n\\xef\\\\\\xdcr<\\xae9\\xe2\\xb7\\xf4\\xf4 \\n\\xd6\\x0e\\xe7\\rx(\\x9b\\xf6\\xe4\\x90*\\xcdW\\xb7\\x1c\\n\\xb1Z\\xa3\\x81\\x85-\\x14P\\x02RR\\xd2P\\x00EA+\\x05\\x153\\x1c\\x02k.\\xfe\\xe4\"1\\xce1J\\xe0U\\xbe\\xbe\\x11)$\\xd7\\x99\\xf8\\xab\\xc4\\xaf#5\\xb4\\x0f\\xd7\\xa9\\x1e\\x95g\\xc5>\"\\'|\\x10?\\xcc85\\xc5\\x85i\\\\\\xc8\\xfc\\x9e\\xb5\\xa4\\x16\\xb7fnW\\xd1\\x10\\xec-\\xd7\\xa99&\\xad\\xc2\\x81\\x17$T.v\\x8aF\\xb8!q\\x9a\\xb6\\xc1\"yXc\\x15Id+.{SL\\xc4\\x93\\xcdD\\\\\\x93J\\xe3\\xb1bI\\xc95=\\xac\\xbb\\xf8j\\xa0\\x1bq\\xa9Q\\x9a3\\xf2\\xd4\\xa7b\\xecOr\\xc2+\\x88\\xf9\\xee+\\x9e\\xd5\\xc9m^rp\\x00=\\xbe\\x95\\xa5+<\\x92\\x87 \\x93\\x9c\\xd6F\\xa4\\xc0\\xdf\\xcczsZGVD\\xb6!<\\x0e\\xb4\\xde\\xd4\\xd2\\xe0\\xd0$\\\\\\xf5\\xadL\\xc7\\x0f\\xa5\\x1c\\x92i\\xbb\\xbdiw{\\xd0 >\\xd4s\\x91H\\x1b\\x9e)I\\x1d\\xa9\\x00\\x1e\\xb4\\xdc\\xd0\\xc7\\xa0\\xf5\\xa5\\xc2\\xe3\\xbd0\\x10\\x90G42\\xa8Pw\\x03\\xedF\\t\\\\\\xf6\\xa0\\x01\\xc6{\\xd0\\x02\\xab\\xb2\\xa9\\n\\xc4\\x0e\\xfe\\xf4\\xcc\\x0e\\xa4\\xd3\\xce7dt\\xa6\\x9a\\x060\\x9e@\\xady\\xddN\\x83\\n\\xe0n\\xdey\\xfc\\xeb)H\\x03\\xa74\\xf0\\xee\\xf1\\xec\\xc9\\xc0\\xedE\\x84>\\xd1\\x0c\\x93`\\xe3\\x18\\xa8\\xe4]\\xb2\\x10=iP\\xbck\\x91\\xde\\x82w\\x1c\\xd0\\x02\\x06\\xda1\\xcd\\x19\\xdd\\x8c\\xf4\\xa6\\x9e\\xb9\\xefFpG\\xa5\\x00)\\x00\\x1e\\xb4c+\\x90)\\xe0\\x8c\\x10E5$\\xd8\\xcc1\\xc1\\xa0\\x06\\xe7\\xd6\\x94\\x91\\x8aR\\x01\\xe9\\xd4\\xd4\\xdfcsg\\xf6\\x81\\xcan\\xda}\\x8d\\x00V\\xceiG$\\xd3s\\x83\\x8aPNh\\x00`A\\xa4\\xed\\xcd8\\xb1#\\x14\\xc2)\\x80\\xe1\\xefN\\x07\\xb8\\xa6\\x8e\\x94\\x7f\\r!\\x0b\\x9fj_\\xe1\\xa0\\x00\\x0f4\\x1e\\xa4P\\x03G\\xde\\x06\\xb4#\\x98\\x7ff2\\x11\\xc8b=\\xaa\\x81\\x19\\xa5B\\xe02\\x068<\\xe2\\x9a\\x19\\xeb\\x9f\\x08\\x94?\\x86\\xf5\\xa0O\\x1b\\x80\\xc7\\xfc\\x04\\xd5\\r=3\\x13`\\x9c\\x82kC\\xe0\\xf0?\\xf0\\x8eky\\x1d\\\\\\x0f\\xfct\\xd6v\\x9eZ!\\x9f\\xf6\\x8eh\\xad\\xa4\\x11\\xb5?\\x89\\x96\\xf3\\x9c\\xd7\\xa5\\xf8\\x13K\\xb3]\\x02+\\x93\\x10yY\\xd9\\x89npw\\x1e\\x95\\xe6\\x83\\x87>\\x9e\\x95\\xe9\\x9f\\x0f\\xa72h2G\\xff\\x00<\\xe7`?\\x1c\\x1f\\xeb\\\\\\xb7kcI-\\x0e\\xba\\x92\\x96\\x92\\xa4\\x829\\xbf\\xd57\\xd2\\xbc\\xd7\\xc5\\x08\\xbfjRG9\\xafJ\\xb8\\xff\\x00R\\xd5\\xe5\\x9e-\\xf3Z\\xf8c\\xb7\\xa7z\\x97\\xb8\\x11\\xd8\\x95[\\xd8rx,+\\xd1ofq\\xa70\\x03\\x9d\\xbc\\x1a\\xf3\\x0b\\x18\\xe4k\\x98U\\xb3\\xb80\\xafO\\xbc\\x8c\\x8b\\x1c1\\xe0\\'\\xf4\\xae\\xca;\\x10\\xcf\\x9e\\xbc[\\x1b5\\xec\\x8eI?1\\xcdqr\\x0c1\\xfa\\xd7m\\xe39\\x80\\xbd\\x91\\x13\\xfb\\xd5\\xccCa-\\xc2\\x87\\t\\xc1\\xa6\\xde\\xa6fj\\x03\\x91S1\\xda\\xb5-\\xcd\\x9c\\xb6\\xe7%H\\x1d\\xaa\\x16\\xff\\x00W\\xee*\\x90\\x15\\xd9\\xb9\\xa8\\xf3V#\\xb7y\\xce\\x11\\t>\\xd4\\xc9\\xed\\x9e\\x03\\xf3\\x02>\\xa2\\xa6\\xfa\\x88\\x96\\xc5<\\xc9M^\\xb8\\x98E\\xc7\\x19\\xf5\\xaa\\xfah\\xe1\\xbdi\\xd7\\x104\\xb2b\\xa1\\xeeW@w\\x12\\xc4\\x0e;Wc\\xe0\\x00\\x15\\xa4>\\xe2\\xb8\\xcf(\\xc7\\x16\\x0fj\\xec\\xfc\\x080\\\\\\xf4\\x19\\xa6R4|\\xbc\\x9c\\x8a\\x9d~QI\\x08\\x0e\\xa2\\xa6d\\xc0\\xaf\"j\\xce\\xc7\\xdcQ\\xa8\\xaaA4Bn$N\\x86\\x955)\\x13\\x1f5E(\\xdb\\xcdgJ\\xd8n)#IE[S\\xa7\\xb5\\xd6\\x9c\\x10\\rj.\\xad\\x94\\xe4\\xd7#j\\x0f\\x07\\x15w\\xcc\\xdaqC\\xb9\\x84\\xa9A\\xbb\\x9a\\xb77\\xbea8<TpH]\\xfa\\xd5\\x10wsW-Tn\\x07\\xd2\\x97QM%\\x1d\\x0e\\x8e\\xc1A#5\\xd2\\xd9\\xa8\\x18\\xaewO##\\x9e\\xd5\\xd0[\\xb8P9\\xae\\x9ag\\xcf\\xe2n\\xe4l\\xc4p\\x05M\\xbcVr\\xce\\x08\\xe0\\xd4\\xab0\\xf5\\xadQ\\xc0\\xd1t5.j\\xb2\\xcbO\\x12dS\\x04Jh\\xa6\\x07\\xa6\\xbc\\x98\\x14\\x87b+\\x99B)\\xae\\x07\\xc5\\xfa\\xf7\\xd8\\xed\\x1c#|\\xed\\xc0\\xae\\x93Y\\xd4\\x16\\xde\\x07b\\xd8\\x00W\\x8ck:\\x94\\x9a\\xa6\\xa0\\xf2\\x926)!ET#\\xcd\\xb93v\\xd0\\xa6\\xcc\\xf2\\xbe\\xf9\\x1b%\\x8eN}\\xeaM\\xe1W\\x15U\\xe4\\xda@\\xcd0\\xcb\\x9e\\xf5\\xa3\\x95\\x88Ht\\xd2\\x13\\xc5C\\xcd8\\xe4\\x8c\\xd3EKw4H\\x15psMq\\xcdXH\\xd9\\xf1\\x85\\xe0\\xfaV\\x9d\\x9e\\x8b4\\xff\\x00yH\\x04\\xfe5*I\\x15c\"(\\xd9\\xf8\\x02\\xb5\\xec\\xf4i\\xa7 \\xed }:\\xd7O\\xa6xd\\x06\\x05\\xa3\\xcb}+\\xad\\xb2\\xd0\\xe3@\\xb8^G\\xb5Cw\\x0b\\x9cU\\x97\\x85\\x01\\xc1e\\xcf\\xb5y.\\xa8\\x86-R\\xee3\\x90RF\\\\\\x1fc\\x8a\\xfa\\xa6\\xdfMU\\x1d+\\xc0>)x}\\xb4O\\x16\\xcf*\\x83\\xe4^~\\xf9s\\xd8\\x9e\\xa3\\xf3\\xfeu\\xb5\\x17gfg%s\\x89\\xcd c\\x9e\\xb4\\xdc\\xd2\\xf1]&#\\xcb\\xe0\\xd3\\xa3\\x06W\\x08\\x9dMC\\x9arH\\xd1>\\xe48j,\\x03\\x83\\x95l\\x1f\\xc6\\x95\\xdc\\x1e\\x01\\xa8\\xfb\\xe5\\x8d#\\x1c\\x8eh\\xb0\\x87\\x896\\xe3\\xbd/\\x9aME\\x8e(\\x07\\x14X\\t\\x8b\\x95\\x1c\\x1c\\xe7\\xb5!\\x99\\x88\\xc15\\x16h\\xa2\\xc3&\\x12\\x81\\xd4R\\xf9\\x9cU~\\xb4\\xb9#\\x14X.K\\xe6g\\x8cR\\x87 \\xd4JpsJ_ \\x9cQ`&\\x12\\x1e\\x99\\xe2\\x94\\xbe2\\t\\xaa\\xd9\\xa5\\xdd\\xd2\\x8b\\x01>iI\\xe0\\x02*!\\xf3\\x1cf\\x98Y\\xb7ry\\xa5`-!\\x1b\\x80c\\x80{\\xd2\\xc8\\x141\\xc1\\xc8\\x15T14\\xec\\x93E\\x81\\x13\\x86\\xe7\\x9ap\\x95\\x86\\xe5\\x04\\x85n\\xa3<\\x1a\\xab\\x93\\x9cf\\x9c\\t\\x034\\xec\\x04\\xf8R\\x84\\x03\\xcd4\\x8ex\\xa8D\\x84}i\\x1aC\\x9aV\\x02j^\\xb8\\x15\\x16\\xfc\\x8ax|s\\xde\\x98\\x0e\\xcf\\xbd\\x03\\x04Ta\\xfa\\xe6\\x95\\\\\\x02}(\\x02ER\\xc7\\x03\\xad\\x01\\x0epi\\xf18W\\x0c0qO\\x98nO11\\x83\\xe9H\\x08q\\x82s\\xd4R+`\\xfb\\xd3Kd\\x03\\xde\\x82\\xc3\\x1e\\xf5@{_\\xc2\"\\xaf\\xe1-[\\x8c7\\x98y\\x1f\\xee\\xd6%\\x9f\\xdcq\\x8eA=j\\xf7\\xc2K\\xd4\\x83\\xc3:\\xd2\\x922\\x8f\\xbfo\\xb6\\xdf\\xfe\\xb5U\\xb3u\\x92\\x12\\xf8\\xeaI\\xa5]\\xfb\\x88\\xda\\x9e\\xec\\x91A \\x9e\\xf5\\xe8\\xdf\\x0e\\x0et\\xeb\\xcc\\x7f\\xcfo\\xe8+\\xce\\xc6T\\x91\\xda\\xbd\\x1b\\xe1\\xd6\\x0e\\x99w\\x8f\\xf9\\xef\\xff\\x00\\xb2\\x8a\\xe35\\x96\\xc7iIJi)\\x19\\x91\\xceq\\x13W\\x9ax\\x99\\xd5oFO5\\xe9W<\\xc2\\xd5\\xe5\\xde&\\x89\\xa4\\xbf\\xcfOJM\\xea\\x04VS*_@\\xd8\\xe3p\\xcdz&\\xa4[\\xfb9\\xd7\\xb1^\\ry\\xce\\x9d\\x08k\\xd8T\\xff\\x00xW\\xa2\\xea%V\\xc1\\x98\\x9e\\x02\\xd7]\\x1d\\x88}O\\x9f|Oo\\x9b\\xf6\\\\\\x13\\x96\\xc5tZV\\x86\\xad\\x0c#oD\\xcfN\\xf5\\x8b\\xae\\xc8\\xb3\\xebD\\xaf@\\xf5\\xdfh\\xac>\\xc8\\xa4\\x0e@\\xa5=\\xc5\\x04aj\\xbe\\x10\\x8eM5\\xdbn$+\\xb9+\\xc9\\xe5\\x8d\\x92c\\x11_\\x9b8\\xc5}+\\xa8\\xc6\\xafg\\x0b\\x81\\xf2\\x98\\xd4\\x93\\xfc\\xeb\\xe7\\xeb\\xb4C\\xe2w\\x03\\x94\\xf3\\x89\\x1fL\\xf1Zt\\xb92VgE\\xe1\\x8f\\x0f\\x99c2m\\x19$\\x01\\x91M\\xf1~\\x90\\xb0\\xc3#m\\xc69\\xae\\xd3\\xc2\\x91\\xaaY\\xbb\\x10\\x08\\xc8\\xc7\\xb5dx\\xfex~\\xc2Lc\\x0c\\xfc\\x1c\\xd7$\\xae\\xe4\\x99\\xa3\\x8aQ<\\xa6\\xceO-\\xdb\\x1dkoM\\x8cJ\\t \\x12\\xa7\\x9a\\xe6\\x91\\xccr\\x1a\\xd2\\xb1\\xd4L\\x0eNq\\x91\\x83[\\xc9\\x11\\x16\\\\\\xd5Qc\\xe7\\x18\\xae\\x9f\\xc0\\xca|\\xb9\\x0e;\\xe2\\xb8[\\xfb\\xd33`6{\\xd7}\\xe0o\\xf8\\xf4r:dP\\x95\\x90\\xd3\\xd4\\xb9i2\\x80\\x06x\\xabrH\\xa0px\\xac+I\\x0b \\x19\\xab\\xe1\\xcb`zW%jw\\xd4\\xf6r\\xfcg\\'\\xbb!.&\\x18\"\\xa8\\xc6\\x9el\\x9di\\xf3\\xa3\\x1a\\xb1\\xa6A\\xb9\\xf7\\x1e\\xdcW5\\xac\\x8fm\\xd6\\xb9\\xa1mnB\\x8e).\\xa3(x\\xadh\\xa1\\x01\\x01\\xc5R\\xbd*\\x06;\\xd4\\xa4%+\\x95\\xa3l.jT\\xba\\xf2\\xaa%\\xc1Z\\x82~\\x14\\x9c\\xd2\\xeaQ\\xbbg\\xac*0\\xcbb\\xb7-u\\xa5l\\r\\xdf\\xadyl\\xb7\\x8c\\x92\\x90\\r_\\xb0\\xd5\\xb6\\x91\\xcfS\\xeb[\\xa4\\xd1\\xe7\\xd6\\xa5\\t\\xde\\xc7\\xabG\\xa9)\\xefV\\xe2\\xbe\\x07\\xbdy\\xccz\\xb1\\xc0\\xf9\\xabB\\rh\\xe4\\r\\xdcU)3\\xca\\xafK\\x94\\xf4(\\xaeA\\xef\\x9a\\xb2\\xb3dW!g\\xa9\\xef\\x00\\xee\\xad\\x98.\\xf7\\x01\\xcdi{\\x9c\\x88\\xda\\x12\\xf1U\\xaen\\xb6)\\xe6\\xa13as\\x9a\\xc0\\xd75U\\xb4\\xb7vc\\xd0Qa\\xdc\\xe6\\xfck\\xad\\xe0\\x1bX\\x9b,\\xddG\\xa0\\xae\\x08\\x10\\xa3\\x9a\\xb3{xog{\\x879,r>\\x95BG5\\xb2\\xb4U\\x8c\\xf7w#\\x91\\xf2\\xd4\\xe4\\xe7\\x83Q\\x13\\x93\\xefJ\\xacA\\xcfQ\\xde\\xb3f\\x88\\x9cs\\xc5M\\r\\xac\\x92\\xb0\\n\\xa4\\xf3\\x83O\\xb3\\xb77\\x0e\\xa0\\x0e\\xa6\\xbb\\xad\\x17DUQ\\x95\\xe6\\xa1\\xca\\xca\\xe5\\xa5s+H\\xd1\\x1d\\x99K\\xa0\\x15\\xdci\\xfaJ\\x85\\x04\\xafZ\\xbde\\xa6\\xaa\\x006\\x8a\\xdb\\x82\\xd8(\\xe9\\\\\\xb7nW5\\xd1\\xa2\\xa5\\xb6\\x9e\\x17\\x1cV\\x9c6\\xca\\xa3\\x91O\\\\/Jx\\x93\\x8a\\xe8RFN#\\xc2\\xaa\\xf4\\x15\\xe5\\x1f\\x1ct\\xa9n\\xb4{\\x1b\\xf8\\xd7)m#\\t1\\xe8\\xc0`\\xfec\\xf5\\xafT\\xf3*\\x8e\\xb3\\xa7\\xc1\\xac\\xe97\\x16\\x17+\\xba9\\x90\\xa9\\xfc\\xaa\\xe34\\x9d\\xc9q>>e \\xfbR(\\xc1\\xad}wI\\x97E\\xd6.l&\\\\4N@>\\xa3\\xb1\\xfc\\xb1Y\\xc8\\xa395\\xdb\\x17s\\x99\\xab29\\x13\\r\\xf2\\xf3L\\x08\\xd5l(\\'\\x9aqN\\x0e*\\x89)\\x18\\xdf\\x1d8\\xa4\\xda\\xd9\\xe9Z\\x0b\\x18+G\\x94:b\\xaa\\xc2(\\x858\\xa6`\\xd6\\x8f\\x90\\xb9\\xebA\\x81y\\xfaP\\xe238\\x03\\x8eh\\xe4U\\xe1\\x02\\xe7\\xa5!\\x80c4X\\nC\\xe9A<\\xd5\\xcf\\xb3\\x8aCk\\xcf\\x14\\xac\\x05^\\xbd\\xa8\\xe9\\xf4\\xab\\x82\\xdcl$\\x83\\xc5F\\xd1\\x1e\\xc2\\x8b0+df\\x80\\x7f*\\x9b\\xc84ydg\\x8a,\\x04X$\\xf1I\\xdb5\\'\\x96FM.\\xc6\\xdb\\x8d\\xb4X\\x08\\xf8\\xebJ\\xaf\\x86\\x14\\xa66\\xec)\\xa5\\x089\\xc5\\x16\\x02I6\\x95\\xde\\xbc\\x13\\xd4S\\x14\\x9eri\\xb84\\x839\\xa0\\x070\\x03\\x9a3I\\xcfzL\\xe0\\xd2\\x01\\xc3\\xd2\\x9cN)\\x99\\xc5&h\\x01\\xe0\\xe4Rw\\xa4\\xce)3@\\x0f\\xce\\x059dd\\x04g\\x83\\xda\\x98\\x085#\\xa6\\xd0\\x1b<\\x1a\\x06 jL\\xe0\\xf5\\xa6\\xe7&\\x90\\xf54\\x08\\xf4o\\x00\\\\F\\x9a.\\xb1\\x19\\xceB\\x8688\\xeck_KT:j\\x90k\\x8e\\xf0}\\xea\\xdb\\xc1\\xa9D\\xee\\x14K\\x0f\\x04\\xf7#?\\xe3Z\\xfe\\x11\\xd4\\xfe\\xd3\\x0c\\x96\\xf2\\x1f\\x99\\x1f\\x8c\\xfaTV\\xd6\\x08\\xda\\x9e\\xe6\\xf9_C^\\x8b\\xf0\\xe0cM\\xbc\\x19\\x07\\xf7\\xff\\x00\\xfb(\\xaf?t\\xc18\\x1d9\\xaf@\\xf8nCiW\\x8d\\xdf\\xcf\\xe7\\xfe\\xf9\\x15\\xc8l\\xf6;jCKHh3\"\\xb88\\x85\\xab\\xcb\\xbcMp\\xab\\xa9*\\xe7\\xa75\\xea\\x17#\\xf7\\r^[\\xe2h\\x03j;\\x8e=)u\\x02\\x1d>s\\xfd\\xa1o\\x81\\xc6\\xe1^\\x85\\xa9G\\xfe\\x80\\xcb\\x9c\\x82\\xb5\\xc1h\\xf0\\x0f\\xed8\\x01\\xfe\\xf0\\xafB\\xd5\\\\&\\x9d!\\x03\\x90\\xbd+\\xb2\\x8d\\xacK\\xeaxV\\xa9h\\xcd\\xae\\x90\\xb9\\'5\\xd3\\xda\\xdd\\xfd\\x86\\xd8n;@\\x1d\\xeb&\\xcc\\x0b\\xaf\\x12\\xb8\\x93\\xd0\\xe3>\\xb5g\\xc5q5\\xb6\\x9c\\xe5z\\x81\\xc56\\xae\\xc8N\\xca\\xe4\\xba\\x8f\\x8b\\xe6\\x96\\x1f\\xb0[0\\x01\\x81\\x01\\xbb\\x8a\\xe7\\x1b\\xc3\\xa6(E\\xdb\\x00X\\xfc\\xd9\\xaegF\\xbbv\\xd6\\xe0\\x129;\\x89\\x1d{\\xe2\\xbd\\x8a[D\\x97GR\\xb8\\xfb\\xa2\\xae\\xdajJ\\xd7Vs\\xde\\x17\\xd5b\\x87\\xcd\\xb3\\x9d\\xc2\\x9c\\xe5I\\xfeU\\x8f\\xe3\\t\\xc5\\xdb\\x88Q\\x81 \\xe3#\\x9a\\xe5uMBK-^x\\xc9\\xf9A\\xc6Ej\\xe8\\xf8\\xbe\\x912r\\t\\xeak\\x9aQ\\xb6\\xa5\\xf3s+\\x1c\\xbd\\xee\\x9a\\xf6\\xe8I\\x1c\\xd5\\x10\\x8cG\\x02\\xbb\\xef\\x10\\xd9\"\\xaa\\xe3\\xa6+\\x99\\xfb:\\xe0\\x001\\x9a\\xa8\\xce\\xea\\xe4\\xf2\\xd9\\x98D\\x1d\\xdd+\\xd3\\xbc\\x0c?\\xe2^\\xde\\xc6\\xb8[\\x8b`1\\xb5x\\xae\\xf3\\xc1k\\xb6\\xc2L\\xff\\x00{\\xfaU^\\xe3\\x8e\\xe6]\\xac\\x84`g\\x92zV\\x92\\xbe\\xd6\\xc95\\x8d\\x13\\x10\\xf9\\x15\\xa5\\x11-\\x1df\\xd1q\\x93\\x8b\\xba.\\xe0K\\x8c\\x0e\\xb5\\xb1al\\x14\\x01\\x8a\\xc4\\xb4c\\xb8n\\xf5\\xc5u6\\x80`z\\xe2\\xb8\\xea\\xc6\\xc7\\xbd\\x83\\xad\\xcf\\x1dI\\xd8\\x04\\x8c\\x9fj\\xe6\\xaf\\xe7\\xff\\x00I\\xda\\x0f\\xbdo\\xdfL\\x12\\x13\\\\\\x8d\\xcc\\xa0\\xccNy\\xcdb\\x8e\\xeb\\xd9\\x17`\\x9b<\\x1a\\x8a\\xf6`\\x88A\\xf4\\xaab\\xe5c\\x19\\xcf\\xd6\\xb3\\xef\\xef\\x0c\\xd8Q\\xc6z\\x9a\\xb8\\xc1\\xb6a[\\x12\\xa1\\x12\\x8c\\xf7\\x1b\\xe58$\\nH\\xa6\\xd8\\xd8\\x06\\xab2\\xe0\\x9erM1K\\x0e\\xdd\\xeb\\xb3\\x91\\x1eC\\xc4\\xca\\xfa\\x9b1\\xdf\\xb2 \\xe4\\xf1SC\\xab\\xb1\\x99Tz\\xd6!rGZ\\xd9\\xd0\\xf4\\xb6\\xbc\\xb9\\r\\x8c\\x8fzVI\\\\\\xc6\\xa5W#\\xb2\\xd2n\\x9aP\\x84q\\xc5u\\xd6^a\\xc6k/J\\xd2<\\xa5\\x19\\x035\\xd3\\xdb\\xc0\\xaa\\x07\\x15\\x9b\\xd5\\xdd\\x18\\xa6\\xc8\\xa7\\x99\\x92#^o\\xe2\\xcb\\xe9\\xa5\\x94@2T\\x9ek\\xd3n\"R\\xb8\\xaef\\xe3DY\\xa6y\\x198\\xe8*\\xe2)k\\xa2<\\xbaM\\xeb\\x18]\\xa7\\x8fj\\x80\\x93\\xd4\\xd7\\xa1\\xdd\\xe8q\\x85\\xfb\\xa3\\x18\\xf4\\xaeGR\\xd3\\x8c\\x05\\x9c\\x10\\x00\\xec)\\xb9\\\\q\\x8d\\x8c\\x96<\\x8cT\\x96\\xf0\\xb3\\xc8\\xa1Frj5RH\\x1e\\x95\\xd4hzg\\x9c\\xe1\\x8a\\xe7\\x15\\x12\\x92E\\xeek\\xf8{G\\x07k\\x15\\xfaW\\xa1XX\\x04Q\\xc5g\\xe9\\x16+\\x12\\xa8\\x0b\\xc5t\\xd0 E\\xa8\\xb72\\xd4/\\xa8\\xe8\\xa3T\\x15>\\xe1\\x8ae!\\xa8q\\xb1\\xa2\\x90\\xac\\xd4\\xdd\\xf8\\xa6\\x92i\\x875\\x0c\\xa2`\\xfe\\xf4\\xbb\\xbd\\xea\\xbf#\\xa5H\\x1a\\x95\\xc0\\xf2\\x8f\\x8c~\\x1c\\x12C\\x0e\\xb9o\\x18\\xde\\xa4G9\\x1d\\xc7c\\xfe}\\xab\\xc6G^E}e\\xaa\\xe9\\xd0\\xea\\xba]\\xc5\\x8c\\xea\\x1a9\\x90\\xaf\\xd0\\xf65\\xf2\\xde\\xa7\\xa7\\xcb\\xa5jw\\x163\\x8cI\\x04\\x859\\xef\\xef]\\xd8j\\x97\\\\\\xac\\xe7\\xad\\x0e\\xa8\\xac\\xbdsK\\x9c\\xf1H8\\x14\\xa3\\xadv#\\x98\\x91zripi\\xaa9\\xeb\\xc5<\\xf1\\xc6r\\x05R\\x10\\xa1F1\\x9a\\\\c4 \\xf6\\xe2\\x86\\xc0\\x1c\\x1a`3\\x8eF(P\\xb9\\xe6\\x93\\xeb\\xde\\xa5E\\xca\\x93\\x8e{P\\x04d\\x0e\\xd8\\xa5\\xc8^i\\xa7!\\xb1\\xdcS\\x9c\\x8cR\\x01X\\xef?(\\xe3\\xbdE\\xb4\\x06\\xe6\\x9c\\x1bi\\xc04\\xde\\xbd\\xa9\\x80\\xe2\\xcaz\\nf\\x07qF(\\xa0\\x07\\xb2\\xae\\x06(H\\x81\\xa6\\xe3?\\x9dJ\\x87\\x14\\x0cF\\x84/A\\x91Mh\\x97\\xb0\\xebSpO^):\\x1ey\\x15V\\x11\\x01\\xb7\\x1e\\x82\\xa1kp;sW\\x8f\"\\xa1`s\\xedC@Rhq\\xc8\\xa8\\x8ar*\\xe4\\x9cT\\r\\xd7=\\xab;\\x0c\\x84\\xaf\\x14\\xdc\\x11R\\x91I\\xb6\\x8b\\x01\\x19\\xa3\\xb5?\\x14\\x84R\\x01\\x83\"\\x97{m\\xdb\\xda\\x8a1@\\x01\\xc8\\x19\\xa4\\xcf4\\xbc\\xe3\\x14b\\x90\\x1a\\x1aCf\\xedc\\'\\x868\\xae\\x97J\\xb7\\xfe\\xcc\\xd7\" \\xfe\\xeea\\x8c{\\xd7\\x1b\\x0c\\xad\\x04\\xab\"u\\x075\\xd9\\xc7)\\xbe\\xd1-\\xaf\\x00\\xc3\\xc1/\\xcd\\xea\\x06jg\\xb5\\x8d)\\xeevM \\xe7\\xde\\xbd\\x07\\xe1\\xb2l\\xd2.\\xcf\\xad\\xc1\\xff\\x00\\xd0Ey\\xc8P\\xf0D\\xeaA\\x05A\\x04w\\xafG\\xf8s\\x9f\\xec\\x8b\\xa2\\x7f\\xe7\\xb9\\xc7\\xfd\\xf2+\\x91\\xe8t=\\x99\\xdaR\\x12=i\\x928U\\xaa2^\\xaa\\x9c\\x13H\\xcc\\xb3u X\\x1a\\xbc\\x97\\xc5\\x17\\xc7\\xfbX*/\\x02\\xbd\\x0e\\xf2\\xfdZ\\x06\\x01\\x86q^e\\xaabm\\\\\\xb3z\\xf7\\xa6\\x96\\xa2f\\x86\\x97+\\xb5\\xfd\\xab\\xa8\\xe7p\\xcdz.\\xac7\\xd9\\xba\\x81\\x8e+\\x81\\xd2USP\\x87?\\xde\\x15\\xd9\\xea\\xf7\\x7f\\xf1-\\x93o\\r\\xb6\\xba\\xa9l\\'\\xd4\\xf1\\xdf4A\\xe2O\\x91\\xb0\\xc1\\xabk\\xc5lf\\xb0de\\xcf\\x1c\\xfb\\xd7:\\xf18\\xd6ZV\\xe4n\\xeb[:\\xbd\\xd9\\xb8\\xb2\\xc0^v\\xe35w3{\\x1ec\\x02\\x18\\xef\\xa2e\\xc8\\xc3db\\xbd\\x9a\\xde\\xe5\\xdfD\\x89\\xff\\x00\\xbc\\x82\\xbc\\xa2\\xee\\x1f\\xb3M\\xe6\\x1c\\x82\\ru\\x9aw\\x8a\\xad\\xd3I0;|\\xca0\\xa0\\xf5\\xa6%\\xa1\\xc3\\xf8\\xa5\\x00\\xd6e\\xc62Mih3\\x18-\\xc7\\x198\\xac-^\\xec^_\\xc97rj{=DC\\x06;\\x8a\\xcaj\\xea\\xc8p\\xd1\\x9a\\xba\\xae\\xac\\xd7\\x00\\xc6GN3Y&\\xf3f\\x05A%\\xc7\\x9c\\xecs\\xd4\\xe6\\x88\\xad\\xdaS\\x9ejRI\\x0c\\xb0\\xf7\\x0b5\\xb8\\xe3\\xe7\\xf6\\xae\\xd7\\xc2O\\xfe\\x87 \\'\\x9d\\xdd+\\x86\\x96\\x07\\xb6U\\x06\\xbb\\x0f\\tI\\x94\\x93\\xdf\\xa54\\x86\\xb73\\x91y\\xdc>\\xedZ\\x86C\\x8a\\xa9\\x01%q\\xc5JXE\\x8c\\xf4\\xa8\\x1bF\\x8a\\xb9B\\xa4t\\xae\\x92\\xc2\\xe9LK\\xcf=+\\x92Y\\xbc\\xde\\x9cb\\xae[\\xde:!\\x02\\xb3\\xa9\\x1b\\xa3\\xa3\\x0b[\\x92z\\x9a\\xba\\xcd\\xee\\xc58>\\xd5\\xca\\xc9tNN\\x7f^j\\xe6\\xa7r\\xd2 \\xeek.\\x0b9\\xe7a\\xf2\\x1e}\\xab8S\\xeew\\xd7\\xc6v\\x07\\x9d\\x9b\\x8ei\\x89\\x13\\xca@\\x00\\x9c\\xf4\\xae\\x82\\xc7\\xc3\\xd2Hr\\xca\\x7f*\\xe8\\xec<4\\x88\\x14\\x94\\x18\\x1d8\\xadt[\\x1el\\xea\\xb93\\x88\\x8bD\\x9aLq\\xf8\\xd5\\x85\\xf0\\xdc\\x84\\xf2\\x0f\\x1e\\xd5\\xe9\\xd0h\\xb1\\xa0\\x1f\\'\\xd7\\x8a\\xb44\\xa4\\x1f\\xc2(\\xe6fz\\x9eP|9\"\\x91\\xf2\\x9c}+\\xaa\\xf0\\xe5\\x8aY\\xe06=\\xc9\\xae\\xad\\xb4\\xa4?\\xc2+\\x1bV\\xb5kX\\\\\\xa7\\x07\\x1cR\\xf8\\xb4\\x05\\xa1\\xb8\\x9a\\x8d\\xb48\\x1b\\x87J\\x955\\x98\\x0f\\xf1\\x8a\\xf3P\\xf7N~\\xfb\\x1a~\\'\\x8dr\\xac\\xc0\\xfdh\\xe4\\x13\\x99\\xe9\\xbf\\xdaP\\xc8\\xc0n\\x1c\\xd6\\x91\\x8d\\x1a\\xdc\\xfc\\xa3\\xa5y$\\x1a\\x85\\xdcN\\xb9b@l\\xf3^\\x95\\x0e\\xb1nt\\x83+0\\x04FN;\\xe7\\x15\\xa58h5#\\x97\\xd45\\xdb(\\xa7h\\x8br\\x0e\\x0f\\xb5s\\x9a\\x8e\\xdb\\xc8\\xd9\\xa3\\x1dk\\x0fk\\\\\\xeas\\xcd\\xce\\xd6r\\x7fZ\\xec4\\xbd?\\xcd\\x85r8\\xc7J\\xceQ\\xb3.2\\xd0\\xe3-l\\xa5k\\xb0\\x9b;\\xf3^\\x97\\xa0\\xe9\\xeb\\x1cK\\xf2\\xf3\\xebU\\xa2\\xd0\\x95.<\\xcd\\xbczWI\\xa7\\xc1\\xe5\\x01\\xc7\\x02\\xb1\\x9a\\xbbE\\'dj[\\xc6#A\\xc5\\\\G\\xaa\\xab \\xe9O\\x0fT\\xaeCe\\xd5l\\xd3\\xc0\\xcdTY1\\xde\\xac$\\xc0u5V\\xb8\\x93\\x1f\\xb2\\x8f.\\x9c$S\\xde\\x9c\\x1d}j\\\\Q\\\\\\xcc\\x8f\\xcb>\\x94\\xd3\\x1dO\\xbd}E4\\xba\\xfa\\xd4\\xb8\"\\x94\\x88\\x08\"\\xbco\\xe3\\x07\\x86\\xbc\\xa9\\xe1\\xd7\\xa0_\\x95\\xf1\\x14\\xe0v=\\x8d{;:\\xfa\\xd6n\\xb7\\xa5\\xdb\\xeb\\x9aE\\xce\\x9dq\\xf7&B\\xb9\\xee\\xa7\\xb1\\x14G\\xdd\\x95\\xd1WMY\\x9f*\\xe7\\x18\\xa3w9\\xa9\\xf5\\x0b9\\xb4\\xddF\\xe6\\xca\\xe1J\\xcb\\x04\\x85\\x18\\x1fj\\xa8Xs^\\x8a\\xd4\\xe3\\x92\\xb3\\xb1azf\\x9f\\x8e\\xd5\\x1a6W\\x14\\xe2p*\\xc9%GP\\xa7uF\\xc7\\'\\x8e\\x94\\x9fJP\\xdcS\\x01)\\xe5\\xca\\xfd\\xd3L\\x194\\xb9\\x1d(\\x18\\x9d\\xc5\\x0c@\\xe9C\\x10:S[\\x9a`\\x07\\x19\\xe2\\x9c\\xb9#\\xa578\\xa7g\\x91\\x8a@!\\x18\\xfa\\xd2\\x1a|\\x8f\\xbb\\x19\\x15\\x1ex\\xa6!\\xc0\\xe2\\x9c:qMT\\xdep*]\\xa5\\x0e\\x0fZ\\x10\\x08\\x0e)\\xdb\\xb7r)1\\xe9\\xd2\\x94\\n\\xa0\\x1c:TnGZ\\x94)\\xc6GLTn\\x06\\xde*\\xba\\x08\\xab!\\xe4\\xfaTM\\xd2\\xa5\\x938>\\xd5\\x0bqY\\xb1\\xa23J\\xcd\\x81\\x8aCL\\xfa\\xd4\\x8c\\\\\\xe4\\xf1Gji\\xa5\\xedH\\x00u\\xa77\\xb56\\x82h\\x01{R\\x1aZ\\t\\x06\\x80\\x1ak\\xa7\\xf0\\x9d\\xc7\\x98\\x97V\\x0e\\xc3l\\xaaH\\x1e\\xf5\\xcd\\xaa\\xee8\\xad-\\x16\\xe1-/\\x15\\xd9\\xb6\\xb8a\\x8f\\xa5KWEGs\\xb9\\xd0\\'g\\xd3\\xbc\\xa6\\xc8h\\x9c\\xa1\\xcdz\\xdf\\xc3\\xd6\\x03G\\xb8\\xff\\x00\\xae\\xe7\\xf9\\n\\xf1\\xeb\\x1b\\x85\\x8fV\\x9a\\xd4/\\xcb \\xde\\xa7\\xea3^\\xb5\\xe0)\\x08\\xd2gS\\xd4N@\\xfa`W\\rgdu\\xc1_C\\xaa\\xd4\\xae<\\x9br\\xd5\\xe6z\\x8f\\x89\\xe5\\xfbd\\xb1\\x07\\x01T\\xe0Wu\\xafHE\\x93s\\xfc5\\xf3\\xb6\\xb1\\x7f0\\xd5.\\x181\\x18c\\x8aT\\x9f3\\xb1\\x15c\\xcb\\xa9\\xdf\\xcf\\xae\\xce\\xeb\\x9f8\\xfe\\x06\\xb1.\\xf5\\x06\\xf3\\x0b\\xe4\\x96\\'\\x8ek\\x8b\\x1a\\xe5\\xc2\\x1c\\x16\\xe3\\xbei\\xf2kM\\xb7v\\xe5<s]J=L9\\x8fA\\xd3u<\\\\\\xc2\\xcc\\xff\\x000>\\xb5\\xde]\\xdd\\x9b\\x8bc\\x96\\x1bH\\xed\\xde\\xbc\\x06\\xdf\\\\\\x93x<q\\xef\\xd2\\xbd;\\xc3\\x97R\\xde\\xe9\\x8cL\\x9b\\x88\\xec\\x0fJ\\xd6\\x9cu\\x1af]\\xe6\\xd8u\\x06\\xc9\\xca\\xe74\\\\^\\xdb\\x88\\x80\\xdc=\\xeb7\\xc5\\x97r[\\\\\\xecLg\\x1c\\xfb\\x1a\\xe2nu[\\x93\\xd1\\xe9\\xb5\\xa8\\xafckY\\xb8\\x8d\\xd9\\xb6\\x1c\\xff\\x00Z\\xe7\\\\\\xc88\\x19\\xc1\\xa6\\xc1;\\xcd!\\xde\\xc4\\xe6\\xaf<_.}\\xa9lK\\xd4\\xcapy\\xf5\\xa6d\\xf4\\x15rH\\xc0\\x19\\x1dj\\x00\\xbf5\\x02\\xb0\\xebpw\\xd7M\\xa5\\xc6\\xa5Fq\\xd7\\x93\\\\\\xdcyF\\x07\\xde\\xb5\\xa1\\xbe\\x11G\\xceq\\xeczVsW.%\\xbdi\\x020\\xce3\\xfc\\xebS\\xc2Rgx\\xe3>\\xb5\\xc9^\\xdf\\x19\\xd8.N\\x01\\xeek\\xaa\\xf0\\x84g.H\\xe0\\x8a\"\\xac\\x83\\xa9F\\xdd\\xf2\\x01\\xab.<\\xc1\\x9e\\xd5V\\xc2\\xd6YO\\x00\\xe2\\xba{M\\r\\xa5\\x0b\\x95=;\\xd6m\\x96b\\xdaF\\xfb\\x88\\x02\\xb6mt\\xd9e\\xe4\\n\\xe8,|;\\x8c3\\x0e\\xf5\\xd1\\xdbi\\x08\\x8a\\x06\\xd1R\\xe4+3\\x91\\x8f\\xc3\\xa6B22+r\\xcf\\xc3\\xb1\\xc6\\xa3\\xe4\\x1e\\xd5\\xd1\\xc7m\\x1a\\x01\\xc058\\x01G\\x02\\xa2\\xec\\xa3>\\xdfK\\x8e02*\\xeaC\\x1at\\x14\\xf2\\xd4\\x9b\\xa9\\x80\\xeaJaqH\\\\R\\x10\\xfa\\xc8\\xd5\\xa1\\xf3\\xa1e\\xad=\\xf5\\x04\\xea\\x1cSL\\x0eMt\\xfd\\x9dFh6c\\x07\\x8a\\xde{za\\xb6\\xf6\\xaa\\xe6\\x15\\x8eu\\xec2\\xc0\\x85\\xef[\\x91\\xd8\\x13fT\\x8e\\xa2\\xa7\\x16\\x80\\xb0\\xadX\\xe3\\x02\\x0c{U\\xc6v\\x0b\\x1c,\\x1aG\\xef\\x9b+\\xfc\\\\q]^\\x99h\\xb1 \\x1bi\\xc9j\\x03\\x93\\x8e\\xf5~\\x14\\x08+9;\\xb1\\x92yK\\xe9J\\x06:S\\xb3I\\x9cT\\x80\\xb94y\\x8c))\\r\\x008\\xdc\\xb0\\xa6\\x9b\\xa9\\x05FG4\\xd6\\xa0\\tF\\xa2\\xe9\\xd4S\\xbf\\xb5\\xb8\\xe8j\\xab(5\\x11A@\\x16\\xdfY*z\\x1cTgZ\\xf5\\xcdRx\\xfd\\xaa\\xbbF3E\\x86j\\x8dr,|\\xcf\\x83R\\xae\\xb3\\x01<H+\\x9c\\x9e\\x00*\\xa9B(\\xb2\\x15\\xd9C\\xc7~\\x10\\x8b\\xc4\\xd7+\\xa8\\xe9\\x93C\\x1d\\xe9\\x01eWl\\t1\\xd0\\xe7\\xd7\\xb5p\\x0f\\xf0\\xef\\xc4Q0\\x02\\xcd$\\xf7I\\x94\\x8f\\xe7^\\x92\\xdb\\x87 \\xd4mq\"\\xe7\\x0cs[FM+\\x12\\xf5\\xdc\\xf3y<\\x1b\\xaf\\xc3\\xd7K\\x9c\\xf6\\xf9\\x17w\\xf2\\xaa\\xf2\\xf8sY\\x8dI\\x93M\\xba\\\\\\x7f\\xd3#\\xfe\\x15\\xe9\\x82\\xf6uo\\xf5\\x8d\\xf9\\xd5\\x85\\xd4\\xeeG\\xfc\\xb45^\\xd6B\\xb2<u\\xac\\xaf\"$Im2\\xe3\\xd5\\rC\\xf3\\xafU#\\xea1^\\xe7\\x16\\xab;`\\x165hK\\x1c\\xa0\\xf9\\x90\\xc4\\xf9\\xeb\\xb9\\x01\\xa3\\xdby\\rE\\x1e\\x00X\\x8e\\xa0\\xd2o\\xaf\\x7f:v\\x959\\xfd\\xee\\x99f\\xe4\\xfa\\xc0\\xbf\\xe1P\\xb7\\x84\\xbc97\\xde\\xd2-\\xb9\\xfe\\xe8+\\xfc\\xaa\\xbd\\xba\\xec\\x1c\\x87\\x82\\xee\\xc9\\xe4\\xd2\\xeeP\\x0ek\\xdc_\\xe1\\xdf\\x86%\\x07\\x16L\\x99\\xfe\\xec\\x86\\xaa\\xc9\\xf0\\xb7\\xc3\\xeeIF\\xb9L\\xf6\\xdf\\x9f\\xe9MW\\x88r\\x1e0X\\x1aP\\xd5\\xea\\xf3\\xfc!\\xb1`|\\x8dJd\\xff\\x00yA\\xaa\\x13|\\x1e\\xb8\\xe4\\xc3\\xaaF\\xde\\x9b\\xd0\\x8a\\xafm\\x11r\\x1eq\\xb8\\x1aL\\xfb\\xd7o?\\xc2\\x8dz%>T\\xd6\\xd2\\xe3\\xb0|\\x13\\xf9\\xd6d\\xff\\x00\\x0e|O\\t-\\xf6\\x1d\\xe3\\x1f\\xc0\\xc0\\xd3Uc\\xdc\\\\\\x8c\\xe7Q\\x8a\\x9c\\xe6\\x9d\\xe6\\x17l\\xb1\\xad\\t|\\'\\xe2\\x0bq\\xf3\\xe9w#\\x1f\\xec\\x13T\\xa5\\xd2\\xf5(\\x0e%\\xb2\\x9d~\\xa8j\\x94\\xd0r435\"\\x9c\\xd4\\x05&A\\xf3D\\xe3\\xdc\\xa9\\xa7\\xc6X0$\\x10;\\x9a\\xa4\\xd0\\xac\\xcb\\x8a>Q\\xdb\\x8a\\x82A\\x86\\xe9\\xc5X^@\\xf5\\xc56H\\xfeNA\\xcdk\\xd0\\x96Ps\\xc1\\xf4\\xaa\\xcc1V\\xe4\\\\\\x1f\\xf1\\xaa\\xe5{\\x9a\\xcd\\xa0!&\\x9b\\xd6\\x9e@\\xcd3\\x15\\x03\\x1bGj)*@\\\\\\xd1F))\\x80\\xf5\\xa3\\xb9\\xa6\\x8aL\\xd0\\x04\\x80\\xe0\\xe4\\x1e\\x94\\xe7\\x98\\xb4\\xfe`\\x01O^:T9\\xa5\\x07\\x9aLgg\\x1c\\xe3\\xc9\\xd2\\xf5\\x1d\\xc4\\x00|\\xb9\\rz\\xff\\x00\\x82nB\\xda\\xcc\\x9e\\xb2n\\xfd\\x05x\\x86\\x8c\\xdfk\\xd1\\xae\\xed2wF\\x04\\xa8=H\\xeb\\xfaf\\xbd;\\xc1\\xb7\\xe4\\xd9C1\\xc8\\xdf\\x85?Q\\\\\\x18\\xa8\\xb6\\xb4:\\xe8I_S\\xbf\\xd7\\xa4\\xce\\x9a\\xe7\\xaf\\xcb_:\\xeb\\x1cjW\\x1d\\x86\\xe3^\\xf9\\xaa\\xdcn\\xb1#=V\\xbc\\x07X\\xc7\\xf6\\x95\\xc8\\x1c\\xfc\\xe6\\x96\\x14x\\x96aJ~l\\x8a\\x88\\x93\\x8fj\\x92N\\x1e\\xa3n\\x95\\xde\\x8e!\\xd1\\x1f\\x9f\\x15\\xe9\\x9e\\x17\\xb9\\x92+,+\\x15\\xe2\\xbc\\xd2\\x12\\x15\\xc15\\xe8\\x9e\\x1d Yu\\xc9\\xc0\\xad)\\xee4d\\xf8\\x9ef7lX\\xe4\\x9a\\xe4&95\\xd4x\\x90\\x813|\\xdd\\xf3\\\\\\xac\\xa7&\\x94\\xfe!\\x04\\x12\\x18\\xdfwj\\xbc\\xda\\x832\\xf2\\xa3\\xa5g\\xa8\\xcd<\\xd40%k\\x9d\\xdd\\x850I\\xdf\\xa5G\\x8aQ\\xd0S\\xb0\\x12\\x19)\\x0c\\x87\\x04\\x0c\\x80i\\xb8\\xcd(\\x1c\\xd1`\\x00w0\\xae\\xff\\x00\\xc2_42\\x109\\x1c\\x1a\\xe0Ta\\xc1>\\xb5\\xddx8\\x9f-\\xd8\\x8cd\\xd4\\xcbb\\xa2wzg\\x87\\x16 7/\\xe9]\\x14\\x1alq\\x81\\x90*\\xda\\xe1F\\x00\\xc5;5\\xc8\\xdd\\xcdAbD\\x18\\x02\\x9d\\xb8\\xe2\\x9b\\x9aL\\xd2\\x10\\xbb\\xa97\\xd1\\xde\\x8d\\xb9\\xa0\\x04\\xdd\\x9a\\t\\xa3m-\\x002\\x9a\\xd9\\xa91F(\\x020\\r)\\x19\\x14\\xfcRb\\x80\"+I\\xe5\\xd4\\xb8\\xcd\\x18\\xa0\\x06\\x84\\x02\\xa6\\x1fw\\x14\\xdcS\\xc0\\xe2\\x81\\x91\\x85\\xe6\\xa5ZLsJ(\\x10\\xfc\\xd2g\\x14S\\x0es@\\x0f\\xddM&\\x8cqF(\\x01\\t\\xa6\\x1c\\xd4\\x98\\xa6\\x91\\x9a\\x00e1\\xba\\xd4\\xb8\\xa6\\xb0\\xa0\\x08H\\xa8YsVJ\\xd4d{P2\\xa4\\xab\\x9a\\xa7$x\\xad\\'\\\\\\xd5iS=)\\xa03\\xa4^:UI\\x17=\\xabBD\\xaa\\xb2\\xafZkrL\\xe3\\x80iwg\\xa1\\xa5\\x91pi\\xab\\xdcU\\x81,R\\xe0\\xd5\\xc4\\xb9\\xce\\x06k+v\\x1e\\xac[\\xa3\\xca\\xc0 $\\xfbT\\xb43f\\x19\\xc98\\xab\\xf1\\xcd\\x83\\xc9\\xacF\\xf3\\xd0yp(2wc\\xf7V\\x9fmj\\xd1\\x9f2\\xe2y\\'\\x90\\xf7s\\xc0\\xfa\\x0e\\x82\\xb7\\xa7\\x85\\x94\\xfd\\x04\\xe6\\x91\\xb65[\\x14%^\\xf2\\x05#\\x82\\x1a@1SG\\xa8\\xd8\\xc8@[\\xebfoA2\\x93\\xfc\\xeb\\xcf\\xafe\\x93\\xfbRxb\\r b\\x0e\\x10d\\xf4\\xfaT2`\\xc2w\\xc3\\xb4\\x8f\\xef\\xa7?\\xa8\\xad\\x1e\\x0e\\xddHUOSB\\x1c\\r\\x8e\\x1b\\xe8sO*\\xc3\\xaek\\xc6XG\\xbc\\x91\\x1c|\\xf7\\xc0\\x15*\\xdc\\xcf\\x12\\xa8\\x86\\xe2h\\xb1\\xd3\\xcb\\x99\\x87\\xf25/\\x06\\xfa1\\xfbD{\\x08\\xcfzx&\\xbc\\x84kz\\xb4 \\x05\\xd4\\xaf\\x06=gc\\xfc\\xf3S\\xa7\\x8c5\\xd8\\x08\\x1f\\xda.\\xfe\\xcf\\x1cm\\xff\\x00\\xb2\\xd4\\xfdRa\\xed\\x13=g8\\xa62\\xa3\\xfd\\xe4R=\\xc6k\\xcc\\xa3\\xf1\\xfe\\xb4\\x87\\xe66\\x92\\x0f\\xf6\\xa1\\xff\\x00\\x06\\x15i>\"\\xdf\\xaf\\xfa\\xcb\\x1bG\\xff\\x00wz\\xff\\x00SS\\xf5j\\x88|\\xf1;\\xd7\\xb0\\xb2\\x98m\\x92\\xd6\\x16\\x1e\\xe8*\\xb3\\xe8:C\\xf5\\xb0\\x83\\xfe\\xf9\\xaeU>#\\xf4\\xdf\\xa5)\\xf5\\xdbs\\xfe)VS\\xe2%\\x83}\\xfb\\x0b\\x95?\\xec\\xba7\\xf5\\x15>\\xc6\\xaa\\xe8>dG\\xe2\\xef\\x05Y\\\\\\xe8\\x97\\x17\\x1a]\\xb0\\x86\\xf6\\x00eA\\x18\\xff\\x00X\\x07%q\\xf4\\xce=\\xfe\\xb5\\xe4zv\\xa2\\'\\x9cEp\\x8b\\xb4\\x11\\xce{\\xd7\\xb4\\xc3\\xe3\\xdd%\\xdb\\xe6\\x8e\\xee?B\\xc8\\xa7\\xf91\\xaf8\\xd4\\xbc=\\x03\\xf8\\xb8\\xcf\\xa3\\xd9\\xb5\\xde\\x9ftw\\x88\\xc0+\\xe59<\\xae=\\xba\\x8e\\xd85\\xbd5UF\\xcd\\t\\xf2\\xb66\\r\\n-Jq\\x14k\\xb4\\xb3q\\x8a\\xe9d\\xf8Qn\\xf0\\xa6.\\xb6\\xc9\\xb4n\\xc0\\xe35\\xbb\\xe1m\\x19,Y\\xaenUce\\xf9b\\x8c\\x9e\\x9e\\xff\\x00\\xd2\\xbas\"\\x13\\xc3\\x0f\\xce\\xb0\\x95Y\\xad\\nv\\xbe\\x87\\x94]|%\\xb8\\nL7J\\xc7\\xb6Ed\\xdc|.\\xd5\\xd0~\\xec\\xa3W\\xb5\\x96\\xe3\\x83@n\\xf4*\\xb2\\x15\\x8f\\x00\\x9b\\xc0Z\\xf49\\x06\\xd0\\xb7\\xb85\\x95&\\x81\\xaaC1\\x8aK)\\x83\\x8e1\\xb0\\xd7\\xd2\\xdb\\xbdE1\\xa1\\x82F\\xcb\\xc4\\x8c}H\\xa5\\xed\\x984\\x8f\\x99\\x9fH\\xbfNZ\\xd2a\\x8fT5]\\xad\\xe5^\\xb18\\xfc+\\xe9\\xf3ijF\\x0c\\x08\\x7f\\n\\xaf&\\x85\\xa5\\xcd\\xf7\\xec\\xe3?\\x85?m\\xe4\\x1c\\xa8\\xf9\\x93\\x04v\\xa4\\xc5}\\x11s\\xe0]\\x12\\xe5\\x8b\\x1be\\\\\\xfa\\n\\xc6\\xba\\xf8Y\\xa5L\\xe4\\xc5\\x98\\xf3\\xe8j\\x95dO)\\xe24\\x87\\x8a\\xf5\\x8b\\x8f\\x84`1\\xf2n\\x1b\\x1e\\xf8\\xaa\\xb2|)\\x9dm\\xf0$\\xfd\\xe0=q\\xda\\xadU\\x8b\\x0eS\\x85\\xd0nM\\xb6\\xa2\\x9c\\xf0x#\\xd6\\xbd\\xce\\xdfO\\x8b\\xfb\\x12\\xc2KT\\x08\\xa5\\x03`z\\xf7\\xaf6\\xff\\x00\\x85m\\xaa[\\xdc\\xa9B\\x08\\x1dOz\\xf6\\r\"\\xd8\\xd9\\xe8\\xf6\\xb6\\xd2r\\xd1\\xc6\\x14\\xd65y[L\\xb8\\xab\"\\xbd\\xecO%\\x90\\x03\\xba\\xe0\\xd7\\x9c_xI\\xee.$\\x94\\x06\\x05\\x8fj\\xf5\\x93\\xb4\\xae\\xdc\\x0czT~D?\\xdd\\x15\\x92\\xd3a\\xcb\\xde\\xdc\\xf0\\xfb\\xdf\\x05O\\x1e\\xe9\\x17;}\\x08\\xe6\\xb9\\xf9\\xf4\\x89\\xa1;]\\x08?J\\xfa\\x16\\xf6\\xd6\\xdd\\xe1?(\\xc8\\xe9\\\\u\\xf6\\x99n\\xf36G=3Z\\xc2o\\xa9\\x0e=\\x8f\\'\\x83N\\x9c\\xc8>Q\\x8e\\xbc\\xd7u\\xa3[\\xcbme\\x87R=+f\\xcfC\\xb63\\x0c\\xa8\\xfc\\xb1[\\x13i\\xd1CnB\\x81\\x8a\\xe8\\x84\\xd2\\x05\\x03\\xca\\xb5\\xe5\\x7f=\\xc1^y\\xaenT+\\xd4W\\xa0j\\xda\\x7f\\x9bpzc>\\xb5\\x89q\\xa46z\\x0c{Rr\\xd4\\x8bX\\xe7\\xa3\\x88\\xec\\x07\\x185\\x1bg5\\xd1\\x9d8,{v\\xfe5E\\xb4\\xd6g\\xe0S\\xb8X\\xc9\\xefJ+M\\xb4\\xb7\\x03\\xa5\\'\\xf6k\\x0e\\xdd=h\\xb8\\x8a {R\\x9e*\\xdf\\xd8\\x9f\\xb8\\xe2\\x83f\\xde\\x94\\xd3@S_\\xbe\\x07l\\xd7q\\xe1.<\\xc0\\x0f\\x03\\x15\\xc9\\xc7d\\xe6`0z\\xd7_\\xe1\\xc8\\xde#\"\\xf2:`c\\xadL\\x99qG\\xb2\\x06\\xa5\\x06\\xa2\\x19\\xcdJ+\\x8c\\xb1ii)h\\x00\\xa5\\xcd\\x14\\x94\\x00\\xb9\\xa4\\xa4\\x06\\x90\\x9a\\x00Z)\\x074\\xe1@\\x05\\x1d\\xa8\"\\x9c\\x05\\x000\\nv\\xdau:\\x80\\x19\\x8ei\\xc0R\\xe2\\x8cP\\x02b\\x80)h\\xa6\\x02b\\x8cS\\xbbQH\\x04\\xc5.)(\\xa0\\x02\\x9aE8\\xd3M\\x00!\\xa6\\x91N\\xa44\\x00\\xccqQ\\x91Sb\\xa3\"\\x80\"u\\xaa\\xf2/5h\\xd4N\\xb9\\xa0\\n2\\xaej\\x94\\xab\\xcdi:u\\xaa\\xb2\\xc7\\x82j\\x92\\x03*T\\xe0\\xd5o-\\x99\\xb6\\xa8,O\\x00\\x0e\\xf5\\xa8\\xf0\\x80\\x86I\\x18$~\\xa7\\xa9\\xfaT-}\\xe5.\\xdb4\\xf2A\\x1c\\xca\\xdc\\xb9\\xfazV\\xf0\\xa5)\\x12\\xe4\\x90\\xc8\\xb4\\xd8\\xa1;\\xaf\\xa5\\xd8{B\\x9c\\xb9\\xfa\\x8f\\xe1\\xfcj\\xd3\\xdeG\\xe5\\x08\\xa0\\x89a\\x8b\\xba\\x83\\x92~\\xa6\\xb1\\xda\\xe8.py\\xcf>\\xf4\\xd4\\xb8$\\xe7<\\n\\xed\\xa5\\x86KVe)\\x9b\\x02`\\x17\\x8e\\x99\\xa0\\xcb\\xb8\\x8c\\x1a\\xce\\x12\\xfb\\xd4\\xd16Xd\\xd7|b\\x91\\x9bg-\\xa9\\xcd\\xe5\\xebs\\xa9\\'\\x00\\xf6\\xf5\"\\xa4K\\x89\\xc2\\xb6\\x15\\xd9X\\xe0\\x92_\\x8f\\xc8\\xe2\\xa9x\\x81\\x82kS\\x95 \\xe3i\\xe4{\\x03Vm\\xa7\\x92kdq6\\x97\\xbc\\x92\\n\\xbca\\x18}H\\x00V57\\x18\\xe7\\xbe\\xb9b\\xbb\\xa4\\x91\\x8a\\x8c\\x02\\xceO\\xf3\\xa8\\x1eb\\xc4\\xb3\\x0f\\x9b\\xb9\\xc0\\xa2D\\x92\\x07q\\xba\\xda\\\\\\x00\\xd9\\x86`\\xcb\\x8f\\xa8=}\\xa9\\xae\\x1d\\x95N\\xdc\\x06\\xf7\\xcdB\\x01\\x9e`*A_\\xd2\\x9aJ\\xf5\\xdbJ\\xdd\\xc7=3\\xd3\\xaf\\xe9P\\x19@c\\x9e\\x7f\\nw\\x19#\\x05\\xe3\\x03\\x1f\\x8d0\\x84\\xa64\\x98\\xf9\\xb3Q\\x99A\\x19\\x078\\xa1\\xd8D\\xdf(\\xe7&\\x93#\\xae\\xea\\xac\\xd2\\x8fZ\\x8c\\xcf\\x85\\xebJ\\xe8}\\x0b\\xdb\\xf1\\xfcY\\xf6\\xab6\\xba\\xabZ\\x1d\\xca\\xdf0\\xf7\\xac\\x19.\\xc8\\xe8j\\xba\\x1b\\x8b\\xc7\\xf2\\xa1R\\x7f\\xa5K\\x9d\\x81&\\xce\\xb1\\xfcI;\\x10\\x90\\xc8\\xfec\\x1e\\x02\\x93\\x9f\\xc3\\x15\\xd9\\xf8o\\xc3\\xba\\xc5\\xc6\\xcb\\xadV\\xf2x!8\"\\xdcHw0\\xff\\x00k\\xd0{u\\xfaW#\\xe1M\\x16x\\xaf\\xe0\\x95\\x10\\xbc\\xc8\\xd9\\xdf\\x8e\\x16\\xbdp\\xdcH\\xf1\\x80\\xc3\\r\\x8eqYJ2\\xa8\\xec\\x8d\\x13\\xe5)M\\xa3X\\x8e#i\\xd5\\xfb\\x14\\x94\\x82*\\xc4I\\xe5\\xa0]\\xcc\\xd8\\xee\\xc7&\\x94\\x0cR\\xaf,EEzJ\\x14\\xd8FM\\xc8p\\xa5\\xa2\\x96\\xbc\\xd3P\\xa5\\xedH)M\\x00\\x19\\xc5.\\xee+?S\\xbakd\\x8fh\\xce\\xe3\\x8a\\xb7\\x01g\\x85I\\xeaE %\\xdd\\xc5&\\xe3I\\x8a\\x08\\xa60\\xdd\\xcei\\t\\xa3\\xb5\\x14\\x80\\x8d\\x8e*2\\xf53\\xa8\"\\xa1\\xf2\\xe9\\x81V\\xe9\\xcf\\x94k\\x99\\xbc\\x93\\xf7\\x84g\\xbek\\xa6\\xba\\x8f\\xf7d\\x8e\\xd5\\xc9\\xde\\xe7\\xcf9\\x1cUCq2\\xcd\\xa3\\xfe\\xf0f\\xae^K\\x88\\x0f=\\xab2\\xc9\\xb7?\\xd2\\xaf]\\x82\\xd6\\xecEl\\x81\\x1c\\xa5\\xec\\x83q\\'\\xd6\\xa8;\\x83\\x829\\xfa\\xd5\\x8b\\xdf\\xbe\\xff\\x00\\xca\\xa8\\x93\\xc8\\xaa!\\xee+6F* \\x14\\x1c\\xe6\\x9e\\xdc\\x1ct\\xa6q\\x9fJ\\x05p`?\\n@\\xa1\\xba\\x8e\\xb4\\xa5G\\x1c\\xd3\\xe2\\t\\xbb\\x04\\xd2\\x13#\\x16\\xe3 \\x11R\\xad\\xaa\\x13\\xca\\xd4\\x85Fx5:\\x108=\\xa9\\x81\\x04vH\\xaf\\xc2\\xf3[z|\\x0b\\x1a\\xee\\xc75E\\x08b9\\xadK|\\x01\\x8acG\\xa2\\x8auF\\x1b-\\x8a\\x92\\xb9\\r\\x05\\xa5\\xa6\\xd2\\xd0\\x02\\xe6\\x90\\x9a)0h\\x01h#4\\x01N\\x02\\x80\\x10\\x0c\\np\\xa4\\xc5-\\x00(\\x14\\xa3\\xad&M\\x02\\x80\\x03\\xd6\\x96\\x8cQ@\\n)i\\xb9\\xa5\\x06\\x80\\x10\\x9aZi\\xa0\\x1a\\x00vh\\xcd2\\x96\\x80\\x1d\\x91I\\x9aC\\xcd \\x14\\x00\\xfc\\xd3h\\xa34\\x00\\x11IK\\x9c\\xd1L\\x04=)\\x86\\x9dM\\xa4\\x04DR\\x11IpJ\\xaeE\\t\\x92\\x80\\x9a\\x06F\\xea1\\x9a\\xc9\\x96\\xf9\\xfc\\xf6X!\\x8d\\x808\\x05\\xf2sZ\\xd3\\x0c\\xc4\\xe3\\xfd\\x93\\\\E\\x85\\xc4\\xab\\x03\\x02\\xe4\\x10\\xdc\\x12Mua\\xe0\\xa4\\xd9\\x9c\\xdd\\x91\\xa9-\\xad\\xd4\\xcf\\xe6K\\xfb\\xc7\\xc7\\xb6\\x07\\xd0V}\\xd5\\x9e\\xa0\\xd9\\t\\x0b\\x91\\xedW\\x05\\xdb\\xad\\x98\\x0b!3\\x1f\\xe2\\xde\\x08\\xc7\\xa61\\xd7\\xf1\\xa6\\xef\\xb9X\\x99\\x8b\\x92W\\x9e\\xa0\\x8a\\xeeWFW0\\xe5\\xb2\\xbd\\x84\\xe6H\\\\~\\x14\\xb1\\x89S\\x87V\\x07\\xe9Z\\xff\\x00m\\x97#.y\\xe9\\xc5F\\xd7\\xees\\xb8\\x8e\\rh\\xa5$+\\x14\\x96p\\x0e\\t\\xc1\\xf7\\xabP\\xce\\xbe\\xa3\\xdf\\x9a\\x86y\\x92^Y\\x17\\xebPm\\x8fo\\x19\\x1c\\xd6\\x8a\\xa3\\x15\\x91\\x8b\\xad[\\xb4\\xba\\x9d\\xc4\\x91.\\xe0@<\\xf1\\xdb\\xa5f\\xd8\\xeawpF\\xe9\\x1c\\xf2\\xa8\\x07\\xee\\x86\\xe3\\xf2\\xae\\x98\\xd9[H\\xdb\\x98d\\x9e\\x0f\\x15\\x17\\xf6=\\xb7!X.j$\\x9bw\\x1d\\xd1\\x99\\x15\\xecr\\xc3\\x95\\x92&}\\xb9\\xe5\\x97$\\xfa`\\x81\\xcdG\\x1b5\\xc4l\\xca#\\x0e\\t\\xc8\\xdc\\xab\\xd0s\\xc6E__\\x0fD\\xae\\x1e9\\x02\\xb09\\x07=*&\\xf0\\xd8iY\\xf7\\x02\\xc7\\x9c\\xe6\\xa7\\x96B\\xba3\\xdeR6\\x91\\xc6N\\x074\\x8c|\\xb5\\x05\\x81\\xc1\\xadF\\xf0\\xfc\\xbbP$\\x83(w)*\\x0e\\x0f\\xe3QM\\xe1\\xfb\\x99Ic*\\xef\\'\\'\\x08\\x14~C\\x02\\x8bH.\\x8c\\xb6\\x97r\\xff\\x00\\xb3\\xebP\\x17\\x07\\xbdk7\\x87\\xb5\\x03\\x1e\\xc16T\\x7f\\x0eN\\xdf\\xca\\xaa\\xb7\\x86\\xf50O\\xca\\x8c=\\x8d&\\x98\\xee\\x8c\\xd9\\x1cs\\x83U\\x1d\\x99\\x98*d\\x93\\xd8V\\xc1\\xf0\\xde\\xa6dT1u\\xf7\\xae\\x8fG\\xf0{\\xc4\\x15\\xca3M\\xf5\\xe0Vn\\xe3V8\\xfb]\\x1e\\xe2\\xe1\\xb7M\\xb9\\x13\\xfb\\xa3\\xa9\\xafA\\xf0\\xe7\\x84\\xcb\\xc6\\x1d\\x90\\xc3\\x0f\\xa1\\xea\\xd5\\xd0i\\xbe\\x1b\\xb6\\xb4\"I\\x86\\xf9:\\xe0\\xf4\\x15\\xd0&\\x17\\x801ZB\\x9e\\x9a\\x8f\\x9dt#\\xb5\\xb3\\x82\\xca\\x11\\x1c(\\x00\\xf6\\xa9\\x98\\xf3JM4\\x9c\\x9a\\xd5+\\x10\\xdd\\xc34\\xe8\\xf9$\\xd3F\\x05H\\x84b\\xb9\\xb1\\x8f\\xf7e\\xd3\\xdcx\\xa7b\\x90\\ny\\xaf$\\xdcn))\\xd4\\x9dh\\x02)\\xa1I\\x80\\x0c3\\x83\\x91R\\x80\\x14`Q\\x8a\\r\\x00.(\\xc5\\x19\\xc5&\\xea\\x00i\\x18\\xa6S\\xcd!\\xa0\\x04\\xe6\\x9aMHG\\xcbQ\\xed\\xe6\\x81\\x90]\\x0c\\xc4k\\r\\xac\\xd2Uv8\\xc8\\xe8+v\\xe3\\x88\\xcdr7\\xf3\\xbcs\\x90\\xacFj\\xe0&6\\xdd\\x02\\xceB\\x91\\x8c\\xd6\\x85\\xe2\\x05\\xb4>\\xb5\\x9bbKL+N\\xfc\\xff\\x00\\xa3\\x9a\\xe8\\x88\\xba\\x1c>\\xa2\\xfb%\\xc9\\xc6+-\\xa5\\x1b\\xba\\x8a\\xbd\\xabd\\xb9\\x00\\x8e\\xb5\\x93\\x8f\\x97\\xa5;\\x19\\x92\\xbc\\x98\\xa8\\x0c\\xdc\\xf2zS\\x18\\x12\\xb9\"\\xaa\\xcaH\\xe34\\x08\\xb8\\'$\\x83\\x9a\\x7f\\x9f\\xd7\\x15J\\xd6&\\x9a@\\xa0\\xfdj[\\x81\\xe5\\x123H\\x0b\"\\xe5\\xb3\\xdcS\\xd2\\xe4\\xe4\\x12N1Y\\xc1\\xf23K\\xbf$s@\\x1bV\\xd7\\x7f9\\xe2\\xb7mg\\x12r+\\x93\\xb7$>k\\xa4\\xd3y}\\xa7\\x9acG\\xa8\\xc6\\x849$\\xd4\\xc2\\x99N\\x06\\xb8\\xcdE\\xcd\\x19\\xa4\\xa34\\x0cu(\\xe9M\\x14\\xb4\\x08Z\\\\\\xd3GJu\\x00-\\x14f\\x8a\\x00)E%\\x19\\xa0\\x07QI\\x9cR\\x83\\x9a\\x00LR\\x81E-\\x00&(\\xc5\\x19\\xa38\\xa0\\x00\\n1Fih\\x01\\xb9\\xa4\\xa7qILbR\\xd1E!\\x08\\x05\\x14t\\xa34\\x00\\xde\\x94\\x99\\xe6\\x9ci\\x94\\x00\\x8d\\x83\\xc1\\x14\\xce\\x94\\xe2j>\\xa6\\x80\\x19 \\xcco\\xf45\\xc3ZD\\xdbHn\\x17q\\xe7\\xafz\\xef\\x18|\\x8d\\xf4\\xae&\\xd9\\x9aA$R`\\xe1\\xce\\xd2\\x00\\xcfZ\\xeb\\xc2n\\xcc\\xeal?\\x05\\x14)\\xc9\\x00\\xf0h9h\\x0f#\\xaf\\x00\\x81O\\xfb5\\xe9o-`\\x0c{\\x10rq\\xf8\\x1aC\\x14\\xd1\\xc47\\xc4\\xc3=\\xcek\\xbc\\xc4\\xac\\xf0\\xfc\\x83\\x0c3\\xdb\\x15\\x0e\\n\\x9c\\x11\\x93S\\xb9*\\xb9\\xc1\\xfet\\xc6db6\\x06\\xcf\\xb8\\xaaC*\\xb8=(\\xc0\\xc7\"\\xa4l\\x01\\x8cs\\x9aa*EZ$e\\x00\\x9fzq\\xda:RqT\\x02\\xef\\xed\\x9aP\\xc4\\x9an=\\xe8\\x03\\x8ab%\\x120<v\\xa7\\xa4\\xc795\\x16=)B\\x9a\\x00\\xb0.\\n\\x8a\\x90\\\\\\x9cb\\xaa\\xd2\\x8a\\x00\\xbfo.g^\\x95\\xd8Zc\\xecL\\x02\\x8e\\xb9\\xcdq6\\x9c\\xce\\xb5\\xdbY\\x8f\\xf4\\x13\\xf5\\xa2\\xc8cO\\\\S\\xd6\\x90\\x8eiG\\x14\\x86)4Rc&\\x9d\\xc0\\x19n\\x94\\x80i\\x03if\\xe0\\x7f:|f\\xab\\xa0\\xb9\\x9e\\xe9\\xb1\\x11\\x10\"\\xe7w\\xbdXR\\x00\\xae,o\\xc0\\x8di\\xeeJ\\x1b\\x14\\xbb\\xb3Q\\x13OQ^a\\xa8\\xec\\xd3\\xb3\\xc50\\xd2\\x83\\xc5\\x00<\\x1a3L\\xa0\\xb6(\\x01\\xf4\\xdaM\\xd4\\x9b\\x85\\x00)\\xa0\\x8e)7R\\x93\\xc5\\x00\\x14\\x99\\x14\\xd2y\\xa6\\x93\\xc5\\x03\"\\xba\\xff\\x00Vk\\x8b\\xd5F\\'8\\xf5\\xae\\xbe\\xed\\x88Z\\xe55!\\x99\\x0f\\xd6\\xaa\\x1b\\x89\\x8d\\xd3r\\xd2\\xadk_\\xa8\\xfb;\\x13\\x8c\\x01Y:v\\x04\\xc3\\x8e\\x95\\xa3{)0\\xb0\\xed\\x8a\\xe9\\x88\\x1c&\\xa9\\xf2\\xccA\\xf5\\xac\\xa0\\xa4\\xe7\\x8a\\xd9\\xd4F$9\\xe7\\x9a\\xcb$\\x1ej\\x99\\x9b+\\xb8\\xc2\\xd5\\x19\\x8es\\xebZS\\xae\\x17\\x8fZ\\xcf\\x95N\\xef\\xadI$PN\\xd0I\\xbdz\\xd3\\xe5\\x94\\xc9\\xf3\\x1csL\\x910(E\\x18\\xc7\\xe5@\\x08\\x83\\x8e\\xb5 \\xcesH\\x14\\x03\\xcd8\\xb7=x\\xa0\\x0b\\xb6\\xa7\\xa7\\xb7\\xadt\\x9aa\\xc8\\x04\\x81\\xdb\\x9a\\xe6\\xe0#p\\x1e\\xb5\\xd3iX\\xd8\\x05R)\\x1e\\xa0\\x8d\\xb8f\\x9fME\\xda0)\\xf8\\xae#A\\x05:\\x90R\\xe3\\x8a\\x00(\\x07\\x9a1H84\\x00\\xe1KIK@\\x0bE \\xa2\\x80\\x174RQ@\\x0e\\xa2\\x92\\x90\\xb0\\x1di\\x80\\xec\\xd1H9\\xa5\\xa4\\x00)sH\\x074\\xb4\\xc0)sM\\xe6\\x96\\x80\\x03\\xd6\\x8a(\\xa0\\x02\\x8e\\xd4\\nCH\\x044Pi\\xb9\\xcd\\x00.i\\xa6\\x83\\xc5\\x02\\x80#\"\\x90\\x0eqO\\xaa\\x97\\x17\\xb0\\xdb\\xf2\\xcd\\x96\\xfe\\xe8\\xa2\\xd7\\x02\\xcb\\x90\\xa8\\xccz\\x01\\\\6\\xc9\\xa2i\\x1dT\\xba9\\xc8*A\\xc5.\\xbf\\xe3X\\xa0\\xfd\\xc4L\\t<0\\x07\\xee\\xfdO\\xaf\\xb0\\xa5\\xb4\\xb5\\xb2%\\xdb\\x0f\\xb8\\xf2v\\xb7\\xf8\\xd7n\\x16-6eQ\\x97,\\xb4\\xedB\\xf2\\xd5\\xee!\\x81\\xca\\xafr\\x83\\x14\\xf9REI\\x15\\xc1\\x1e_\\x0cv\\x9c\\x03Q\\xb6\\xcc\\xee\\x82YS\\x03\\x18\\xc8\\x1f\\xca\\xa3\\x90_m\\xf2\\xd2\\xfaUF\\x1c\\xaer\\x0f\\xeb]z\\xdc\\xccQ\\x1b\\xf9{N:g\\x93\\xda\\xaa\\xc8B\\xb0;~Q\\xe9\\xcd?\\xcc\\xd4\\x15\\x817\\xdb\\x88\\x1b~e\\xed\\xe9L\\xdfx]\\x81\\x109\\'\\x9c\\xa8\\x15i>\\xa2\\x19$\\x91\\x9c\\x84C\\x8fq\\xcdE\\xb26\\xce\\x0ex\\xa2T\\xb9.\\x7fp\\xb9\\xff\\x00`\\xf1Q\\x130 y.\\x0f\\xb5Z\\x11#\\xc5\\x1a\\xa0\\xc6\\t>\\xf5\\x16\\xc5\\xed\\x91M\\x12\\x12\\xc7r?\\xe5F\\xf5\\xcf\\xff\\x00Z\\xa9\\x00\\xbeX\\xea\\r\\x1b\\x08\\xe8\\xd4\\x9ej\\xf1\\xc8\\xa6\\x99Fx<U\\x01(R:\\x11J\\xaa\\xe0qQ\\xf9\\x9f-H\\x8f\\x9aW\\x10\\xa46:s@\\xdf\\x8e\\x94\\xe0\\xe2\\x9c\\x1b\\x8ah\\x07\\xd9\\xbb\\x89\\xc7\\x15\\xdeY\\x1c\\xe9\\xfd9&\\xb8{C\\xfe\\x92\\x9fZ\\xefm\\xc0\\x1a~{\\xe6\\x81\\x91\\x11FGjiny5^\\xe7Q\\xb7\\xb2\\x89\\xa4\\x91\\x82\\x81\\xd5\\x8fJ\\x962\\xeaD\\xeeHUf8\\xe1Td\\x9a\\xa5\\xa0\\xde\\xc5\\xac\\xf8\\x84\\xdb\\x99S\\xc9\\x89[|C\\x87V\\x04\\x8f\\x9b\\xd3\\xa5Wo\\x15Mm\\xe1\\xfb\\x9b\\xdd6\\xe5\",\\x08I\\x9a<\\xb6z|\\xb9\\xae;\\xc07\\x17\\x96\\xba\\xc4\\xfa\\x84\\xc1\\xda;\\x82bi\\x0fM\\xcd\\xeb\\xees\\xfa\\xd6jWvF\\x9c\\xba\\\\\\xeb\\xac<Gs{\\xa8\\xdei\\xd1\\'\\x97\\x02\\xc8\\xd1\\xb1F\\xcf\\x98\\x14\\xf0k`\\x0cqX\\xba\\x06\\x95\\xfd\\x99\\xa9\\\\.\\xf0K\\x12\\xc8\\xcd\\xe9\\xd7\\xf3\\xad\\xa0y9\\xeb\\x9a\\xe6\\xc7/u1\\xd3\\xb5\\xf4\\x1c\\x05/4\\xdd\\xf4\\xb9\\xaf0\\xd4Zvx\\xa6f\\x8c\\xd0\\x02\\x9a\\x8c\\x06\\xcf&\\xa4\\xa4\\xcd\\x003$SI\\xf4\\xa98\\xa4\\xe2\\x80\\x11I\\xa7\\xe7\\x8anE.h\\x005\\x198jqjc\\xf64\\x0c\\x82\\xeb\\xeeg\\xd2\\xb9k\\xd1\\x99O\\xa5t\\xb7L\\x0cF\\xb9\\xbb\\xb2\\xbb\\xd8\\xd5DLe\\xa7\\xfa\\xdcU\\xbb\\xb3\\xf2\\x1f\\xa5Q\\xb2bd\\x18\\xebW\\xae\\xbf\\xd5\\x93\\x9a\\xe8\\x8e\\xc28\\xfdLe\\x9b\\x1d\\x8de\\x83\\x8c\\x82\\xb5\\xad~\\xbb\\x9d\\x8ez\\x9a\\xca\\xdb\\x83\\x83TC\"\\x95\\xca\\xe7=*\\x93\\xc87\\x0c\\x8e\\xf5z`:\\x03Y\\xb7\\x18\\'4\\xac\"\\xe4Vf\\xe2&\\x94\\x8f\\x94\\x0e\\xb5A\\xd4,\\xb8\\x1d\\xaaA\\x7fs\\x1c\\x1eR>\\x10\\xf6\\x15_%\\x8f\\xbey\\xa2\\xc2%\\xdaX\\x7f*U\\x8f\\x90h\\x87\\x96\\xe7\\xb5Lx\\x19\\xa0\\x07\\xc4\\x84\\xc82H\\xc5u:H!W?\\x8dsQ\\xfd\\xf0k\\xa6\\xd3~\\xea\\x1f\\xcc\\n\\xa4R=>G\\xd8\\xa4\\xd3m\\xa6\\xf3\\xd0\\x9fC\\x8aq@\\xe3\\x07\\xa5,h#\\x18^\\x95\\xc4hH)i8\\xa5\\xe2\\x80\\nN\\xf4\\xb4\\x9d\\xa8\\x01\\xd4R\\nZ\\x00(\\xcd4\\xb6)A\\xa0\\x05\\xa0Q\\x9a\\x05\\x00\\x04\\xd5;\\xe9\\x02F\\t8\\xe6\\xae\\x11T\\xaf\\xad\\xfc\\xf5P=i\\xad\\x00\\xb4\\x92\\x0f)Nz\\x8ax9\\xaa\\xcbl\\xd8Q\\xbb\\x00\\n\\xb2\\xa3h\\xc5\\x008QE\\x19\\xa4\\x02\\xd2\\x1aL\\xd2\\xd3\\x00\\xa5\\xa6\\xe7\\xb5.x\\xa0\\x034\\x99\\xcd!4P\\x00O4\\x94\\xa4RR\\x004\\xd7uE,\\xec\\x15@\\xe4\\x9e\\xd4\\xbdk3\\xc4\\x0c\\xcb\\xa1\\xdc\\x95\\xeb\\x81\\xfc\\xc5TU\\xdd\\x81\\x96\\'\\x98H\\x81\\x11\\xf1\\xbb\\xa9\\x1e\\x95\\xcakZ>\\xb1\\xa8\\xab\\xc5g41\\xc0x\\xdaX\\x82\\xdf\\xef\\x1e\\xff\\x00N\\x95-\\x9d\\xdc\\xabg\\x12\\x82C\\x13\\x9d\\xdb\\x88 zU\\xf5\\xbd1\\xe3{1\\xdc:+\\x0c\\xe2\\xbb\\xd6\\x1d-\\x8c\\\\\\xcf5\\xba\\xf0\\x0f\\x89\\x0c\\xa0\\x98\\xa1t\\xcf\\xdeY\\x86\\x00\\xae\\xd6\\xdc-\\xa0#nN\\xdd\\xb9S\\x8a\\xd9K\\xf6h\\xfa\\x93\\xc6O\\x00\\xd5/\\x91\\xe5\\xc9P\\x07\\xd2\\xb5\\x849Y-\\xdc\\x8d\\x15$la\\x95\\xba\\xe4\\xb0\\xc5;\\xc8\\x05r\\x0f\\xd7\\x81R\\x06\\x8c\\xf5 \\xf3\\x8cd\\xd3\\xff\\x00t3\\x9f^0Eh\"\\xa0\\x84\\xb2\\x9e\\x06A\\xe3\\x83P\\xbcD\\x1c\\xf4?Z\\xb8\\xc0\\x93\\x98\\xf2\\x05A\"HXd\\x9a\\xa4\"\\x03#\\x059\\xe9P\\xb31\\xe7\\xa1\\xab\\x0f\\x132\\x95\\'\\x06\\xa1\\xfb+\\x83\\xc9\\xaaB\"\\xde\\xc0z\\xd2n\\xc9\\xce\\x07\\xe5Jm\\xe5\\x07\\x02\\x9ab\\x94rEP\\x80\\xf9g\\xaa.>\\x94\\xcf.&\\xff\\x00\\x96b\\x94\\x87\\xec\\xa6\\x9b\\xf3\\x03\\xd2\\x98\\n`\\x84\\xff\\x00\\x0e>\\x86\\x91m\\xe3\\xcf\\x05\\x86}\\xe8.})\\xe8\\x19\\xb9\\xc5\\x03\\x11m\\x17w\\xfa\\xc6\\x15(\\xb5\\xeaw\\x9f\\xca\\xa5\\x8e6$\\x0csZVv\\xc03\\xfd\\xa1\\x0e\\x15s\\x81\\xd7\\x1e\\xb4\\xdbH,gY\\xd9\\xc9%\\xc0\\xd8\\xe3\\x8e\\xd5\\xda\\xc6\\xb2\\x8d2<\\x0cd\\xf3\\\\\\xb5\\x94\\r\\xf6\\xb6x\\x8eT\\x1e\\xddk\\xb1\\\\\\x7fdF<\\xc2\\x18\\xb6J\\x1f\\xe7HfL\\xdb\\xd6xc\\xcf\\xdflc\\xf5\\xac\\x0f\\x14\\xab]I\\x06\\x9fn\\xa6Ido\\xb8+\\xa3\\xf2d\\x9bP\\x8eA\\x9d\\x91\\xa9\\xe7\\xdc\\xd5[\\x0b\\x01g5\\xce\\xaf~?~\\xc4\\xecC\\xfc\\x0b\\xfe&\\x89+\\xab\\ri\\xb9F\\xf3G\\x82\\xdf\\xc3\\xf6\\xdaTR\\xbb\\xea2I\\xca\\xed\\xf9\\x11;\\xb6~\\xb5\\xa1\\xa9\\xe9\\x11\\xe9\\xbe\\x17\\xd34\\xabD\\xf9\\xaef\\x0f#w\\xda3\\x82~\\xa7\\'\\xf0\\xa6\\xc0\\x8e\\xd7\\xeb;\\xb6f\\xbb\\xea?\\xb8\\x83\\x9c\\x7f\\x9e\\xf5\\xa7v\\xcd-\\xca3\\x1e\\x14\\x00\\x07\\xa6:V\\x11i\\xfb\\xcbb\\xdffT\\xbbY\\xd2k6C\\xc1;d$rF2*\\xf2\\x9f\\x96\\xa7`nYW\\x1fq\\x7f@*\\x01\\xc5sc\\xa5\\xa2C\\xa6\\x18\\xcd?\\xa56\\x82zW\\x9cj(>\\xb4n\\xf7\\xa6\\x1e\\x94\\xd00(\\x01\\xed&*374\\x8c})\\x823\\x92s@\\x13n\\xe3\\xad.sUY\\x19\\x7f\\x8a\\x9a$x_v7\\n\\x06\\\\\\xce\\r\\x04\\xd4\\t1\\x90\\xf4\\xe6\\x9f\\xb8\\x9e1@\\x12g\\x8ac\\x1c\\x8cR\\xe4\\x91\\x8ai\\xe0\\xf4\\xa0\\n\\x17\\x0crFk\\x9b\\xbelJy\\xae\\x96\\xe9~RGZ\\xe6\\xaf\\x17s\\x92\\xc2\\xae\"cm\\x1b\\x0e[\\xd2\\xac\\xdc\\xe5\\xa39?AUm>V\\x03\\xadX\\xb8$\\x03\\xde\\xba#\\xb0\\x8eb\\xfd\\x8bH\\xea\\xbc\\x0cqY\\xbc\\xf7\\xebZ\\x17\\xf8\\x04\\xb68\\xe9\\xf55\\x9b\\x9c\\xf3T\\xc8d\\x13\\x96\\xdb\\xb8V{\\x96?J\\xd7l:\\x15\\x02\\xb3.\\x14(\\xc69\\x14\\x85b?,\\x98\\xf7{\\xd1\\t\\x006G\\x06\\x9f\\x14\\x85U\\x97\\x19\\x04Ta\\x82\\xb0$g\\x9e\\x94\\x08pR\\x01a\\xc5L\\xad\\xc0\\xcd5\\xa4Y\\x18\\xec\\\\/\\xa5+\\r\\xaa\\xa7\\x07\\x14 ,[\\x92\\\\\\xe6\\xba]0\\x80\\x14g#\\xf9\\xd7=hT\\x82q\\xc9\\xad\\xfd,\\x02\\xdc\\x0e\\x07\\x14\\xcaG\\xaa\\xd0\\r3u\\x19\\xae#BO\\xa5\\x14\\xd1@8\\xa0\\x07\\xe6\\x83M\\xcf4n\\xa0\\x01\\x9f\\x1d:\\xd3\\x81\\xa6b\\x9c:P\\x00Fi\\xca8\\xa4\\xa1r\\x074\\x00\\xb4\\xbb\\x85%7\\x00\\x9a\\x00~\\xec\\xd2u4\\x01\\x8a\\x0fJ`:\\x8e\\xf4\\x82\\x81\\xd6\\x80\\x1dI\\x9c\\xf5\\xa34qH\\x04\\xce)sF)\\x0f\\xb50\\x16\\x82M\\x00q@4\\x80LR\\xf7\\xa44df\\x80\\x14\\xf5\\xa8\\x98\\xb7\\x99\\x8c\\xf1R\\x13M\\xf5&\\x80\\x175\\x97\\xe2\\x13\\x9d\\x0e\\xe8\\x0e\\xa5G\\xf3\\x15\\xa5\\xb8t\\xac\\xddx\\xe7C\\xba\\x03\\xa8P\\x7fQU\\x0f\\x89\\x03\\xd8\\xe7\\xadP\\xac\\x00\\x93\\xc8\\xce:\\xd3\\x8d\\xcc\\x85\\x819,\\xa3\\x00\\x9ex\\xa8 \\x90\\xc9\\x12\\x15G\\x03\\xa3\\x02\\x06j\\xc2\\x98\\xdc\\x9d\\xc4\\xa9\\xe9\\x8d\\x87\\xfaW\\xb0\\xb69\\x98\\x9ev\\xe0s\\x8c\\xe7\\xd0P\\x19NA8\\xcf|U\\x86[U\\x8dY.#|\\xf5^A\\x1f\\x98\\xa6y\\x11n}\\xae\\x87j\\x93\\x9d\\xe0\\xf1E\\xd0\\x11\\x96E\\x88\\r\\xdf6}iZ@S \\xf3\\xf8R*+\\xe4\\x81\\xc58B\\xbe\\x94\\xc4F\\xccJ\\x03\\xdfu+\\xb9\\xe0\\x83\\x8as\"(\\x00\\xf0\\t\\xa8\\xdd\\x01\\\\\\xa9;i\\x80\\xd6\\x91\\x9b\\x92\\xdc\\xfd{\\xd3\\x0c\\xc5\\x97,y\\xa5x\\xc7\\x184\\xcd\\x83\\x1dj\\x84\\xc0\\xc9\\x85\\xe0\\xd0\\xb2\\xee#\\'\\xb55\\x93\\x03\\x02\\xa2*r*\\x84Le\\xc14\\x86@W\\xa0\\xc6j\\x12\\r\\x00\\x90)\\x80\\xf3\\x83\\xfc5\\xb7\\xa3\\xda\\xc7:\\x80W\\xa9\\xac\\r\\xc6\\xbao\\x0e\\xbf\\xdd\\x04g\\x06\\x98\\xd1\\x8d\\x7fr\\x96\\xfa\\xf3\\xe9\\xe3+2\\x10A\\x1d\\x08\\xab\\xb77\\x17?j\\x8e\\xd6\\xe9JN\\xa8\\x1a6\\xc7\\xdeZ\\xb5&\\x90\\x9a\\xbf\\x8c\\xaf\\xdbn\\x0cP\\x8d\\x87\\xd1\\xb1YZN\\xb9&\\xbb\\xab\\xdb\\xc3z\\xa8\\x1a\\xde\\x13\\x1a0\\x1c\\x9c\\x1e\\xf5\\r\\xeah\\x96\\x85\\xa0\\xcbgz\\x9191NpH<\\x02\\ruW,\\xe2\\xc2\\xd8\\xb2\\x8c\\x0c\\x80\\xc3\\xbde\\xf8\\x8a\\xce=J}2\\xec(\\x06%1\\xc8\\xc3\\xb8\\x1d)\\x8f<\\xf3\\xd8m\\xb7>g\\x96\\xfc)=qT\\x89e\\x95\\x92D\\x99B\\xb0\\xc195\\x97\\xe2k\\xc77VVh\\xc4$\\x87{\\xe3\\xb8\\x1d\\xab9u\\x89Z\\xf3\\xcdx\\xda4C\\xb4\\xaf\\x7fCZ\\x97Zl\\x9a\\xc3Z]\\xc0\\xe1\\x1dF\\x0e\\xefCJj\\xeb@\\xb6\\xba\\x96\\xb4l\\xdcO5\\xd9\\xfb\\x91\\x8f\"/\\xa0\\xfb\\xc7\\xf3\\xfeUri\\x14\\xcc\\xaa\\x0f;\\xb9\\xa7E\\x0cv\\x16I\\x02t\\x8cr}MP\\xb7>}\\xfa\\xc9\\x9e@9\\xf4\\xa8Q\\xe5J(w\\xbb\\xb9\\xbb\\xe7\\xa5\\xbc\\x0cPe\\xe4\\x88\\xab\\x1fB[\\xfc\\x07\\xebT2\\xe5\\x86:PTB\\x9brNX\\x9eiU\\xb3\\xcdy\\xb8\\xd7y\\xd8\\xd6\\x9e\\xc4\\x82\\x86 \\x1anx\\xa4\\xcfs\\\\e\\x8bLf9\\xc7j^\\xa2\\x98T\\x1c\\xf3Lc\\xb7f\\x94\\x1a\\x88\\xc6w\\x02\\x0e\\x05; \\n\\x04=\\x80<\\xe6\\x9a\\x10\\x13\\x93G\\x18\\xa7\\x0cb\\x80\\x15UT\\xe4\\x00)x\\xa6\\xe3\\'\\x19\\xa4dc\\xdc\\xd01\\xc7\\xda\\xa2v#8\\xa7\\xee*@\\xc54\\x92OJ\\x00\\xa7p\\xc4\\xa1\\xe3\\x15\\xcf]\\x91\\xe6c?\\x8dtwx(G\\xe7\\\\\\xce\\xa2\\xcb\\x9e\\x06\\x17\\xa0\\xaa\\x8b\\xd4B[\\xec/\\x9c\\xf4\\xa9.H\\x10\\xb1\\xcf\\x15V\\xd9J\\xa6q\\xc1\\xebS\\\\d\\xc1\\x91\\xc9<\\xe3\\xda\\xbab#\\x9d\\xbe\\x89\\xa4$\\x81Y\\xdb\\x08\\xcf\\x07\\xda\\xaf\\xdd]H\\x8e\\xc8\\xacG\\xf7\\xb1T\\xfc\\xc6Q\\x93\\x8c\\xff\\x00J\\xa2\\x1e\\xe4\\x07*\\xac\\x0fn\\xa6\\xa94bG\\xc98\\x18=kFK\\x90\\x13\\x0f\\x18*z\\x9a\\xa1q$G\\xe6P\\xc0t\\x03\\xda\\x90\\x8a\\xbe\\\\\\x87\\xa7J\\x8c\\x1d\\xad\\x9csW#\\x99<\\xacy\\xb8 `q\\xda\\xa2\\x11\\x86?}y\\xa0DQL\\x10\\xb1\\xc6w~\\x95;N\\xcf\\n\\xa1\\xc6\\x17\\xa5 \\xb3nI\\xed\\xe9Q\\x85\\xc3`\\x8eh\\x03J\\xd9\\x19T\\x01\\xdf\\xd6\\xba\\x1d5B\\xb8\\xf4\\x03\\xf35\\xce@IU\\x07\\xa9\\x1f\\x95tzk\\x81\\xb5\\xb00:\\x03\\xdc\\xd5$RG\\xa6\\xf3OZi\\xc5;\\xd0\\xd7\\t\\xa8\\xb9\\xa3\\x14\\x9e\\xf4\\xb9\\xe2\\x81\\x05.@\\xa61\"\\x9a\\x99\\xef@\\x0f\\xe4\\xd3\\x90\\x15\\x184\\x01\\x81K\\x9a\\x00vqFy\\xa6\\x93H\\x0f4\\x00\\xec\\xd2\\xd33N\\x1d)\\x80\\xb9\\xe7\\x9a\\x0b\\x0e\\x99\\xa6\\xe0\\xe6\\x9aPn\\xc9\\xa4\\x04\\xbb\\x80\\xa4\\xcd\\'\\x18\\xa5\\xea(\\x01sJ\\x0ei\\x87\\xad8\\x1e:P\\x02\\x8a\\t\\x18\\xcdFd;\\xb1HA?z\\x80$\\xde;Q\\xb8\\xd4[\\xb1\\xc60\\x05<\\x1c\\x8a\\x00vi\\xbc\\xf5\\xa0\\x1eh\\xc9\\xa0\\x04-\\xcd\\x04\\xd0N9\\xa4\\xceh\\x00\\xaa\\x1a\\xe7\\xfc\\x80\\xee\\xb1\\xfd\\xce\\xdfZ\\xbb\\x9cv\\xaaZ\\xd3gE\\xba\\x03\\xfb\\x86\\xaa\\x1f\\x12\\x07\\xb1\\x8b\\xa6\\\\M\\xf6x\\x82J\\xb9 \\x82]\\x87ONh{\\xb9\\x15\\xca4H\\xc0\\x1c}\\xd0y\\xaaQ|\\xd6q\\x858\\xe3\\x90\\r[\\x8a\\xdag\\x8f\\x92\\x18\\x9e\\x83\\x8a\\xf6\\x16\\xc7-\\xc6\\xf9\\xe8\\xea\\x15\\xe3\\xd8\\xde\\xc0\\xd0#\\x8cs\"\\xe3\\xebRy%\\xb0\\xc1q\\xb4\\xf2pF(\\x9d\\xa4\\x93%\\x9c\\xba\\xb1\\xc8\\xe7\\xa50Da Rr\\xc4zb\\x965\\r\\xf3\\x89\\x0e\\xc5\\xeb\\xd6\\x94Z-\\xc2\\x8f)\\x0es\\xc8$TOnP\\x15\\x05\\x86:\\x8a4\\x02O$O\\x90f\\x18\\x1c\\xae\\x7f\\x954\\xc1/\\x92\"R\\xa4\\x1f\\x9b\\xde\\xa3H_\\x19V+\\x8eq\\x9a]\\x92\\xb4\\x9bA\\xc1\\xf7\\xa6\\x04>D\\xb8%s\\x81L\\xfd\\xe2\\x8eA\\xcdY\\xf2\\xe6\\xf2\\x89\\x04\\xd4\\x04\\xc8[\\x15HD;\\xdb\\xb89\\xefH\\xd2`\\xe0\\x03S\\xeec\\x9c\\x8ah\\x94\\x02\\tQ\\xc7\\xb51\\x11\\x17\\x1bF\\r&\\xe1\\x8a\\x96F\\x04\\xf0\\xa3\\x9a\\x8f\\nA\\xc8\\xe6\\xa9\\x00\\xcd\\xc2\\xba\\x7f\\x0f\\x10v\\x9f~k\\x97;A\\xe9\\xd2\\xbam\\x00(\\xc1\\x07\\xbd\\x08e\\xc9&6\\x9a\\xa6\\xb1<-\\x87X\\xf2\\x0e?\\xd9\\xaf;\\xf0\\xcbJ.\\r\\xda\\x0c\\x98\\x8f\\xce=\\x8dz]\\xf5\\xa2\\xb5\\xf5\\xd0\\x1cy\\xf1m?\\x95p>\\x10\\x87\\xec\\x9a\\xe5\\xd5\\x8c\\xfco\\x05p{\\x90\\x7f\\xfdt\\x9a\\xd5\\x16\\x9e\\x8c\\xectk\\xb5\\xd4t\\xf9w\\x1e\\x16R>\\x82\\x99o\\xa6]\\xe9w,\\xb1\\xe6[I\\x89 \\xf7SQ\\xda\\xe9\\xe6\\xc2;\\x88\\xa2<9\\xcdi\\xe9s^\\x0bu\\x12\\xbe\\xf0\\xa7\\x80EV\\xa2\\xb9\\x9d{\\xa1I,\\xa2h\\x9bi<\\xb2\\x11\\xd4\\xfa\\x8a\\xbfgrQ\\x15%]\\x8e>R)5\\x8b\\xddI\\xe6V\\xb3\\xb5\\x0c\\xa0\\xe5\\xb1\\xfc\\xab6\\xe1\\xaff$\\x98\\n\\x15\\xfe\\xf7\\x7f\\xa5-\\xd8\\x1b\\x17\\x9b\\xd8(E%OSL\\xd3-\\x96+D\\xc2\\x1f5\\xb7\\x17>\\xa4\\xb1\\xfe\\x98\\xaa\\xd6w\\xf71\\xa8[\\xb8B\\x8e\\xcc\\x0fZ\\xd8\\xb7\\x99^H\\x94 Tf\\x00\\x9fl\\xd6m\\xebq\\xf4\\xb1Rr\\x0c\\xa1A\\xe1h\\x1c\\x0ct\\xa2\\xe9R;\\xa9\\x95N@r>\\x9c\\xd2\\x0eW\\x8eEx\\xd5d\\xe56\\xd9\\xbctC\\x83\\xe0\\xe2\\x93vN)\\t\\xc0\\xf5\\xfe\\x94\\x80\\xe7\\xbf\\x15\\x98\\xc9\\x0f\\xf9\\xf7\\xa6\\xe7\\xf3\\xf4\\xa6\\x86$\\x91\\x9e\\x9f\\xa50\\xca\\x14\\x12I*=\\xb2h\\x02BI\\x04\\x03\\xcd\"\\x9c\\x0c\\x1e\\xb4\\xd4\\x90H2\\xa0\\xfe#\\x14\\xbdG\\x07\"\\x80\\x1c:P\\x18\\x03L,G\\x03\\xaf\\xa5\"\\x93\\x83\\x93\\xc7\\xa5\\x00L\\x18}\\r\\x06M\\xa4\\x03Q\\x01\\x8e\\x7fCK\\xc3pN}\\x8d $$\\x11\\x9e\\xf5\\x18\\x90\\x8e\\x0fZ\\x00\\xe7\\x8f\\xca\\x98\\xcd\\x85=\\xc7SLeK\\x96\\xdc\\x8d\\xcf\\x1e\\x95\\xcf_\\x10%99\\'\\xb7\\xa5t\\x17\\nv\\x92z\\xf6\\x1e\\x82\\xb9\\xcb\\xe2\\x0c\\x84\\x0c6\\x0f&\\xaa;\\x88X\\xa7a\\t\\x8f\\x1f.s\\x8a\\'$\\xc7\\x858 r}\\x05C\\x0eI\\xc7~\\x9c\\xd18>I\\x19!z1\\xae\\x94\\xc4s\\xf7j\\x0c\\xbe\\xde\\xbe\\xb5\\x04\\xa3{\\x0e@\\xedS\\\\\\r\\xcc\\xd2\\x0c\\xed\\x03\\x81T|\\xe2\\x01\\xc9\\xe4\\xd536Es\\x90\\x84\\x91\\x95\\x15\\x9a\\xe4\\x91\\x9cV\\xa3\\xc8\\xa5B\\xb0\\x07<\\x01Y\\xf7!D\\x9e^y\\x1dH\\xf5\\xa0ET\\x8d\\x9aC\\xcfA\\xde\\x97\\xe6\\x1f0\\x1c\\x0e\\xa6\\xad%\\xba\\xb5\\xb9\\x95\\\\gv\\xd2\\x83\\xae=i7\\xa1\\x84\\xc4\\x14\\x0c\\x12I\\x1dM\\x002)\\xe4+\\xb4~uf\\x12\\x1d\\xcf\\x9ax\\x07\\xadW\\x8dYzc\\xebN\\xb7\\x19\\x94d\\xe0\\x7f:@\\x8d8#\\x8c3(8\\'\\x80z\\x8a\\xe84\\xe0\\xa8\\x8aKd/*;\\x1a\\xe6\\xed2\\xed\\xb4\\x1c\\x12~c\\xe8+~\\xc0\\x95;\\x87\\x01:\\x1e\\xc6\\xab\\xa1Q=C\\x91K\\xcd-\\'^\\xb5\\xc2j\\x1d\\xa9\\xc3\\xa5\\'\\xb5\\x14\\x08S\\xefGzZA@\\x0bGj(\\x07\\xb5\\x00\\x07\\x8e\\xb4\\x8a\\xdb\\x85/\\xd6\\x8a\\x00\\\\R\\xd3s\\xebA4\\x00\\xed\\xd4}i\\xbd\\xa9FH\\xc1\\xa0\\x05\\'\\x8aQI\\x8c\\x0cR\\xf4\\x14\\x00\\x99\\xc5.\\xe3I\\xf8Px\\xa0\\x03\\x18l\\x9a\\\\\\x8e\\xf4\\xdc\\x1e\\xf4\\x81Nq\\xda\\x98\\nH4\\xa0\\x8e\\x94\\xa7\\x8e\\xdcR{P\\x01\\x90\\x06i3\\xde\\x97n:\\xd2\\x10H4\\x80\\x0e1I@\\x18\\x14\\xd3@\\x03|\\xc3\\x1d\\xeb?X\\x19\\xd2.\\x7f\\xdc\\xab\\xc4\\xe4\\xd5MTgH\\xba\\x07\\x82c=*\\xa3\\xf1 {\\x1c\\xed\\xa6\\xd9-\\xc1Px\\x1e\\x95*\\x98\\x9c\\r\\xd3\\x85\\x1d\\x0e\\xe0p\\rEg\\x00\\xfb(\\xdd:>\\xe5\\xe0\\x81\\x8c}sQ=\\xb1\\x03#i\\x1e\\xc6\\xbd\\x95\\xb1\\xcah%\\xa9x\\x94\\xac\\xe9\\xf36\\xd07\\x81\\x9fzC\\x1c\\xb1\\xb6\\xc5$\\x8c\\xf0\\x01\\xaa\\r\\xb9\\x91\\x11\\xf3\\xf2\\xf4\\x19\\xedM@\\xd1\\x959 \\xf6\\xfaQ`4U\\xa5-\\xb8s\\x93\\xe9Hw\\x06\\xc6\\x01>\\xb5D\\xcb4a\\x0cr2\\xf6\\xe2\\xa5\\x172##g\\'\\xabf\\x8b\\x01vyp>E# \\x13\\x8a\\x80\\xcb\\xfb\\xc0\\xec\\xb9%q\\x9aG\\xd4&kv]\\x89\\xb4\\xf0\\x0e9\\xaa\\xeb9+\\xf3\\x0ehK@-I2ym\\xb4\\x1c\\xf1\\xda\\xa0.2H\\xe0\\x9a\\x96+\\xa8J\\xfc\\xcb\\xc8\\xe2\\xa2\\x92H\\x83\\x90zv\\xa6\"&p\\xd8\\x18\\xc53\\x03?\\x8d?\\xf7M\\xd0\\xd2\\x15P85`1\\xb1\\xb8w\\x14\\xce2i\\xe5\\x07\\x1c\\xd3H\\xa6!\\x84\\x02\\xbf\\x8dt>\\x1e\\x1d+\\x9e\\xd8O\\x15\\xd1x}p\\xe2\\x9a\\x19\\xb9\\xa8\\x82\\xb2\\t\\x00\\xe5O?J\\xe4<I\\xa5I\\x05\\xd2\\xea\\x96d\\xac\\x80\\x87\\xc8\\xf5\\xae\\xda\\xec\\x07\\x91\\x81\\xe4\\x1a\\xa0\\xb1\\xa5\\xdd\\xac\\xb08\\xc9BT\\xe6\\xabt4\\xecd\\xe8\\xfa\\x9b]\\xc6\\xb38\\x19#\\x0c=\\r]\\xd5e\\xbb\\xb3\\xb5k\\xab(\\xd6P9e\\xac#k&\\x8f|J\\x82ac\\xc8\\xae\\x82\\xce\\xf9\\x15A\\xdd\\x98\\xcf\\xafj\\x07\\xe8fh\\xde)\\xfe\\xd1\\x95\\xa1\\x9e5\\x81\\xd7\\xa7\\xcd\\xc1\\xad\\xb5\\x8f\\xcfq\\x9f\\\\\\xd6]\\xcf\\x86`\\x96\\xec]\\xd9\\x15]\\xc7-\\x1fo\\xc2\\xb7R#\\x04 \\x01\\x97<q\\xda\\xa5\\xe8\\x1at)\\x18\\xd6{\\xb2\\xb8\\xe1MN\\xcf\\xb6\\xe2(\\x80#\\x1c\\xe7\\x14\\xa9\\x10\\xb2\\x85\\xdd\\x8b;u\\xc1\\xe6\\xab\\xdb\\x19d\\xba-!\\x07\\x07\\x81\\x8eEqJ\\\\\\xb6\\x8b\\xdd\\x96\\x95\\xc5\\x93\\x1e{\\xee\\x18%\\xb8\\xf7\\xa5\\xdczw\\xf5\\xa6\\xb3\\xa9\\x91\\x8a\\xb9a\\x93\\x91\\x9f\\xf0\\xa39\\xe9\\xd3\\xd3\\x15\\xe6\\xcf\\xe2f\\xcba\\xe7\\x1cg\\x8f\\xebA\\xe4\\xfa{\\xf6\\xa6\\x16\\x1f\\xc2\\xc3=\\xf9\\xa5\\x03\\xe5\\xe9\\xc7\\xa1\\x1d\\x7f:\\x90\\x02\\xe0d\\x10\\x07\\xbf\\xad/q\\x91\\x9fq\\xd0T[\\x94\\xb1*pOU&\\x83 \\xc6\\x00 \\x0e\\x0eA\\xe7\\xf3\\xa0\\t\\x18\\x00\\xb9\\xe8=EF\\xc4\\x90\\xbbzz\\xd0\\x1f\\x907m\\'\\xa2\\x93\\xc5!8;A\\xc1\\xcf\\'\\x04\\x83@\\x0e\\xe3nI\\xcf\\xa9\\x14d\\x1eO#\\xb57\\x00\\x059\\xd9\\x93\\xec3C\\x02x\\xea\\xde\\xbc\\x91H\\x07\\xf6\\xeb\\x91\\xfa\\xd2\\xf3\\x81\\xb7\\x91L<q\\x80=\\xe9\\x18\\xb1a\\xd7\\xea9\\xc5\\x00HO$\\x93\\xd3\\xadF\\xcf\\xf2\\x86\\x07#<\\x0fZR\\xca\\xab\\x920=x\\xe6\\xa2g,\\x0e9c\\xd3\\xbe)\\x81Z\\xe9\\xf3\\x95\\x07\\x0cG\\xcc\\xc7\\xb5s\\x97\\xa7\\x9c\\xed\\xf9=\\x7f\\xbck~uV\\x0c\\x0f\\xca\\xa3\\xef7L\\xd6\\x15\\xe3\\x02\\xd9n\\x14\\x1f\\x90u\\xcd\\\\\\x16\\xa0\\xc4\\x89\\x8b\\x1e\\x07_\\xd2\\x9bx\\xdb\\xe0d\\'\\xe54\\xb0\\x1d\\xac\\t\\x03\\x03\\xad2r\\n\\xe7\\x07*N9\\xed]1\\x11\\x87r\\xae\"\\xe3\\x86oJ\\xa4m\\xb1\\x1a\\x93*\\x12z\\xaey\\x15\\xadr\\xe6\\x18\\x8c\\x05Wvy%y_\\xc6\\xaa\\x06\\xb4\\x01\\xd9\\x83\\x9f\\x93\\x8c\\xb60\\xde\\xb4\\xecf\\xcaRi\\x972\\xc0\\xd2\\xc4\\x01U\\xe3\\xa8\\xac\\xc9\\xec\\xae-\\xd1\\x19\\xe2`\\xae\\xbb\\x83\\x11\\xd4V\\xb4\\xb72\\x88\\xa4T\\x94\\xaaJ9\\x8c\\x1e\\x05f\\x99\\x1d1\\x1f\\x98\\xc4c?|\\xe0\\x0f\\xa5\\x02h\\xa9\\xb5\\xd44\\x8aHS\\xc7\\x1d)\\x83\\xfd\\xae\\rZL\\xeda\\xbd\\x80\\xc6T\\x01\\x90[\\xde\\x9a\\xf2I!yK\\xedi~\\xf8\\n\\x00<\\xd2\\x02\\x14v\\xe7\\xeb\\xd6\\xa6\\x07\\x04v\\xc59|\\xb0c\\x0c\\n\\x81\\xf7\\xca\\xf5\\xfc*\\xec\\x91Y\\x82e\\xb7\\x92F^\\xc2@\\x01\\xfd)\\x82\\x0bE\\xfb\\xaa\\x8d\\xb4\\xbf\\xdea\\xd0\\n\\xe8,6\\xac\\xa8\\xcd\\x95T9\\x18\\xe4\\x13\\xef\\x9a\\xc3\\xb6\\xb6\\x98FL\\x7f.\\xf1\\xb7\\'\\xa5tZ]\\x99\\r\\x87l\\x08\\x946@\\xdc\\xac}\\xe9\\x95\\x13\\xd2\\xe8&\\x9b\\xbb\\x1d)\\x7f\\x95q\\x1a\\x81=\\xe8\\x06\\xa2\\x99Y\\xd0\\x85%}\\xc5=x\\x03\\xbd\\x16\\x10\\xfc\\xe6\\x97\\xb50g9\\x1d)\\xdd\\x06i\\x00\\xb9\\xcd\\x02\\x80=)h\\x00\\xefA\\xc5\\x03\\xd6\\x93\\xafJ\\x00\\x08\\rE-\\x07\\x9a\\x001J\\r79\\xe9N\\x03<\\xf7\\xa0\\x00\\x93\\x8e\\x05*\\x9d\\xc3\\xa6\\r\\x03\\x9a3\\xdb\\xbd\\x00-\\x07\\x9aL\\xf6\\xf4\\xa39\\xa6\\x86?\\x82(\\xe9Q\\xee\\xc7\\x14n=\\xe8\\x10\\xe2\\xde\\xb4n\\xf6\\xa6\\xe4Q\\xbc\\x0e\\xb4\\x80qc\\xe9I\\xb8w\\x18\\xf7\\xa4\\'\\xd2\\x8e\\xb4\\x00\\xbcz\\xd4l7\\x1e\\xb8\\xa3\\x1bs\\xcf_ziS\\x9cn\\xe2\\x81\\x88x\\x1d\\xbe\\xb5_S\\x04\\xe9wC\\x9f\\xf5M\\xd3\\xe9V\\t\\xdb\\x80\\xc7\\x8fZ\\xad\\xa8\\xc9\\x8d6\\xe8\\x0e\\x7fv\\xdd;qU\\x1d\\xc4\\xcef\\xc8\\x01\\xa7\\xf3\\xf7\\x8e\\x08\\xf9\\xbaU\\xabh\\xa11\\xc9+\\xee\\xc9\\xca\\x8c(5V\\xde6[U\\x01\\xb8#8\\xa9U\\x1dc!q\\xc9\\xee+\\xd8_\\t\\xcc5\\xa1 \\x06\\xcf\\'\\xda\\x98crF[v*P\\x92\\x02Oo\\xad<\\xb1\\xc2|\\x98a\\xd4\\xe6\\xa8A\\x14\\x12\\xc9\\x13(\\x03b\\xfc\\xccq\\xc8\\xa8Y\\x0b7\\'\\xadK\\xe6\\x15\\x1d:\\x9c\\x1e)\\xee\\x13\\xccR\\x0f\\x04s\\xech\\x02\\x00\\xaa\\x06\\xd2\\xbdG\\x14\\x8c\\x14\\xaa\\xfc\\xb8\\xc0\\xe6\\xa4u\\x0ex4\\xc5A\\x83\\xebL\\x06\\xacJFy\\xc9\\xa8\\xcc`\\x83\\x93W\\x96T\\x11\\x80\\x14g\\xd6\\xab\\xb6\\xd0\\xdc\\x0e\\xbc\\xd0\\x04\\x05\\x028\\xa6\\x93\\xf2\\xe3\\x1d\\xeaV\\x05\\xdfsc\\x9fAM+\\xc9\\xa6\",SIl\\xd4\\xc4d\\xe0zP\\x8a\\x0br8\\xefT\"\\xb9-\\xda\\xba?\\x0f1$g\\xads\\xed\\x80O\\xa5t\\x1e\\x1f\\xea\\x0e:SCGKu\\x8f=\\xb00+,\\xc9\\xf6]a3\\xfe\\xae\\xe1v\\xff\\x00\\xc0\\x85j]\\x1c\\xdc6:V^\\xabj\\xd76\\x84\\xc6q,gz\\x1fqT\\x0br\\xc5\\xdd\\xa2L\\xa40\\x075\\x90\\xfas\\xc5\\x9f,\\xf1Z\\xdam\\xe0\\xd4,\\xd5\\xfaH8q\\xe8j}\\x9c\\xf3E\\xc7\\xb1\\x8di\\x1d\\xe4\\x0c@\\x90\\xed\\xf44\\xfb\\x8dr[y\\x8d\\xb2\\xc4\\xcf!\\x00\\x83\\xdb\\xae+NR\\xb1\\xa1>\\x82\\xb2c\\x8b\\xccY\\xee\\x98|\\xe1\\xb2\\xbf\\x87jOPE\\xc3$\\xc7Nf\\x98\\xaaJ\\xef\\xb4d\\xe7\\xf9{\\n,F\\xf9\\x9eF\\x04m^[\\x1c5Ms\\x0b\\xcdd\\x8a\\xbdH\\xc9Py5\\x04\\xaa\\xba^\\x9aV@\\xce\\xd2\\x90\\xa1\\x14\\x16#=\\xab\\xcd\\xaa\\x9a\\xaa\\x9b\\xd9\\x1bGb\\'m\\xccK`6x\\xf9\\xa9\\xdf6\\xdc\\x1f\\x97\\xfd\\xa0*\\xb9\\x98\\x84\\xdc\\xa0\\x91\\x9eC\\x1cS\\xbc\\xc1*nT\\xde\\x07\\xf0\\x81\\xbb\\x9f\\xc6\\xb8\\r\\t\\x1aUE\\xc3\\x82\\xa0p\\x08=iL\\x99o\\xbaX\\xfa\\x81\\xd2\\xa3I\\x0e\\xdc(p\\xdd\\xd5\\xb0\\xb8\\xa6\\x80\\xae\\x0e\\xcd\\xb8\\xfe%9l\\xfbR\\x01\\xeb\"\\x15m\\xcd\\xf2z\\xee\\x03\\x9aF\\x90\\xb2\\xf2\\xa1\\x97\\xb6\\x018\\xa4lDAU\\xd8\\xff\\x00\\xdc\\x00(4\\xdc\\xee\\x1cmYq\\x96\\xe4\\x9a`;v\\x01]\\xc5\\xbdO\\x03\\x14\\x86EV#v\\xf5\\xc7\\n\\x01&\\xa3\\xd8\\x11\\xb2\\x14\\xc6\\t\\xcf\\n\\x06\\xeao\\xcaX\\x19\\x08\\x0e\\xdd\\x0e\\xf2\\x7fL\\xd1`,,\\x8c~T\\xe4w\\x07\\x03\\x14g+\\xb1%\\x18\\xee\\xa7$\\x9a\\x81\\xdfg\\x00s\\xdeDLg\\xf14\\xe1 \\x08\\x1aV\\xc9\\xec\\xe5\\xf3\\xfc\\xa9\\x01*\\x02\\xbc+\\xb0\\xf5R\\x00\\xa7\\xfc\\xb8\\x1bd\\xfa\\x82j\\x0c\\xb7V\\xda\\xd9\\xfe%^\\x94\\xf2\\xe7\\xa3\\x1d\\xd1\\xff\\x00\\xbd@\\x0f\\xe1H\\xcb\\x11\\xe8\\xb8\\x184\\xd2\\xe3$dg\\xbf=)\\x9c\\x0f\\x9bhoO\\x978\\xa6o\\x019n\\x07$\\x93\\x8a\\x06W\\xba+\\x80\\xcc\\xa4&1\\xc0\\xc6M`\\\\\\xab|\\xaf!\\xdc\\xed\\xc0\\x19\\xe9[\\x97R&\\x0c\\xac\\x9b\\x8a\\x1c U\\xc9\\xe6\\xb1.\\x9c\\x86}\\xf92\\x06\\xcf\\\\`zqZ\\xc0L\\xaf\\x1f\\xa9\\xc8\\xecH\\x1cS\\x9eFt+\\xb4\\xbb\\xb8\\xc2\\x85\\xab\\x10\\xdd\\xd9\\xac\\x0e\\r\\xa2\\xb4\\x99\\xca\\xee%\\x94\\x0e\\xf8\\x1e\\xb5\\x04\\xb2Mo\\xfb\\xe8\\xdeH\\xe5?p\\'\\xcb\\x80z\\xf4\\xad\\x92&\\xe6-\\xc2\\xb1o-\\x01\\xde\\xdc\\x93M\\x82\\xc2{\\x96\\x91#B\\xfeR\\x17~F\\x00\\x1d\\xe9\\xf7\\x05\\x1ag\\n\\xe4\\x06\\xe5\\x8b\\x12O\\xe7P\\xcaa\\xf2\\x97d\\x98U8\\xda\\x06\\x0b{\\xd5\"\\x1b)K\\xf2\\xc6\\xdf.X\\x8f\\xca\\xb3Y\\x80\\xcfO|\\xd6\\xac\\x8e\\xac\\x1b\\xf7\\xf9a\\xd1\\x1f$\\x81Y\\xd2\\x85\\x07!\\xfe\\xa7\\x1d(\\x026\\xdc~\\\\\\xe3\\x1c\\xd3\\xa6t\\x92%h\\xdc\\xf9\\x99%\\xd3`\\n>\\x874\\tJ\\xa9!\\xbe\\xf7\\x07\\xe9N\\x88F\\x89\\xbfz\\xee=\\x88\\xe9HCr\\x9e@D\\\\9\\xe4\\x92s\\x9f\\xa5>\\'e\\xf9\\x08\\x18<\\xe3\\x14\\x86U9\\xfb\\xacI\\xe0c\\x14\\xa8\\xe40\\xe8B\\xf64\\x05\\xcdH\\x9aq\\x12D\\xac\\xea\\xc5\\xb7*\\xb1\\xe3\\x07\\xf9V\\xdd\\x86\\xf0\\xe2\\x1d\\xfeFF\\x1fs\\x1d\\xa5\\x80\\xac\\x18/\\xa7\\x0b\\x80\\xcaT\\x90\\x02m\\xfdkz\\xccr\\x90o,\\xe3\\xe6u\\'\\xbdR)\\x1e\\x95\\xd0P)M\\x04\\xd7\\x11\\xa0\\x0e\\x984\\x9cf\\x95\\xb9\\xe6\\x9b@\\xc7\\x8fJ9\\x1cR\\x0ex\\xa0\\xe7\\xa5!\\x0e\\x1dis\\x8ah\\xf44\\x99\\xe7\\x14\\xc0x\\xe6\\x94rx\\xa6\\x83\\x8a2zR\\x01\\xc4\\x00x\\xe6\\x90\\x03\\xd6\\x800sK\\x9c\\x1a\\x001\\xe9N\\xa4\\xa34\\xc0L\\xe7\\xeb@?\\x9d\\r\\xebK\\x8c\\x8c\\xd0\\x04FL6*L\\xe7\\xafZ\\x8fb\\xb1\\xf44\\xe0\\xa3o\\xb8\\xa0c7\\x168\\'\\x14\\x06$\\xe2\\xa4\\t\\x9a\\x00\\xf6\\xa0\\x06\\x83\\x8e(\\xc0\\xdd\\xb8\\x8ezS\\x8e\\x0f\\xcai\\x0fN\\x94\\x84;8\\xfa\\x1ai\\xe3\\x9a\\x06GSM`\\xd9\\x18\\xc1\\x1fJ\\x00q\\'\\xb7JL\\x02>\\x94n!y\\xa6d1\\xc1\\xed\\xdb\\xb5\\x005\\x9c\\x96\\xc0\\xe0\\x7f{8\\xa8/\\x17v\\x9dr\\x08\\xceco\\xe5V\\t\\xc2\\xf5\\xc7\\xbfJ\\xad\\xa8\\x16]>s\\xbb\\x1f\\xbb?\\x8f\\x14\\xe3\\xba\\x03\\x9a\\xb4i<\\x88\\x89GR\\x17\\x9d\\xc39\\xfaU\\x98\\xee\\xda(\\xc24\\n\\xdc\\xe7<\\x83\\xf4\\xa8\\xac\\xe5\\x90E\\x1b\\xaa\\x9e\\x0f\\x04T\\xee\\xe5\\xdf\\x91\\xf8q^\\xd2\\xd8\\xe6\"k\\x97\\x1c\\x84 ~t,\\xd9UfR3\\xd3\\x8a\\x93s\\x91\\xb3\\x1cS\\x90\\xa1L\\x14\\xe74\\x08a\\x9a0\\x0eF3\\xd0\\xd2\\x19\\x14\\xe3\\x14\\xe6\\x8166\\xec\\x8c\\x0c\\x81\\xefQ\\x88RO\\x94>=i\\x80\\xe0@l\\n\\\\\\x0c\\xf4\\xfa\\xd4\\x7fg\\xd8\\x03\\x86\\xcei\\xe5X\\x0c\\x93\\x9e(\\x10\\xa5\\x00\\xe6\\x9b\\xb0\\x1ei\\xe0\\x16\\x8c\\xe4t\\xa8@;y\\xe0\\xe7\\x91B\\x01\\x8e\\x07QL\\xc1\\xdaNi\\xec\\xad\\xb4\\xf3I\\x13\\x02\\xa5H9\\xaa\\x02#\\x9aT\\x91\\x90\\x11\\x8e\\xa2\\x9cA\\x074\\x86\\xa8DL\\xdf)\\x18\\xae\\x83@\\xf4\\xf5\\xae}\\xc8\\x06\\xba/\\x0f\\xe0\\xb8\\xcd43\\xa2\\x9dJ\\xcas\\xd6\\xa2nEX\\xbd\\xcf\\xda\\x1a\\xab\\x81L\\x0c$\\xf34\\xcdM\\x8a\\xff\\x00\\xaa\\x93\\x9cW@\\x8e\\x97\\x11\\xeeB3T\\xef\\xad\\xc4\\xb1|\\xa3\\xe6\\x15J\\x06\\x96\\xd4d\\xf5\\x14\\x98\\xf7-\\xdd\\xefE!\\x874\\xb6\\xd0\\x97\\x8d#S\\xc6y5,\\x17\\x91^\\xc6D\\x88HS\\xde\\xa0\\xbe\\xd6,\\xacO\\xd9\\xd2T[\\x86\\x1f(\\xeb\\xb7=\\xce9\\xa9\\x94\\xac\\xae4\\xb5\\xb1\\x15\\xe5\\xec\\x91\\xdf1\\x81\\x8b`l\\xd8\\xc4\\x05\\xe3\\xbfL\\xd4o;\\\\\\xb6Y\\xd4\\xbe3\\xb7\\xadP\\x96aom$\\xf2.\\n\\xf3\\xe6\\x08\\xf1\\xbb\\xf1#\\x9a\\xc3\\xb6\\xd4.\\r\\xea]\\xdd\\x161;m_\\xdep\\x07\\xe1^T\\xa7:\\x97\\xbe\\xc6\\xe9$u!A%\\xa3\\x06&\\x03\\x18\\n\\x06\\x7fJ{`\\x9c>\\x16N9\\xdc[\\xf4\\xa8\\x89\\x0e~\\xe0a\\x9e\\x1c&q\\xf9\\xf44\\xe2\\xfeTle\\x7f\\xdd\\x8f\\xe2.\\x05s\\x16;h\\x1c\\xf9e?\\xda\\t\\x8d\\xd4;\\xe1\\x81\\x98\\x80:\\x03\\xbf4\\x80\\x86\\x19\\xda%C\\xf7B\\xa9jRLk\\x85.\\xe0\\xf5\\\\\\x85\\xc0\\xa4\"\\x17\\x84#\\x97P\\xcd\\x9f\\xe3T\\xe9\\xf8\\x9aV}\\xb1\\xe1\\xdc\\x98\\xb0>\\xf3\\xe0\\xe7\\xf0\\xc5 \\x8e2X\\xc6\\xc3\\xca<\\x95r\\\\\\xb7\\xf3\\xa8\\xca\\xa2\\xf2\\xad\";\\x1c,a\\x02\\x0f\\xd7\\x14\\xc0Y6\\xf5Q\\xe6/\\x07o\\x97\\xbb\\x1f\\x89\\xa7\\xfc\\xc3pBY\\x7f\\x883\\xed\\xc5W2\\x04m\\x9b\\x82\\xcez\\xee\\x90\\xb7\\x1fAR\\xc7\\x1b\\x1c\\xb0\\x88\\xc1\\xb4ni#\\x84 o\\xc4\\x81\\x9av\\x01\\x84\\x07\\x1b\\xa21\\xbat1\\x15.O\\xe2i\\xd13G\\x9d\\xbedlx\\xd8\\xc0 \\xfc\\xb1\\x9a\\x9aV\\xb3\\x05Zi\\xcc\\xb2\\x11\\xc1\\x12m\\n}=\\xe9\\xb7\\x1feVO-$f\\xc7\\xfa\\xd1\\x00%\\x7f\\xe0T\\xac\\x03\\x14\\xa1\\x90\\xaa\\x95W\\xc6YK\\x16\\xcf\\xeb\\xc5I\\xfe\\xad\\xfeX\\xda&\\xeb\\x85M\\xa0\\xfe\\x94G\\r\\xcc\\xd9Q\\xbaH\\xd1Kn\\xf3\\x02\\x90\\x07^2\\rG\\x92\\xc3p(\\xe8zaw\\x11\\xf8\\xd2\\x01\\xee\\xc0\\xf1&\\xd5s\\xdfqj\\x8d\\xd4\\xb2|\\xcaBc\\xa8\\\\f\\x9c\\x18\\x85!X\\xb0=rB\\xe2\\x98X\\x15-\\x84(1\\x85\\xc9bh\\x19Bw\\xda9\\xda]\\x87\\xca\\xa4\\x93\\xfc\\xab\"}\\x8b\\x85]\\xc6G\\x1f1\\xdb\\x8c~5\\xb4\\xec\\xeaZS\\xbde,B\\xa8\\x01\\x02\\x8f\\xa5a^\\xff\\x00\\xach\\x83)`yl\\xee\\xc5i\\x1d\\xec&1Xo\\xcb\\x1f\\x94t\\xf9\\xb1I4\\xa7\\xc9\\xdc\\xa04\\x87*\\x063\\x8aX\\xc6\\xdc\\xfc\\xc4m\\xe5H\\x18\\xcdG:yq1ndb\\x0f-\\xd0WB\\xd8\\x96e\\xde*+*\\x06!\\xc9>g8\\xc7\\xb7\\xf3\\xa8\\x15\\x11\\xd1\\x98\\xed\\xc2\\xf4\\xf55%\\xc4as\\x1a\\x03\\x8c|\\xd8\\x1d\\xea\\xa1\\x19\\\\\\xaeF=h \\x86q\\xb4\\x86\\xc1Rx\\xaa\\x05\\xc9b\\x0e\\x08\\x07\\xa8\\xab\\xb7\\n\\xe0n\\xeez\\n\\xaa\\xc8Q~l\\x06<\\xf5\\xe2\\x81\\x11\\xb7#n0i\\xe8\\x91\\x99\\x95e;S\\xd7\\x19\\xa6:\\x92r\\xa4\\x03\\xd3\\x14\\xf3\\x19\\n\\xa5\\xb7\\x03\\xd7>\\xb4\\x00\\xf6DY8ep?\\x88R\\x1d\\xab \\'\\xee\\x0e\\xb8\\xeb\\x8af7\\x1c\\x93\\xb4\\xe7?Z\\x968K0\\x89N_\\x19\\'\\xb0\\x14\\xc4\\xcbv\\xc4\\x96\\xf3\\xba\\x8e\\x8b\\xcf\"\\xb7\\xf4\\xff\\x000\\x91\\n\\xc4%g\\xef\\xfcB\\xb0\\xe0uw\\xcc\\x8a\\x10\\xa8\\xda\\n\\x0e\\t\\x1d3[\\xf6/\\x18\\x8c\\xcb*\\xc8\\xb7\\x0e\\xf9\\x86X\\xdb\\x03\\x1fJi\\x14\\xb6=3\\x90i\\x0bc\\x81\\xd6\\x9c})\\xb8\\xe7\\x9a\\xe15\\x1c2\\x05 \\x1f6{P\\x0e)T\\xd3\\x01y\\xcf\\x146M(\\xe0\\xd1\\xc6h\\x18\\xa3\\xee\\xd3:\\xfdi\\xc7?\\x85(\\xe3\\x91HB\\x01\\xc0\\xf5\\x14\\xa2\\x90\\x9e\\xf4\\x83\\'\\xa5\\x03\\x1f\\x9e(\\xa0\\x0e\\x05-\\x02\\x0fj9\\xcf\\xb5\\x1dh\\xe4q\\x8a\\x06/C\\xea))3\\x8a9\\x1c\\x11LBc\\xb8\\xe0\\xd1\\x8c\\xf2:\\xd2\\xe7\\x1fJ3\\xdf\\x14\\x0cRzz\\xd2\\x0eM&{\\x8aBy\\x1e\\xb9\\xa0\\x05\\'\\xa0\\xefI\\xdb\\x06\\x9d\\xc1\\xa4\\xcd\\x00\\x07\\xd2\\x90\\xb7^\\x99\\xa4f\\x03\\x83\\xfc\\xaa9\\x1f\\x0b\\xff\\x00\\xd7\\xa0D\\x9b\\xb3M\\xf9s\\xd4z\\xe35_sd\\x12z\\xf7\\x02\\x94\\xa3\\xb1<\\x90\\xbe\\x99\\xebH\\x02o\\x9f\\x01X\\xa9\\x1c\\x82\\x05U\\xbd\\x94\\x8bI\\xb3\\x92\\n\\x10X\\xfb\\xf1V\\x02\\xaeH\\x1d}:\\xe2\\xa3\\xba\\x87\\xed6\\xb2A\\xb8\\xae\\xf5\\xc6\\xe1\\x81\\x8aqz\\xab\\x83\\xd8\\xc5\\x86\\xc6x-<\\xd4\\x969#R2\\xd1\\xb7#4\\xe0\\xb3H\\x0c\\xac\\xa7\\xeay\\xac\\xa4\\xbd[x\\x84W\\xd6\\xed\\x19\\xdb\\x85\\x9a#\\xc1\\xc1\\xc75i/<\\x94O\\xb2\\xeaL\\xc1\\x97.\\x8d\\xc6\\xd3\\x9e\\x9e\\xf5\\xec\\xa7\\xa1\\xcc\\xc9Z]\\x99\\xc9\\xc52+\\xb4\\x0e\\x0b6Fz\\x03\\xcd_\\x84$\\x96\\xe2IX\\x05\\xc0$\\x95\\xc8\\xe7\\xe9M\\xfb%\\xa4\\xee\\xa1d\\xb5%\\xb3\\xc6\\xe0\\x08\\xa7t\"\\xb2\\xcc\\x928\\xf3X\\xa8\\xf6\\x14\\xe2\\xd1om\\x92g\\xda\\xad\\x1d29\\x13/\\x19*\\x0fUj\\x85\\xf4\\xb8\\xe3\\x04\\xa3\\xb8\\xcf\\xad=\\x00\\x92@\\xb9\\x026R\\xac\\xbe\\xb9\\xa8\\xcc2\\xaa\\x81\\x80Fz\\x8aO\\xb3\\x95\\x00\\x1e\\x82\\x826\\x8e\\xa6\\x98\\x80G:\\xa1`\\x0e\\xdf\\xad$\\xab&A\\x11\\xbe\\xd3\\xdc\\nUr\\xd9U\\x94\\x80{g\\x8a\\x99^\\xedF\\xd4\\x94\\x15\\xf4 \\x1aZ\\x8c\\xaaH\\xdf\\xb7?\\x9d#\\xf0>\\xe5O3H\\xc7\\x05\\x06=\\x85B\\xfb\\xf1\\x9cSB!\\x1c\\xe4w\\xa6\\x80\\t\\xc3v\\xa7n;\\xbe\\xe9\\xc8\\xa5$c\\x18\\xebT\\x80\\x89\\xd5\\nu\\xad\\xed\\x060\\xac0\\xdcf\\xb0\\x18\\x02k\\xa3\\xf0\\xfa\\xae\\xe1\\xc9\\xea*\\x80\\xe8.2f9<\\xd4\\x07\\xadK?27\\xd6\\xa2%Td\\xd3@8\\xe0)-\\xd2\\xa8\\xcd\\x11\\xbap\\xab\\xc2\\x83\\xcf\\xbdL\\xc5\\xa68\\xe8\\xb5\\x8d\\xae\\xf8\\x86=*3\\x05\\xb6\\xd7\\xbba\\xf5\\t\\xeei0\\x1d\\xac\\xeb0\\xe8\\xb6\\xff\\x00g\\x83k\\xdd\\xb0\\xe0vOs\\\\\\x8d\\x94\\xa6\\xe3T\\x8d\\xef$y7>Kg\\x9c\\xd6d\\x93I4\\x8d,\\xae\\xce\\xecrX\\x9eI\\xabV\\xcc\\xcb4l\\x83<\\xf1\\xc6k\\t\\xbb\\xa6\\x8d\\x16\\x8c\\xe9u\\xa7%!\\xb5c\\x1c\\x81\\xdb\\x81\\xd4\\x81K-\\xa0\\x82\\xda \\x06c\\x04g\\x03\\xa0\\xac\\xe8c\\xb8{\\xd3p\\x84\\xb6\\x0e\\x08\\xce8\\xad+\\x9d\\xcfm\\xb9\\x1b\\x04\\x1f\\xbars^t\\xb4i#_3MQD[\\xa3\\xf9\\xa2 d3d\\x9f\\xd2\\x91\\x18 V\\x8b\\x1dxE_\\xc3\\xbdUW>Z2\\xc8\\xe8\\xfd~P\\x14R\\xbb3p\\xceC\\xf5\\xc9o\\xf0\\xaew\\xb9E\\xb6Y\\x1b%d\\n\\xc7\\xa8\\x91\\xb0?AP\\xee\\x0c:\\xacg\\xa1!I\\xc9\\xa4]\\xcc0\\xd9\\x07\\xbb\\x85\\xeb\\xf8\\xd4s\\xb7\\x96\\xa3\\xcd\\x0c\\xc3\\xf8w>\\x07\\xe9@\\x13\\x9c3fM\\xeb\\x8e\\x9c\\xe34\\xe7\\x92\\xce9\\x13\\xcd\\xcc\\xc7o\\x07\\x9f\\x94\\xd5\\x1c\\xb8\\'$H\\x0fB\\xaaN*Dy\\x15~@\\xec\\x80\\xfc\\xf9`\\xbc~u@Y\\x96\\xebp*\\xb1m\\x87\\x1fyW\\x1f\\xa9\\xc9\\xaa\\x92N\\xef\\x96\\xb8t\\x9a!\\xf7U\\x98\\xb1\\x1czb\\x9f\\xbe\\x00\\x01\\x87iQ\\xd4\\x12X\\x93\\xe9\\x83\\x9ai\\x19}\\xd0\\x86G#\\xee` \\xa2\\xe0\\x10\\xcf \\x1f\\xbb\\x0c\\xf1\\xb0\\xf9\\x97h\\x18\\xfc\\xcd?\\x96l#\\r\\xbdJ\\xc8\\xf9\\xfc\\x00\\x02\\xab\\xb0\\x19\\xc3\\x15\\x8eoV\\x93w\\xe1\\xc5(\\x04`0d=\\x9d\\x10\\x0f\\xe9R2\\xccs2\\xb8ky\\x19\\x1c\\x1clU\\xfeG5*\\xdc\\xb3\\xbb%\\xcc9\\x95\\xc9&G\\x93\\x07\\xeb\\xc5T`I\\x0f1\\xeb\\xd1\\xcb\\xff\\x00\\x81\\xa70*\\x9b\\x08W\\x07\\xf8\\xd12G\\xe6)\\x80\\xf7\\x8e2\\xd9\\x88\\x00O\\xa2\\xf3\\xf8\\x9e\\xf4\\xdc\\xb3(y\\xcc\\x84(!W!F~\\x9c\\xd2\\xe1\\xf1\\x95\\xcbF\\xa3\\xbb\\x01U\\xc4\\xed\\xf3\\xc8\\n\\xb1\\x07*\\x1b-\\xf8P\\x84W\\xb9|m\\x08T\\xc8\\xdd\\x8f8\\xac\\xc9r\\xa1\\xa2\\x05\\xb2xlp\\rk\\xb8\\x8e\\xe2M\\x80<\\x138\\xe3#\\xe5\\x1f\\xd6\\xb3\\xaf4\\xf9mr\\x8cb\\x90\\x06\\xcbH\\x8d\\xb8V\\x91@\\xca\\x18\\xda\\xa1\\xd8)A\\xc6\\x0f4\\xcb\\x87\\xc4\\x08FK\\x12GN\\x83\\xb5L\\xd8 .HN\\xa3\\x03\\x19\\xa8\\xe4S\\x90\\x98\\xcb1\\xc8\\x0c\\xdcV\\xa8\\x93*\\xe4nET\\xeb\\xd1\\x89nI\\xaa\\xa1B\\xc4\\xeeXa\\x0e1\\xeb\\xefW\\x9dM\\xb9 \\x00$\\xdd\\x9e\\x9f\\x8dA+\\xf9\\xea#h\\xca\\xc7\\x9c\\x86\\xc0\\x1b\\x8f\\xd7\\xd2\\xa8\\x97\\xdc\\xa1w,\\r\\xb2H\\xd6@J\\xe5\\xb7\\x11\\xd7\\xdb\\xd0{U\\x02Y\\x8e\\x07<\\xd6\\x95\\xdd\\xb8#rFB\\xc6B\\xb3g<\\x9c\\xff\\x00\\x81\\xaaI\\x1f\\xce\\xc4\\x83\\x9cq\\x8aD\\x902\\x12\\xbe\\xe2\\xa4\\x0c\\xc4`\\xfc\\xc3\\xd4\\xd4\\x9eA8*p\\x7f\\x88\\x9e\\x82\\x92H\\xa4L\\x01\\xca\\x9er;\\xd0\\x03c\\\\\\x93\\xb4\\xeebv\\x855a$\\xf2U\\x91T4\\x8c1\\x83\\xd6\\xab\\xa8m\\xdc\\x0e\\xbd\\xc5L\\x14\\xf0\\xee\\xa4\\x9e\\xc6\\x80&\\x88n\\x9bb\\xe4dd\\xee\\xad\\xfb!\\t\\r.\\r\\xbb \\x068\\xd8d9\\xfc\\xab\\x1a\\x103\\x12>v\\xfd\\xe2Ps[\\x96\\xe8\\xf7Xx\\xc3In\\x83\\x93\\xddW<\\xff\\x00:\\xab\\xd8h\\xf4\\xfcw\\xa6\\xb2\\x93\\xcd\\ny\\xc5?wj\\xe15\\x1b\\xb7\\x8e\\xb4\\xecqE\\x1d)\\x8cP2:\\xd2`\\xd2\\xf1K\\xda\\x80\\x1ay\\x14.qN\\xed@\\xc5\\x00\\x1b}i@\\xdb\\xd2\\x8aP}i\\x08NE\\x1dFh\\xe8i\\x07_j\\x00^O4\\x1e@\\xf5\\xa5\\'\\xd2\\x93\\xa9\\xe2\\x98\\xc3\\x1csK\\xd4\\xf3I\\xc9\\x1d(\\xa0\\x00\\xf1\\xd6\\x8fjC@>\\xa2\\x80\\x0e\\x87\\x8a:Q\\xde\\x8e\\xf4\\x00}h#\\x8e(\\xc8\\x14\\n\\x00\\x88\\xc4\\xac\\x98bO\\xbd\\x025\\xdb\\x8c\\x12\\x07@jLs\\x90i1\\xc7\\x14\\x00\\xc2\\xbc\\xf4\\x14\\xc6\\xc89\\x07\\x81\\xd6\\xa5#\\x9f\\xe9Q\\x90\\r\\x007\\x0b\\x8e\\x94\\xc2\\xa4\\xa3(\\x00\\x128\\xf6\\xa5\\'\\xae8\\xe7\\xad2W1B\\xd2\\x0c\\xf0\\xa4\\xe3\\xd6\\x90\\x8c\\x1dM4\\xebiT_\\\\Gl\\\\\\xf0r\\x00\\xcf\\xd2\\xa5K8\\xee\\x93r\\xc5c\\xa8 \\x1fy~G\\xfc\\xc5y\\xbf\\x88\\xfc\\xcdcP3;\\xe0\\xe3\\x1bz\\xe2\\xb3ml\\xeem\\x18\\xb5\\xb5\\xec\\xd0\\xb6\\x7f\\x81\\xc8\\xafR3v\\xb4\\x8c\\x1a\\xd7C\\xd2\\xe6\\xd3\\xbc\\xa2U#\\xbb\\xb6R~\\xe9m\\xeb\\xf9\\xd6N\\xa4V\\xcaUO5\\xd9\\xdf\\x1b~SY\\xf6>\\'\\xd7-\\x11C^\\x0b\\x85\\xf4\\x94f\\xb5\\x13\\xc7\\x13\\xed\\xc5\\xc5\\x84\\x12\\x1e\\xe2\\xb5RV\\x15\\x9d\\xc2\\xd6=E\\xe6P\\x839\\x1b\\x94\\xee\\xc6j\\xfa]^\\xed\\xf9\\x9c\\x82\\xa7\\x05s\\x9a\\xac\\x9e.\\xd3\\xe5P&\\xd3\\n\\x83\\xd4\\xa1\\xe9R\\xc3\\xaexi\\xc9VK\\x88[\\xf1\\xa3\\x99\\x0bR\\xdf\\xf6\\x86\\xa4\\x01\\xdd\\x037nc\\xa4]`\\xa3\\x01-\\xb0\\xe3\\xaeA\\x154Z\\xb6\\x9aX}\\x9fYt\\x1d\\x84\\x9c\\xff\\x00:\\xb5#\\xad\\xca\\xe15\\x0biW\\xdc\\x0e\\xb4\\xd3`\\xd2)\\xc7\\xa8ZH~hp}\\x8d[3Z\\x82<\\xb2G\\x1e\\xb5\\x17\\xd8\\xa5)\\x91\\x15\\xbc\\x80wSP=\\x83\\xe7&\\xd8\\x85\\xc7E4\\xee-\\x0b;\\x95\\xc8)&w\\x1a|\\xb6\\xf2\\x08\\xf2\\xcd\\x8f\\xadf\\x1biT\\xfc\\x8b*\\x90{v\\xa6\\xcdqzP#\\xca\\xe5G\\x18j\\x00\\xb4c`x \\xfd\\r/\\x96\\xdb9_\\xc6\\xb3_\\xcf\\xf2\\xf7+\\x1c\\x8e\\xc2\\xac\\xc7yp`\\x08UkK\\x88\\xb4\\xd6\\xcc\\x8b\\x9e\\rlx\\x7f\\x1fh\\xc1\\xe3\\x075\\x83\\xf6\\x99v\\x80H\\xe6\\xb7\\xf4$V\\x99\\x89c\\x9d\\xbc\\xd3\\xb8#v\\xe9\\xd5\\x1d\\x95y \\xd5Ly\\x87&\\x9d.\\xd8\\x83;\\xb0U\\x1c\\x92OJ\\xe25\\xcf\\x165\\xcb=\\x9e\\x9b\\xc4]\\x1eo_\\xa5;\\xd8h\\xd6\\xd7<I\\x1d\\x90k[2\\x1a~\\x8c\\xfd\\x97\\xff\\x00\\xaf\\\\<\\xac\\xf2H^F,[\\x92\\xc4\\xe7&\\x80\\x1b\\x199\\'\\xd4\\xf7\\xa1\\x81\\xdf\\xfd*\\x1b\\x1a\\x1b\\x1cd\\xa9\\xf7\\xa9`-\\xf6\\x85\\xd8H \\xd0\\xa0\\xf6\\xa7F1( sY\\xcba\\x9d-\\x84\\x04C\\xe6)\\xc3g\\x91\\xd74\\xfb\\xa7\\xde\\x9b>\\xeb\\xe7\\x8e\\xd4\\xdd6\\xe3\\xcd\\xb7\\x08\\xe0\\xab\\x8e\\x9e\\xf4\\xeb\\xb5\\x1f(~\\xa4\\xf0s\\xd2\\xbc\\xe9/x\\xd8\\x11\\xe4\\xf9RU\\xf9\\x8e\\x08|\\xd5\\xac\\x9c|\\xea\\xdb?\\xbc\\xabQ\\xab4Q\\x85\\x90\\xe5q\\xf7\\x80\\xa9\\xb7\\xae\\xce\\th\\xfd\\xcda\"\\x80\\xca\\xe20\\x0eZ.\\xd94n*\\xa1\\x80\\xdd\\xe8\\xa1s\\x8aD}\\x99`A\\x1e\\x98\\xcd&\\xfeIM\\xdb\\x8f8<\\x01J\\xc0Dwd\\xb4e\\xf2NH,\\x06)\\x01G\\xc8\\x8d\\x911\\xd4\\x1c\\x9c\\xd2d3\\x91\\x90\\xad\\xd4\\xf7\\xa6\\xc8\\xe1\\xf3\\xbc2\\x85\\xee\\xa3\\x19\\xa6\\x01\\xbf\\x9ew\\xab\\x03\\xc6\\x06\\x01\\xa9\\x04\\xa5_\\xcb\\x99Wy\\xfb\\xac[v?*\\xaadX\\xcef@\\xe0\\x9f\\x97-L\\x8ef\\x8fv\\xc3\\xbdI\\xe7\\x0b\\xd2\\x84\\x80\\xd21\\xc6\\xf6\\xc4\\xb4\\x84\\xb2\\xf5\\xda\\x98\\xe3\\xd8\\x9a\\x80L\\x14e\\x86\\xe8\\x8f\\x00\\xb3r?\\n\\xad\\xe6\\xb6\\tO\\x99\\x01\\xf9\\x95\\x9b\\x14\\x88wbH\\xca\\xaf\\xfb8\\xcei\\xb4\\x06\\x84s\"\\xf3\\x1b\\x06\\x07\\xf8v\\xe7\\x15*\\xb0\\x7f\\xf5l}\\xc3qYA\\x99\\xb7\\x10Hr~\\x82\\x83# \\nB\\xabwa\\xcd+\\x01\\xa0YX\\x95]\\xab\\x8e\\xa3\\x93M\\x91\\xc1P\\xee\\x187E\\x00`\\x1a\\xa6\\x93\\xb0\\xc7\\x9aX\\x808\\xda1R\\t\\xb27\\xc9\\x82\\xa0aA<\\x8av\\x02\\xb5\\xcc\\xa66c\\xb5ZIz\\x12I\\xc5g\\xcf3\\xf9\\x868\\xf7\\x12\\xc3,Uz~5~f\\xdb\\xb5\\x83\\x8f1\\xba\\x00:VU\\xc22\\x11\\x1a\\xf5?{&\\xb4\\x13\\x019B\\x0f%Tc/\\x83W#\\xb9\\xd3\\x1bOs8d\\xbf\\xff\\x00\\x96[P\\x95o\\xa9\\xed\\xde\\xa9JcVM\\x9bB\\x85\\x1b\\xbb\\xe4\\xd4O0\\xe6g\\xdc\\xb8\\x1f*\\x81\\xd6\\xb4HDWVW\\xd0\\xc2X\\xc0n\"`\\t\\x99>\\xea\\xf4\\xef\\xeb\\xda\\xa2k\\x16{g\\x11\\xc8\\x98\\x89\\x950[\\xe6\\x05\\xbd\\xbd;U\\x83\\xa9\\xb4P\\x83m#\\xc6\\xce\\x0e\\xe0\\x1c\\xfc\\xdd;~\\x15(\\xd5\\xa3\\x98J/\\x1dD\\xb2G\\xcc\\x88\\x83<\\x10Fx\\xaa%\\x99wV\\x8f\\x04\\xf0\\xbaG$\\xb1\\xa2\\x06o\\x90\\xe0\\x91\\x9c\\xd5\\x19-\\xe5\\x8a%\\x9ah\\xccQ\\xc9\\xf3.\\xe5\\xc7\\x15\\xaa\\xf7R_\\x08\\xc4RH\\xf0\\xc2K9\\xce\\x00\\\\\\xf2j\\x8d\\xee\\xa1=\\xc8Ev-\\x14O\\xfb\\xa5\\'4XEx!\\x86F\\t#\\x94\\xdc\\xc1I\\xc18\\xf7\\xa9$\\xb6\\x89\\x11Q\\x0b\\x97\\xdeCg\\x80\\x07jG\\xbd\\xbd\\x92)|\\xc8\\xc7\\x96\\x84? \\x0c\\xe7\\xbdD\\x92L\\xca\\xec\\x06\\x14\\x9d\\xc7\\x8a\\x00\\xd2\\xb7H\\x1cK\\x1a\\xa2\\x85\\x11\\x16@[\\x90@\\xed\\xf5\\xa8-\\xa0F\\xdc\\xcc\\xac\\n\\xf4\\x07\\xa5C\\x15\\xc0\\x8c\\xa3\\x11\\x83\\xd0\\x9fZ\\x9c\\xdc\\xfc\\xe5F\\xe5\\x1b\\xb3F\\x80L\\xca\\xd0\\x16x\\xcb\\xac\\xad\\xf2(\\x1d\\x08<\\x1a\\xb7n\\x85V(\\x801I\\xbb\\xf7\\x8e:~5\\x97\\x14\\xf24\\xc5\\xdc\\x97\\x8dr\\x00\\xcdk\\xe9\\xf7-\\x1c\\x12>\\xc5\\x93\\xcc\\\\\\x15\\xef\\x81\\xe9O\\xcckC\\xd3\\x8a\\x03 ~\\xe2\\x9d\\xd7\\xa5\\x03\\xf1\\xa0pk\\x84\\xd0\\\\\\xf1J9\\x1di\\x00\\xe6\\x9d@\\x08\\x01\\xc5\\x01\\xb0qK\\xd6\\x8e\\xb4\\xc0\\t\\xc5\\x1d(\\x1c\\xf1F{P\\x02\\xd1I\\xc6}\\xe8\\xcf4\\x0cS\\xd2\\x80x\\xa4\\xa5\\xc5\\x00\\x00\\x1a^A\\xa4\\'\\x8e(\\x06\\x80\\x17\\xa5\\x1fJOj^\\x94\\x00\\x9dE\\x1e\\xd4\\xe21\\x83M=x\\xa0\\x00sI\\x9e}\\xe9h\\xc6h\\x01\\x0e\\x05\\x00\\xe0\\xe3\\xb5\\x18\\x04\\xd3O\\x02\\x86\\x02\\x93Hx\\xe6\\x907j\\x1b\\xeb@\\x86\\xb3R\\x13\\xc7\\xf4\\xa5?\\xad4\\x91\\x8c\\xd026\\xe4\\xfd;S&%m\\xe4a\\xd4)=)\\xe4m9\\x1d\\rAxqi \\xe7\\x05OJ\\x04y-\\xdf\\xcfr\\xec\\xbc|\\xc7\\xdb\\xbdW \\xe7\\x8e\\xb5\\xa1v\\xa0\\xddJ\\xc8\\x00\\x1b\\x8f\\x02\\xab\\xec\\xc9$W\\xa1\\x1d\\x8c^\\xe5tV\\x07>\\xb4\\xd9\\x94\\xb1\\xeb\\xcd[)\\xc7\\x14\\xd3\\x10c\\xc5P\\x8ahd\\x03\\xe6\\x07\\x03\\x81Og.r\\x06*\\xd8\\x87r\\x91\\xe9Q\\xec\\xe3\\xa54\\x05Fc\\xc8#\"\\xa4F|\\r\\xb9\\xc7\\xb1\\xab0\\xc7\\x18c\\xe6\\x02A\\x15,b(\\xbe\\xe8\\xfcM\\x1a\\xa0+%\\xfd\\xcc?\\xea\\xe7\\x91y\\xfe\\xf5^\\x83\\xc4\\x1a\\x8cx+{&{\\x83\\xcdQ\\x9173q\\xf9T&\\x1c}{S\\xbb\\x03\\xa0\\x8b\\xc5\\xfa\\x9cY\\xf9\\xe3~9\\xdc\\xb5/\\xfc&W\\x12q%\\xb4l}\\xb8\\xaeh\\xc4{S\\n6=\\xe9\\xa91Y\\x1dj\\xf8\\xba\\x06\\x00Kg\\xb7\\x1d\\xc1\\xab\\xb1\\xf8\\xc3JX\\xb0\\xf6\\xb2n\\xc6xZ\\xe1F\\xed\\xbc\\xfeT\\xe4\\xe9\\xf3r*\\xb9\\xd8Y\\x1dT\\xde6\\xd3!\\x93\\x9bYO\\xe1V,>&\\xe9\\xd6R\\x16\\x16s\\xb7\\xb0\\x03\\x9f\\xd6\\xb8\\xd9b\\x8d\\xdb\\x01r\\x0fAW,4hf\\xb9Q\\x8fs\\x9a\\x14\\xe4\\t#\\xa1\\xd4\\xfcKw\\xe2\\x87\\x97b\\xbd\\xb5\\x99 \\xacy\\xe5\\xbe\\xa6\\xaa\\xc7\\x16\\xc5\\x0b\\x8c\\n\\xd0\\x8a\\xda\\x18m\\xe4\\x8f`]\\xa7\\xe5\\xa8\\xce\\rl\\x81\\xb2\\xb8M\\xa3=i\\xa5pzT\\xce6\\xfd\\xdak\\x1f0\\x96\\xfc\\xe8bC\\x07\\xaf\\x02\\x96\\x1f\\x9eE\\x00s\\xda\\x98\\xdf\\xad,\\x1f\\xeb\\x14\\x1e\\xbe\\xb5\\x9c\\xb6\\x1a6\\xec\\xf2\\xb2\\x88\\xdf\\x00\\xfa\\xd5\\xb9\\xce\\x1dA\\xe4z\\xd5\\x18\\x9c,\\x8a\\x1b\\x9fz\\xb8GB\\x0e\\xe5\\xf5\\xae).\\xa6\\xa8\\x9c3*(9h\\xe9\\x17\\xe5\\x05\\x94\\x0czP\\xaa@\\xca\\xfd\\xda9\\xc8*pGj\\xe6\\x91d\\xe9\\x82\\x9c\\x12\\x1b\\xd2\\xa3r\\x0eT|\\xb2z\\x93L\\xdcL\\x9c\\xf0\\xf43\\xf1\\xb1\\x80\\r\\xd7p\\xa9\\x01\\xcd\\x820N1\\xfcB\\xa2rB\\xe1\\xc11\\x8fSH\\xb20\\x040&:L\\xe4n\\x18+\\xfd\\xdai\\x00\\x85\\n)t\\xda\\xc0\\x9cc\\x19\\xc0\\xa8\\x1a\\xdd\\xc1?gbI9`N*\\xc2\\xcc\\xc9\\xb8\\'\\'\\xae\\xdcR\\x19\\xb2J\\xaa\\x85\\x93\\x1c\\xe6\\x98\\x10\\x05\\x0cr\\x00V\\x1dG\\xad\\n\\x1c\\x10\\xcc\\x19J\\x9e0:\\xd4\\xfb\\xc3|\\xac\\x02\\x91\\xdc\\nV\\x978\\x12.@\\xefE\\x84\\x99\\x0f\\xcc\\xacw\\x81\\x9e\\xcdN\\xda\\xec\\xb8\\x19*z\\xe0S\\xf7mPp\\x19z\\xd4\\x91\\xceA!O\\x04`\\x81@\\xc4[1\\xb7pr\\xca\\x17$\\x13\\xfaUW\\xb79y\\xbc\\xc0\\xa0t\\x00f\\xaf\\r\\x99;F\\x01\\x1c\\x82hy\\xa3q\\xca\\xed\\n1\\xc0\\xebL\\x0c\\xd9\\xf2\\xb0\\x97^_\\xb5eLJ\\xe5\\x7f\\xe5\\xa3\\xf2I9\\xc5k\\xce\\xeb\\x19\\x0c\\xcb\\xd7\\xa6k6f\\x0b\\xc0\\x03{UD\\x96V\\xc8%\\x14\\x93\\x81\\xd4\\x81U\\xee\\x10\\xb4\\xc1\\xceJ\\x8c\\x80\\rZ\\x12\\x05F@\\x9b\\x8f\\xf7\\xbd*\\xb9|\\x9d\\xdc\\x00\\xa7#5\\xa8\\x14\\xfc\\x93\\x1a,\\xbb\\xc0f8P\\x06j\\x9bHco\\x94\\x9d\\xec\\xa4\\x12}*\\xd4\\xb3\\xca>g;v\\xfd\\xc1\\xd2\\xa81c\\xcb\\x9e\\xa3\\x83M\\x10N\\x86\\xf2\\xc9\\x84Q\\x96\\x88L\\xb9<u\\x14\\xf5\\xd5.\\xa3\\x92\\x18\\x8a\\xc5\\xb2&\\xc2\\xe60OZ\\x82{\\xf9\\xee\"\\x8c;\\xe5\\xe3\\xe069\\xc0\\x18\\x02\\xaa\\xac\\xa0\\xc8w\\x82\\xc7\\x9e\\xfd\\xe8\\x0b\\x9dD\\x05\\xee\\xca\\xf9\\x960\\x96\\x97\\x1bN\\xe2\\x14\\x81\\xc7OJ\\x8a\\xea\\xc6M6H#\\xdc\\x93%\\xc2\\x0c\\x858\\xeb\\xc69\\xacE\\x8e\\x7f\\xb2\\xac\\xaf;\\x01\\x9c*\\xee\\xe8(\\x9e\\xeaP\\xb6\\xdf\\xbc\\xdd\\xe4(\\t\\xf3r9\\xcf\\xf8\\xd1p\\xb9f\\xf9c\\x89T2\\xa8\\xde\\xc3hW\\x07\\x18\\xf5\\xab\\x13Z\\xdb\\xee\\x8a6\\xb9Ub\\xa0\\xb7\\xcd\\x9c\\x92j\\x94\\x8dk<\\x98u1\\xee`D\\x83\\xd3\\xd3\\x15\\x14\\xc2 \\x80\\x82I\\xdd\\x90\\xd41\\x9b\\x90\\xda\\xe8\\xf7\\x12\\xb4K|\\xf6\\xd2\\x07\\x03\\xe6\\\\\\xa9\\x1e\\xb9\\xad\\xa4\\xb5\\xb1i\\xa4\\x90]\\x80#\\x04!U\\xe1\\x88\\xc6+\\x8f\\x8d6\\xc5\\xc1\\x0c\\xed\\xc85\\xb7d\\x99u\\x86\\x1f\\x9e\"\\x0b\\x13\\x8cb\\x9a\\x19\\xeaTv\\xa4\\x1cPr\\rq\\x1a\\x0f\\x03\"\\x94S\\x07Zu\\x02\\x17\\xbd\\x00u\\xa4\\xcd(\\xe9@\\x00\\x18\\xe9G\\xbd7\\x90is\\x8a\\x00\\x0f4u4\\x1a(\\x18\\x02:P\\t\\x06\\x83\\xd74\\xa3\\x9a\\x00\\x0fZ\\\\RR\\x8fz\\x009\\xa7S{\\xd2\\xd0\\x01\\x9c\\x82)\\x01\\xa0\\x9aC\\xc8\\xa6!OZ\\x0fJ=\\xa9;\\xd2\\x18\\x9d)\\x0f4\\xa7\\x8a\\t\\xc5\\x007\\xda\\x90\\x8aS\\xebM-\\x9a\\x04\\x07\\xa53\\xb5)4\\xc2q\\xc5\\x005\\xfe\\xb5^\\xe3\\x02\\x07\\xdd\\xd3\\x1c\\xd4\\xcd\\xd3\\x9a\\x82\\xe1\\x87\\xd9\\x9c\\x1e\\xe2\\x80<\\xe7P\\x8c\\x0b\\xa9\\n6T\\x9e*\\xae1\\x8a\\xbdz\\x9b.]{f\\xa9\\xed\\xe3\\x1d\\xeb\\xd0\\x86\\xc6/r.\\x87\\x15!\\x88\\xa2\\xabz\\xd2\\x05\\xc5;\\x99\\x1dT\\x9c\\x05\\xe9T!\\xd1($\\x0e\\x86\\xa2\\x910\\xf8\\x02\\xb5b\\xb1\\xc4_i,\\x02\\xadPx\\xceI\\xea\\t\\xe0\\xd0\\x98\\x15q\\xfa\\x9a{\\xc7\\x808\\xe0\\x8az\\xc0NI\\xed\\xd6\\x9d \\xe0})\\x81\\x0ch\\x1b\\x93Mt\\x02\\xa4\\x0c\\xc0`\\x0c\\x8aksH\\x08\\x88\\xe3=\\xea2\\x99\\xe6\\xa7e\\x1d\\x050\\x03\\x9d\\xa6\\x9a\\x02\\x02\\x9e\\x94m\\xf9qS\\xed\\xc1\\xa4\\x0b\\x91T\"5P\\x08\\x15\\xb3\\xa6\\x7f\\xc7\\xc6G\\\\Vg\\x95\\xf2\\xee\\x15\\xb5\\xa5\\xc4\\xad:\\x8fl\\xd5Gp/\\xca\\xdf.\\rBx\\xcdZ\\xba\\xc6H\\x03\\x80j\\xa9\\x07\\x1e\\xd5\\xba$\\x81\\xf3\\xdb\\xa5)a\\xb3?\\xa54\\xfd\\xfe:Sd\\xc6\\xce:\\xd2e\\x10\\xbb\\xeep\\x07QS\\xc3\\x8d\\xc3\\'\\x93UTr}MZ\\x80\\x06p\\x1b\\xf0\\xac\\xa5\\xb0\\xcd\\x04b\\xb8\\xdd\\xd2\\xae[9VR9C\\xd6\\xabye@\\xee\\xb8\\xa9`;J\\x908\\x1d\\xab\\x9aH\\xb4j)\\xf9\\xb2\\xa7\\x8fJaa\\xbc\\x11\\xc1\\xcf\\x14d\\x11\\xb9x>\\x95\\x1b0-\\xcf\\r\\xda\\xb9\\xa4\\x8b\\x06\\x979\\x0c0\\xf9\\xebMy1\\xf2\\xb1\\xc8\\xf5\\x14\\x8cFpz\\x9e\\xf5\\x1b\\xb8\\\\\\x03\\xca\\xd6v\\x02@\\xc1F\\x07\\xcc\\x95\\x19o\\x98\\xba\\x1c\\x02>\\xedB\\x1b\\x92W\\xee\\xfb\\xd3\\xb0H\\x12\\x0e\\x0f\\xa5RC$b\\n\\x86\\x0cD\\xb8\\xe9I\\xf7\\xce\\xc7\\xe1\\xb1\\x9d\\xd5\\x0c\\x83$g\\x86#\\xad&\\xe6P\\x11\\xb0r>\\xf5\\x16\\x1131^\\x18\\xe5GqH0\\x15\\x9b\\xaa\\x9e\\x82\\xa2$\\x80:\\xb2w\\xa3q \\xb4x\\xc7\\xa1\\xa6\\x04\\xab+);\\x0eG\\xa5I\\x19\\x00\\xee\\xe8\\xd5\\x9a\\xb2\\\\4\\x84c\\x04{T\\xcfm+\\xc8\\x19\\x98\\x8c\\x8a,\\x05\\x99.Fv\\x8e\\xbe\\xb5\\x1c\\x12\\xc9(&n\\x11I\\xc6)\\x12\\xdb\\xcb\\xca\\xf2}M?\\xb63\\x94\\x1dMK\\x19\\x14\\xdf2\\x89Y~Q\\x9c\\x03Y-\\'.\\xe4\\xfc\\xe7\\xa0\\xab\\xf7DI)\\xdaq\\x1a\\xf4\\x07\\xbdg9\\\\\\xb1l\\xf3\\xc2\\xf1U\\x04&1\\xc8\\xc6\\xd4\\xc8v?6i\\x85p\\x13\\xa6\\x01\\xe7\\xde\\x90\\xb1_\\x9b\\x19&\\x92V\",\\x01\\x9e{V\\xc8F|\\xec\\xd2Hr>U\\xe9U\\x18\\xee9\\xedV\\xdc\\x06c\\x8e\\x83\\xadSv\\xdc\\xd9^\\x00\\xed\\xebL\\x86G \\xc2\\x90\\xbd{{\\xd4 \\x81\\x9c\\xf0\\xd9\\xa9dr\\xdb21\\xb4`\\x11\\xde\\xab\\xb8m\\xfc\\xd0\\xc4XY\\x0bE\\x87\\'\\xee\\x9cc\\xd6\\xa1]\\xbeY\\\\|\\xd9\\xeb\\xedNY\\x00\\x8d\\x90\\xaes\\xd2\\x88\\xc2\\x85\\xc9\\xeezP\\x03\\x83d\\x0c\\x1c\\xa8\\xedV\\x17c\\xab\\x1cgi\\xe0{Ue\\x8f\\x82@;\\xbd=\\xaa\\xdc(\\x0cJ\\xa3!\\x89\\xe6\\x81\\x96\\xa1-\\x0cbe 2\\xb6\\x00>\\x98\\xad\\x9b9\\xd2(\\x8bG\\xf2\\xcb 9\\\\VL1\\xac\\xb7\\t\\x13\\x9d\\xa3!I\\xab\\xf6\\x91\\x87\\xba\\xcc\\xbf4jr\\xbe\\xc6\\x9e\\xa3w=X\\x8avr8\\xa6\\x83I\\x9cW\\x11\\xa8\\xee\\xf4\\xa0\\x1aL\\xfaS\\x81\\x189\\xa0Br\\r\\x1d\\r\\x1dE(4\\x00\\x8d\\xc8\\xe2\\x8c\\xe4b\\x90\\x9cRP\\x03\\xbd\\xa9s\\x8ao4\\xecq@\\xc5\\xa3\\xa74ph\\xa0@h\\xcf\\x14\\x1a)\\x8c\\r\\x02\\x8c\\xf1\\x9aJB\\n(\\xcd\\x19\\xa6\\x02\\xd1M\\xcd!9\\xa41wd\\xf3M=h4\\x99\\xcfZ\\x04)4\\xd3\\xc8\\xa5&\\x9b\\x9a\\x00k\\x0c\\x1aa\\xf7\\xa71\\xa6\\x1e\\xf4\\x0cI\\x0f\\x19\\xefU\\xa6]\\xf0\\xb2\\x9fJ\\xb0\\xf5VrLf\\x9a\\x11\\xc5\\xdfF\\x16vS\\xeb\\x9a\\xcf\\xd82kj\\xfa\\x17\\x97s\\x059\\x15\\x95\\xb3$\\xf1]\\x91z\\x19=\\xc86sMe;\\xb0=j\\xcc\\xaa\\xbc\\x10~\\xb5\\x16q\\'=:V\\x84\\x97m\\x10\\xcbar\\x85\\xce\\x10g\\x06\\xb3\\xdd\\x99Tc\\xa0<U\\x9f7\\xcb\\x8f\\x83\\xd7\\x83U\\x98\\x87\\x19\\xcf4!\\x87\\x9aN@\\x18\\xcd&\\xe0\\\\\\x03\\xf8\\xd0c\\xf9\\x01\\x07\\x93Q\\xf3LB\\xb2\\x80\\xc7\\x0794\\xc6R\\r9}M#\\x92\\x0eh\\x00\\x82=\\xef\\x8ei\\xae1!\\xf64\\xbb\\x889^\\xb4\\x81\\xc3?<\\nb#\\xceI\\xcd*\\x8c7\\xb5Z\\x96\\xdc&\\xd6\\x1d\\rW\\xdaW8\\x14\\xc0z\\xe5\\xa3\\xeb\\xc0\\xad=/\\xefg8\"\\xb1\\xd4\\xb08\\xc9\\xad]7\\x05\\xb8\\xab\\x8e\\xe0iM\\xd7\\x07\\xa5@\\xed\\xb4U\\x89\\x87\\x00\\x9a\\xab1\\x18\\x1c\\xf5\\xad\\xae\"\\r\\xd9\\'\\x8ai\\x1b\\x87ZL\\xed\\xe4w\\xa0\\x93\\xb7#\\xadCc\\x1a\\xbc6\\rK\\x0b\\x80\\xe35\\x10\\xe7\\xaf\\xe7RF\\xb9\\x90\\x0e\\xd52\\xd8f\\xaa\\xca\\xdb\\x00?v\\x95X\\x87\\x05zzT\\x11\\x92\\x13\\x9e\\x95$y\\xde\\x19\\x7f#X2\\x8dh\\xc8x\\xc3\\x0e\\x1b\\xd2\\x9a\\xc3$n\\xfb\\xd4\\xd5o\\x94m\\xe0\\xfaP\\xcd\\x93\\x83\\xd6\\xb9\\xa4\\x8b\\x11\\x87;\\x7fZ\\x85\\x94\\xee\\x1c\\xe5GZ\\x90\\x93\\x8d\\xbe\\xfc\\x9a\\x8c7\\xcf\\xc1\\xf9{\\xd4X\\x08\\xca\\xff\\x00\\x10\\xe8\\xbd\\xa9\\xcf?\\x9a\\xbd\\x02\\x91\\xd8P\\xcc\\xad\\xc8\\xce)\\x9c7\\'\\x83\\x9a\\x00\\x88\\xc8\\xc0~\\xf0r{\\xd2\\xee)\\x85\\xc6}M?n8q\\x9an\\x08$\\x81\\xc1\\xa0\\x05G#\\x00\\x1c\\xaey\\xa5\\xf2\\xb1\\xf3\\xfd\\xdc\\xf2\\x053\\x03\\xf8\\x0fN\\xb54\\xb2y\\xfb1\\xc1^(\\x18\\xd4\\xf9\\x94\\x96\\xf9Z\\xae\\t\\x14\\xc4\\xaa\\xc3\\xe6\\xc7Z\\xa6\\x99\\xe47\\x14\\xec\\x95\\xeb\\xc8\\xa1\\x81)fL\\xa8\\xe7=\\xea)\\x07e$\\x83O\\x07h\\x04rMB\\xec\\xc0`pI\\xa9\\x02\\xb5\\xd8\\x0eB\\x8e\\x00\\x195J\\xe3\\x9c1\\x1c\\x03Wf\\x8f\\xf7|\\x1ez\\x13Tn\\x00q\\xb4\\x1f\\x90u\\xab\\x882\\x96\\xed\\xbb\\xc9\\xe9\\xda\\x92B\\xcb\\x17\\r\\xc9\\x14\\xe5U\\xe5\\xb3\\x91\\x8e*7\\xfe\\xf7\\xbf5\\xa8\\x8a2d\\xc9\\xe5\\x83\\x82O5\\x14\\xa3i\\xc1\\xa9\\xe6\\xea_\\xbdTm\\xc7\\x83\\xde\\x9a!\\xee0\\xfc\\xc4\\x06?.*\\x1d\\xc41 q\\xdb5`\\xae\\xd6\\xc68\\xa8\\xdc\\xabF\\x15T\\x02\\x0ei\\xdcDi\\xc7\\xcd\\xd4\\xf3\\x91B\\xbf\\xcc{b\\x93\\x18n\\x94\\xe6\\x87le\\xdb\\xb9\\xe3\\x15 \\xc9V\\xe9\\x89\\x95\\x8e\\x06\\xf5\\xdb\\x9cT\\xaa\\xfeZ\\xbe~\\xf6x\"\\xaa*\\x82B\\x1e\\x9d\\xc8\\xab\\x1b\\x08\\xcfu\\x1d\\xe8\\x04hD\\xd9U\\xc0\\xce\\xf3\\xda\\xb5m@D\\x0b\\x0eJ\\x93\\x93\\x9e\\xbd+\\x12\\xd6VL8#\\xe4<\\n\\xd7\\xb2\\x90\\xe3x\\xf9X\\xfeUI\\x96z\\xb1\\xf5\\xa0r(\\xa3!Mp\\x96*\\xd1\\x9a\\r\\'Zc\\x0c\\x90isI\\x9e\\xd4-\\x00/QJ\\xbc\\x8cR\\x0e\\r;89\\x14\\x00\\xb8\\xech\\xc6(-\\xdf\\xbd 9\\xfa\\xd0\\x02\\xf6\\xa39\\xa4\\x14t4\\x00\\xec\\xf1I\\x9a)\\xa7\\x07\\xa5\\x00:\\x9b\\x9eiA\\xa4\\xc7\\xcd@\\x85\\'\"\\x93\"\\x94\\xf4\\xa6\\xd01\\xd9\\xa48\\xa4\\xa4\\xcei\\x88R)\\xa6\\x9ci\\xa6\\x90\\xc34\\xc2pM/zkz\\xd0!\\xa4\\xd0H\\xc6)\\xc4\\xf1M<\\x8c\\xd0\\x04\\'\\x93U\\xae8\\x8c\\x9ej\\xc9\\xa8\\' \\'=)\\xa0g;{u\\xb5\\x98\\x80:VP*\\xe7w\\xe7W5E\\xd8\\xecG\\xdd&\\xb3\\xc6P\\x8cr\\x08\\xae\\xb8ld\\xc69\\xea?*\\x80)f\\xc69\\xab\\x12\\xa6\\x0ei\\xf1\\x00[>\\x95\\xa5\\xc4T\\x942\\xe0\\x10j\\x1c\\x11\\xde\\xaeN\\xdekq\\xc5Uu(\\xdbH\\xfci\\x887\\x9d\\xa3\\xda\\x86o\\x97\\x9e)\\xad\\xc1\\xa3\\x19RM\\x00\\x00\\xfeUb4\\x8c\\xab\\x82z\\x8e\\x86\\xaa\\xb7LP\\x8cG_Jc\\x11\\xc7\\xcb\\x81\\xebH\\x91n\\x04\\xf4\\xc5(\\x19lv\\xa9\\xb1\\xb4\\xe1)\\x88dR\\x92\\xdb_\\xee\\x8e\\x94J\\xa0\\x12EF\\xc8T\\xd2|\\xc0`\\x9a\\x003\\x83\\x9a\\xd1\\xd3\\xc1W\\r\\xebLHP\\xe9\\xfb\\xf8\\xdcMKd6\\xb0\\xab\\x80X\\xd5\\x90\\x13\\x19\\xf6\\xac\\xf9\\x1f\\'\\x9a\\xbf\\xbf(\\xc0Vd\\xa4\\xee5\\xa8\\xac1\\xcf9\\x14\\xe1\\xc8\\xa8\\xc0$\\xf5\\xfc\\xe9\\xe3\\x8f\\xa5H\\x01\\xc74\\xe8[\\x0e\\t\\xa6\\x11\\xbb\\xa0\\xa9\\x02\\xed\\xc7\\x14\\x98\\xcb\\x88\\xc5z\\xf2)\\xf1\\xbe\\xd6,\\xa39\\x1d*%$\\x81\\x9e\\xc2\\x9d\\x18!\\xc1\\xe6\\xb2hf\\x8cRn\\xc6:\\xd3\\xd9\\xb3\\xf2\\x9e\\xbe\\xb5\\x1ck\\x83\\xc63O8=O5\\xcf=\\xcaBg\\x03\\x15\\x1bp\\xdf)\\xc0\\xa96\\x12\\x0f\\xe7\\x9a\\x8b\\xb9\\xc1\\xe2\\xb2\\x18\\xb8\\xdf\\xc8\\xedH0\\x0f\\xcd\\xc7\\xa59Sw# TdrKt\\xedN\\xc0<\\xb8#\\x9esQ6c^9\\xcd8\\x009\\xce~\\x94\\xd28\\xcfRh\\xb0\\x02\\xfd\\xd3\\x822i\\x03g#\\x18\"\\x9d\\xb4s\\x8e\\xb4\\xd6P\\xc3\\x1d\\xf1HhQ -\\x86\\xe2\\xa4\\xce2s\\x95\\xa8\\x15YX\\x023\\xefR\\xa9\\xf9\\xf1\\xfc4\\x98\\xc7\\x9f\\x94n\\x1c\\x9ak0X\\xc9?x\\x9e\\x94\\xf6\\x19\\x04\\x8c\\x8cv\\xa8\\x9f\\xe6;\\x9b\\xb5$\\x05y\\xdc\\x84\\xdb\\xdc\\xd5\\x19\\x00D\\xda1\\x93\\xd6\\xae\\xce6\\x90X\\xe4\\x9e\\xd5Bc\\xb60\\xd8\\xc9&\\xa9\\x01Si\\xdcB\\xf4\\x06\\xa1s\\x96=\\x85LN\\x01\\x03\\x82j\\x17\\xc6\\xecc&\\xb5\\x11\\t\\x1f\\xbb,}x\\xaa\\xb2\\x11\\x19\\r\\xd6\\xa7\\x99\\x88b\\xb8\\xf9I\\xa5\\x92\\xd0\\x9bC3\\x1e\\xf8\\x02\\x82\\x19M\\xc8?>y&\\xa1\\xc8\\x12\\x8fL\\xf3R62;v\\xc54\\xc6J\\x17#\\xa1\\xc5\\x02\\x1a@\\xf3\\x0e\\x0f\\x19\\xebA\\xdcS\\x9e@\\xa6\\x9c.3\\xd2\\xa7\\x88\\x17\\x8b\\xcb\\xc6pI?J\\x00\\x8b\\x85\\x05\\x87S\\xc8\\xab\\x08ZA\\x14k\\x80X\\xd4 \\x06<\\x1e\\x95:\\xaf\\xefA\\x1cb\\x80,\\xa4{\\xe5T^+N\\xd9\\x83\\xba\\xa3p\\x13\\x1c\\xfa\\xd5\\x0b<lun\\x1b\\x9c\\x1a\\xd1\\x18\\x84\"\\x9eKqAG\\xa9\\xb1\\xe2\\x90\\x9c\\x81H\\x074c\\r\\\\\\x86\\xa3\\xc6Xc4`\\xa9\\xc5!;H\\xa5\\xcey\\xa0\\x05\\xc6)}\\xe9)E\\x02\\x0e\\xd4\\xa0\\xf1M\\xcd-\\x03\\x14\\x1aN\\x86\\x94r)z\\x8cP!;R\\x8eh\\x14\\x0e\\x94\\x0c3\\xda\\x93\\xa5.(\\xa0\\x04=iA\\xa4\\xcf84w\\xa6\\x02\\xe6\\x92\\x83HNE\\x02\\x13\\xa5%\\x04\\xf1J\\xa4\\x03\\xcd\\x00!4\\x84\\xd0\\xdfx\\xe2\\x92\\x90\\t\\xd6\\x90\\x9c\\x1aPGJin)\\x80\\x86\\xa2v=\\xaaBx\\xa8\\x88\\xc5\\x004\\x9c\\xa9\\xaa\\xf2|\\xd1\\xb2\\xfbT\\xedU\\xe6\\xe0g\\xd2\\x9a\\x06a\\xdd\"\\xb4r\\xab\\xe0c\\xa5b\\x91\\xf3b\\xb75\\x1c0\\xc2\\xf5\\xacr\\t$w\\x1cV\\xf1fr \\x90\\x93\\xef\\x8a`$\\x1c\\xd4\\xb2.\\xd3\\x8cu\\xa8H9\\xe2\\xb5D\\x88[?ZB\\xe1\\x9b,8\\xa9\\xbc\\x92\\x00oZ\\x89\\x87j\\xa0$1F\\xd1\\xe7\\x1d*\\t#\\x1f\\xc3Mm\\xcb\\xc1\\'\\x14\\tJ\\xf5\\xe9L\\x08$\\x07<\\xd01\\x8a\\x97p~\\xd4\\xd1\\x16\\xec\\xd3\\x10\\x91\\xc83\\xcd:\\x16\\xcd\\xc0\\xcfBx\\xa8\\n\\xedb*{5\\xdd8\\xf6\\xa2\\xe3\\x16\\xe0\\xe2CP\\x96,\\x01\\xa9/\\xbeYx\\xfc\\xaa\\x11\\xca\\x03M\\t\\x93\\xa4\\xc4&\\xdf\\xe1\\xcfJ\\xd2\\xb6\\x00\"\\x91X\\xe9\\xf5\\xad;6\\xc2\\x81W\\x10/\\x86\\xd8\\t\\'\\xadP\\x97\\x96j\\xbb \\x05sT\\xa5\\xab\\x10\\xc8\\x8e+E \\x8f\\xec-!\\x1c\\xfa\\xe7\\xa5P\\t\\x81\\x9e\\xb4\\xf0\\xcd\\xb0\\xa6x\\xf4\\xa4\\x02.\\x01\\xcex\\xa9\\x9eE}\\xa0\\x0e\\x82\\xab\\xb7\\x03\\x1d\\xa93\\xe9I\\x81iO\\x1djE\\x90\\xab\\x0cUx\\xdb\\xb1\\xedR\\xe78\\xe7\\x8a\\x863A[\\xa3\\x0e\\xb5&\\xfd\\xca2y\\xaa\\xb1\\x9fJ\\xb0\\xbfw\\xde\\xb9\\xe6\\x8aC\\xd1\\xf0\\x08 \\xf3L8S\\xc60i\\x0b\\x01\\xc7$\\xd3[9\\xe0Vv(\\x91\\xa5\\xf9B\\x8a\\x88\\xb1g\\xe7\\xa0\\xa1\\xc6y\\x1d\\xa8\\x18$\\xf1A\"\\xb7\\x07\\x93\\xc57$\\x1ass\\xcf\\x18\\xa6\\x0co\\x04\\xf23\\xd2\\x9d\\x82\\xe3\\x88$g\\x184\\xd0p2\\xc7\\x9a\\xbf\\xa8\\x08\\x95\\xf1\\x18\\x1ftV{\\x93\\xb7\\x9e\\x0fAR\\xd1C\\xa3\\x97\\xe7\\xe9\\xda\\x9c\\x0e\\xd7S\\xc63\\x93PD6\\xa1\\xceO5);Pc\\xa8\\xa9\\x1a,\\xe3\\xcf\\x97j\\x12x\\xcdVe;\\x89<\\x01RE)\\x8d\\x86\\x0fn\\xd5^i2\\xa1q\\xdf9\\xa0dR\\x9f2L\\xf6\\x1cU;\\x8f\\xf5\\xbe\\xd9\\xab\\xd1\\xa0rG\\xa0\\xac\\xeb\\xc3\\x89\\xf6\\x83\\xc0\\xaaBeY\\x0e\\x01l}*\\x1eW\\x93\\xd4\\xf3V\\t\\x0c\\x8cH\\xc6\\xda\\xae\\xef\\x9c\\x13\\xf4\\xabB!\\x90\\x06\\x00\\x0e\\xbdi\\xb2L\\xed\\x08Bp;\\x81H\\xe7\\x15\\x1b&FGzb!a\\xbb\\x00v9\\xa6\\x92\\xca\\n\\x9f\\xbb\\xd6\\xa49S\\x8al\\xa0\\xe0\\nB#e\\x04\\x02jh\\x9f\\xc9W\\xc0\\xe5\\xd7\\x1fNi\\x812\\x99\\xa7\"\\x16\\x19\\xf48\\xa0B\"\\xe1\\xc0\\xce\\x0fZ\\xb3\\xe5\\x87\\x90\\x008\\xeej8\\xd3\\xa9=H\\xa9\\xa2;\\x03\\x06\\xe4\\x9e\\x94\\xc6On\\xa0?\\xcd\\x9d\\xa0\\x8ekA\\x06\\xe9\\x84\\x80\\xfc\\x8b\\xd2\\xa9\\xc4|\\xb8\\xc8\\xc6KU\\xd8\\x97\\x11F\\x07$\\x8c\\x91M\\x02=G\\xbd)\\xe9\\x9aJ\\\\\\xd7\\x19\\xa8\\xc229\\xa7\\'Jk\\x1c\\x1ap\\xech\\x18\\xb4\\xb4\\x1e\\x94\\x94\\x00\\xb4\\xa2\\x93\\xa5\\x19\\xc5\\x00(\\xe0\\xd1\\xde\\x90\\xd0(\\x10\\xec\\xe2\\x97\\xb52\\x8c\\xd01A\\xa5\\xcf4\\xda3L\\x07RRQH\\x05\\xcd6\\x83E\\x02\\x13\\xad\\x18\\xa5\\xa2\\x80\\x12\\x90\\xd2\\x9ai\\x1d\\xe9\\x80\\x86\\x98jE\\x00\\xf5\\xa8\\xcfZ\\x00kr3Q\\x92M=\\x8f\\xbd0\\xfa\\xd01\\x87\\xde\\xab;z\\xd5\\x869\\x15Y\\xc6A\\xf6\\xaaBf.\\xa5\\xb8J\\x19G\\x15\\x9a\\xfc\\x92\\xde\\xf5\\xa7t[s\\x06\\xac\\xd7\\xca\\x9d\\xbf\\x8dk\\x14f\\xc8\\xd97.i\\xa6 \\x13$\\xe3\\x1d\\xeaGl\\'\\x15\\x0bHZ<~5\\xa2\\x11\\x1c\\xd3av\\x8e\\xd5\\x089\\xe6\\x98\\xd9/\\xcd\\x04\\x95\\xe9Z!\\x0b!\\xdcx\\x15\\x13t\\xc5?\\'\\xbd5\\x8f\\xcb\\xd6\\x8b\\x80\\xc1\\xc1\\xa7\\t\\n\\x1e\\xbcR\\x11\\xed\\xc5F\\xf9\\xa6\"\\xda\\xc4\\xb7)\\x91\\xd7\\xd6\\xadiP\\xf9W\\x0e\\x92\\x8e}k6\\xd2\\xe4\\xdb\\xca\\t9_J\\xd9\\x93l\\x91y\\xc8z\\x8e\\r&\\xc7\\x17ff\\xeaJ\\x05\\xcbm9\\x19\\xaaX\\xe3\\x02\\xa5\\x9d\\x8bHri\\x11r\\rR\\x11\\x1ad\\x12kN\\xcc\\xfc\\x9c\\x9ek8!\\x078<\\xd5\\xdbB\\xdb\\xbbU\\xc4F\\x86\\xec\\x0ey\\x15Z\\xe1\\x818\\x02\\xa5v\\xc2\\x1a\\xa2I-\\xd75`Z\\x89\\xb2\\xb84g\\x9aH\\xfaS\\x88\\xc78\\xeb@\\x0c~M)\\\\\\x0e(\\xc8\\xc5&\\xec\\xd0!\\xe89\\xe6\\xac\\x8c\\x06\\xe2\\xab-O\\x10\\'\\x07=\\xea\\x18\\xd1e8\\x19\\xa9\\xd4\\xf7\\xc5WL\\x90I5(#\\x83XL\\xb4?\\xa9\\xa3\\x85\\x14\\x9b\\xb03M\\xdf\\xcf5\\x9a\\x06\\xc5\\xe4t\\xa4\\xecE.\\xeex\\x14\\xa4\\xf1\\xe9T\\x90\\xae\\x1dc\\xc6*>ry\\xe2\\x9c\\x1b\\x8c\\x1ah\\xa1\\xc4B\\xb6[\\x0cI?\\x8d$\\xcc\\x19\\xb7\\x0c`t\\xa5a\\x84\\x035\\x0eA\\x1e\\xa2\\xa1\\xa2\\xd0\\xe5b\\x01bz\\x9aq;A=rj&n1\\xd0Ss\\x9eI\\xe2\\xa5\\x94N\\x0e\\x13=\\xf3QHF\\xc1\\x93\\xce{Q\\xd4\\xe4v\\xa6\\x13\\xc1\\'\\x1e\\xd5(de\\xd9:w\\xaaw$\\x96\\x1e\\xa6\\xac?\\x00\\xb1=8\\xaaR1\\x01\\x9b\\xbe8\\xab\\x065\\x80\\n\\x17\\xd4\\xe6\\xabJ1\\xc0\\xf5\\xa9\\x99\\x89\\xdb\\xcf\\'\\xad6p\\x15@\\x04\\x92z\\xd5\"J\\x8e3\\xc9\\xe9Qy\\x98\\xcdO\\'<zUvS\\x90\\x07zb\\x1b\\xbb.[\\xb5&Cs\\x9e*Y\\xe0\\xd8\\xe21W>\\xc0\\xb0\\xd8y\\x8cy\\'\\x8a-q\\x15%#\\xe5\\xdb\\xd0\\x8aU\\x01N\\x05C\\xcex\\xedR\\x8e\\x01jH\\x11,cq\\xce8\\xa13\\xe6\\x13\\xd8Scm\\xab\\xf5\\xa9\\x06\\x01\\xc7s\\xda\\x80,Z\\xfc\\xd2n\\xfe\\x11\\xcdh[\\x0c\\xb1c\\xd0t\\xac\\xc8\\xb2\\x8c\\x02t=sZJ\\xd9@\\x8apGQMn4z}.i\\xa6\\x8e\\xb5\\xc8h\\x04\\xe4\\x1ar\\xf2* N\\xecT\\xaaq\\x9a\\x06.i)(\\xceh\\x10\\xe3\\xd2\\x90\\x1eh\\x07\\xd6\\x8e\\xf4\\x00\\xb4f\\x83I\\xd6\\x80\\x1d\\x9a\\x0fJJ(\\x00\\xa2\\x8a)\\x80g\\x14\\xa3\\x9aJZ@\\x14\\x82\\x8a)\\x80\\x1aC\\xd2\\x8c\\xf1I\\x93@\\x0bM\\xcf\\x14\\x84\\xd2\\x1e\\x94\\x00\\x1e\\r0\\xd2\\x93M\\'\\x14\\x00\\xd2I\\xa8\\x98\\xe0\\xd4\\x87\\xda\\xa34\\x00\\xc2F*\\xb4\\xad\\xb78\\xa9\\xd8\\xe3\\xa5U\\x91\\x89\\xe2\\xa8Fm\\xe9\\xdc2\\xbc\\x9a\\xcbl\\xb0\\xe6\\xb4\\xae~B}+=\\x80\\xe7\\xde\\xb4\\x8b%\\x95\\x9f\\xaf4\\xd1\\x82\\xde\\xd5+\\xe0\\x8a\\xaer\\xbdkBY\\x1c\\xca7\\x9c~\\x15\\x18\\x19\\x18\\xa9\\x18\\x16jGS\\x19\\x15i\\x88\\x89\\x862\\r4\\xa7CR9\\x0c3L\\x07\\x19\\xcd4\\x03X\\xe3\\x14\\xd1\\x86\\xe2\\x87\\xeb\\x9aE\\xe0\\xe6\\x98\\x0cu\\x03\\xa5[2\\x98\\xad\\x00\\x06\\xaa\\xbf\\xd2\\x9c\\xf2\\xef\\x8c-\\x02#\\xdd\\xbb\\xadI\\x0b\\x00z\\xd4 sF0\\xdfJ\\xa04\\x88V\\x8b#\\x14[\\xe1[8\\xaa\\x91K\\x81\\x8fZ\\xb3\\x11 \\xe75hL\\xb5)\\x1e_QTI\\xc3q\\xcdK#\\x9cT#\\xaf&\\xa8E\\xa8\\xdb\\x8a\\x99Aj\\xa9\\x13s\\x8c\\xd5\\xa8\\x9c)\\xa6\\x04l\\x08lP\\xa9\\x96\\xa9\\x18\\xefl\\xf6\\xa7\\x85\\xd88\\x14\\x98\\r\\t\\x83\\x8c\\xd4\\xe9\\xf70j\\x1d\\xc4\\xb7j\\x91O\\x15,\\x11:\\xb0\\nT\\xf1OS\\x93\\xc9\\xa87dq\\xcd<\\x13\\xf4\\xacf\\x8a&\\xc7q\\x9a\\x00\\xe0\\x93M\\xceGZ\\x7fU\\xcdB@\\n2\\xd4\\xaf\\xc04\\x88Ni\\xddj\\xd2&\\xe4D\\xfc\\xb8\\'\\x9aw@=\\xe9\\x08\\xc5(S\\x8ehc\\xb8\\xc7\\xcfJA\\x11pTu\\xc7jv0rjKyDbL\\xe0\\x1cqY\\xc9\\x16\\x8aepv\\xf5\\xa0\\x93\\x808\\x14\\xe7}\\xceq\\xd7\\xd6\\xa3\\'\\x19\\xcf\\\\\\xd4\\x16<\\x11\\x9cg\\x8a\\x8ee.\\xd8Q\\xc0\\xa0\\x9c\\x0e)U\\xc2\\xa9\\x04\\xf3R\\x04\\x0cIP\\x0f\\x15NU\\xcf\\xb8\\xabN\\xdb\\x8e\\x07n\\xf5^rw\\x01\\xf8\\xd5  U\\x1b\\x87\\xa6i\\xce\\x80\\xee>\\x94\\xd6#44\\x80\\xa1QT\"\\xa9\\xe0\\x92y\\xa4\\x95p\\x81\\x87\\x06\\x9e\\xcb\\x81\\x9e\\xd5\\x14\\xae\\x18`\\x1ab\\x12iKmv?0\\xebR\\\\]\\xbc\\xb0*t\\x00Uf\\x05\\x8f\\xb7zV8\\\\R\\x10\\xe8Sw\\xf3\\xa4\\xc0\\xce3N\\x8d\\xca`\\xe7\\xa8\\xc57\\xab\\x1fZ\\x10\\xd1$cq\\nzt\\xa7\\xec`\\xfb\\xb3\\xc55[`\\xcey\\xab$\\xaa\\xc6\\xa0\\x00s@\\x89\\x14*\\x8f3\\x1e\\xf8\\xa9\\xa0,X\\xfa\\x9a\\x85\\xd8\\x96\\xda:b\\xa6\\x89>jhg\\xaa\\xfbR\\x0e\\t\\xcd 84\\x13\\x9ek\\x90\\xd4kp\\xf5.r*\\x13\\xd7\\x9a\\x95zP!y\\xc5\\x02\\x92\\x97\\xb5\\x00\\x07\\x8a:\\xd2c4\\xa3\\xad\\x03\\x17\\x9a\\x05-%\\x02\\x16\\x81IE0\\x16\\x81IK@\\x01\\xa2\\x8aBh\\x01i\\t\\xc5\\x04\\xf1\\x9aa9\\x14\\x00\\xa4\\nS\\xc8\\xa6n\\xc8\\xa4\\xdd\\x8a\\x00\\\\\\xd2\\x1a)(\\x01\\xa4\\xd2\\x1eiH\\xa8\\xc9\\xc1\\xa0\\x04&\\x98\\xdd=\\xa9\\xc4\\xe6\\xa3s\\xf2\\xd0\\x04o\\xd2\\xaa\\xcd\\xca\\x9cu\\xab\\'\\xee\\xf3U$n\\xb9\\xe8*\\x90\\x19\\xd3s\\x955FA\\x83\\xcf\\xa5h]\\x00yZ\\xces\\xbb\\xafj\\xd1\\x12D\\xe3\\xd2\\xa2a\\xb9jV8\\xe3\\xd6\\xa1oQZ\\x12\\xc8\\xc0\\xc3Q\\'=;\\xd1\\x9e\\xf4\\xc2GCTH\\x8c\\xbf.{\\xd4\\'\\xae*b\\x7f*\\x88\\xf0j\\x80a\\xe0S\\x01\\xe4T\\x87\\x14\\xc2q\\xd2\\x84\\x00\\xe3\\x8fz\\x87\\x18\\xcdHN~\\x94\\xc3\\xc5P\\x08\\xbdiXd\\xe74\\x8a\\x07ZB}\\xe9\\xa2G\\xa0\\xfc\\xaa\\xd4m\\xc8\\x15YN*e\"\\xad\\x08\\x95\\xf0\\x0esQn\\x04\\x9a{\\x1c\\xf0i\\x8b\\x80I\\xaa\\x04H\\x9d~\\x956x\\xa8W;\\xaau\\x04\\x90i\\xa0\\x1f\\x9e\\x01\\xa9U\\xb7\\n\\x8d\\x80\\xa1p:w\\xa4\\xc0\\x90\\x8d\\xd4\\xe4R\\xb9\\xedMS\\xc9\\x06\\x9d\\x9f\\xd6\\xa5\\x80\\xa3\\xaf\\x15(\\xe0f\\x91\\x00\\xc9\\xa7\\xa8\\x1f\\x85e!\\x8a\\xa7\\xd7\\x81R\\x13\\x91\\xd7\\x8adi\\x93\\xc5HG\\xcb\\x82)!6\\x0bN\\x07\\x9a\\x8cg\\x91R\\n\\xb4\\x88l\\x0e\\r\\x07\\xee\\x9a\\r#r\\xb4\\x9a\\x1ac\\x1c\\x8d\\x98\\xcd@\\xd8\\xcd=\\xc9\\xcfJ\\x8d\\x89\\xe8k)\\x1a\\xc5\\x8603\\xc0\\xa8\\xc9\\xdcriY\\xf8\\xfaTa\\xf3\\x8fJ\\xcc\\xd0\\\\\\xe3\\x9ac\\x9c\\xe4\\x8a\\x19\\xb2q\\x9e*&o\\x9f\\xa94\\x80ab2j\\xb9\\xe9\\xcdZ\\x90\\x02\\x06\\x05A\\'##\\xd2\\xa9\\x01\\x03v\\xc5G\\'\\xca\\r)\\xe4\\xf1H\\xed\\x90s\\xd2\\xa8D%\\xbe^zR\\x04$n\\x14c\\xaf\\xa6je\\xc0C@\\xacW\\x03\\xb1\\xe6\\x99\\'\\x07\\x15#\\x0eG\\xadF\\xe0\\x93\\x8cR\\x10\\x84\\xf1\\xedB\\xfd\\xf2\\xd4\\x85H\\x14\\xf5^1@\\x0e\\xc6\\xfe\\xd5$d\\x922x\\x1f\\xa5\\x05p\\xb8\\xa4\\xce\\xcc\\x0cpi\\x8c\\x97y\\xf3\\x0bw\\xedZ\\x10\\x81\\x8d\\xfd8\\xac\\xf8\\x86\\xfc\\n\\xd1\\x8f\\xe6\\x01\\x07jhg\\xa8\\x11I@\\xa5\\xae3A)\\xc7\\xa5!\\xa5\\xed@\\x06x\\xa5S\\xd6\\x9bJ(\\x10\\xe1KM\\xcd\\x00\\xd0\\x03\\xf3I\\xde\\x92\\x90\\xd0\\x02\\x9aZnsK\\x9a\\x00;\\xd2\\xd2P94\\x00\\xb4\\x87\\x9aZC\\xd6\\x98\\tND\\xdc\\xb4\\xd3\\xd2\\x91d\\xd8O\\xbd\\x00!\\\\\\x1ai\\xa7\\x13\\x964\\x86\\x98\\x08\\x0f8\\xa4n\\r\\x04s\\x9a\\t\\xa4\\x03I\\xc8\\xa8\\x89\\xa7\\x1a\\x8c\\xf1@\\r\\'\\x00\\x8a\\x89\\x98\\xe4\\xd4\\xcc\\x01\\xa8\\x8f\\\\P\\x80\\x8d\\xdb\\x8e:Ug`y5;q\\xd6\\xabLp3T\\x80\\xa19 \\x1c\\xf4\\xcf\\x15F\\\\g\"\\xaf\\xdc|\\xebY\\xe7\\xd0\\xf6\\xabD\\xb2&5\\tn\\xb9\\xe2\\xa4s\\x83\\xedQ79\\xad\\x10\\x88\\xc0!\\xbd\\xa9\\xac\\xbd\\xeaL\\x1fJf9\\xebT\\x89b\\x01\\xc5F\\xdd\\x7f\\n\\x92\\x98\\xf9\\xcf\\x14\\xee\\x04\\'\\xaf\\xd6\\x90\\xfaT\\xa5p*<s\\xc8\\xa7q\\r\\x1c\\x0eE1\\x86\\t\\xa9[ TG\\xd3\\xbdRb\\x1a{\\xd0\\x06NM)ZA\\x8cb\\xad\\t\\x8b\\x8f\\x9b\\x8a\\x95zT \\x9c\\xd4\\x89\\xc1\\xc7\\xadR\\x11!a\\xc5\\x19\\xe7\\x14\\x11\\xc6zS\\x01\\xe7\\x9a\\xa1\\\\\\xb5\\x12\\xee\\xe6\\xa7\\x03\\x03\\x02\\xab\\xc0\\xd8\\xab\\x1b\\xb3\\xd2\\x9a\\x00\\xdd\\x8cR\\xf7\\xa6\\xfdz\\xd2\\xf6\\x14\\x98\"@r8\\xa5 \\x8eqM\\x8c\\x80\\xdc\\xd3\\xd8\\x9c\\xd4\\xb1\\x8eV\"\\xa6\\\\\\x8a\\xae\\xbc\\x8a\\x99_\\x8a\\xceAr\\xccd\\x04\\xc04n8\\xc5D\\xa7\\xde\\x94\\x93\\x8f|\\xd0\\x91\\r\\x92\\x0fZ\\\\\\xd2(\\xc8\\xa7\\x00EZB\\xb8\\x1fji$qO\\x02\\x93\\x1c\\x93C@\\x8a\\xb2\\xb9\\x07\\x1e\\xb5\\x1ejY\\x90\\x16\\xe0T\\x04\\xe0V\\x12F\\xf1\\x18\\xe5\\x88\\xedQ\\xf7\\xa9\\t\\xe6\\x9a\\xdc\\x1a\\xcd\\x9a\\x0c\\x04\\x83\\x8ak\\xf2x\\xa7\\x11\\xd4\\x93P\\xee\\xf9\\xf3\\xda\\x90\\x0foAU\\xa48B;\\x9a{\\xb1\\x00\\xe2\\xab3\\x1c\\xe5\\xbb\\xd0\\x80i8\\x00\\x03L-\\x81\\x8fZwQ\\xcdC\\'|U\\x08v\\xe1\\x8ei\\t\\xc1\\xc5Fr\\x00\\xa5=8\\xf4\\xa6\\x848\\x9f\\x9b\\x14c\\xe6\\xcdB_\\r\\x9c{S\\x8b\\x8c\\xf0h\\x10\\x87\\x96\\xa9W\\xa7J\\x84>N*A\\xe9\\xedH\\x07\\x16\\xcb\\xee \\xe0v\\xa6\\xb1\\xf3\\x1b\\x83\\xd0\\xd0\\xec\\x14\\x85\\xceI\\xa5E\\xc1\\xed\\xd0\\n`\\x89\\xed\\xfeBx\\xab\\xf6\\xe4\\xe4\\xb1\\xeb\\x8e*\\x9ck\\xf3U\\xc0\\x99A\\x8e\\xbd\\xa9\\x8c\\xf5\\nu\\'Z;W\\x19\\xa0\\xe03I\\xd2\\x90\\x1cR\\x9ey\\xa60\\xce(\\xcd\\'Z3@\\x85\\xcf4\\xb9\\xa4\\xa2\\x80\\x174f\\x8c\\xe2\\x93\\xbd \\x16\\x94\\xe7\\xad\\'\\xbd\\x02\\x98\\nM\\x03\\xad\\'CA4\\x00\\xec\\xd2\\x1eM >\\xb4d\\x83@\\x0b\\xda\\x98F\\r;<Py\\xa0\\x06\\xd1\\x9aJ(\\x00\\xa8\\xd8\\xf3Nc\\x8ai\\'<S`0\\xf3Q\\xb1\\xe6\\xa5a\\x8aa\\xeb\\x9a@FMF\\xf9\\xddR9\\xa8\\x89\\xc5;\\x01\\x14\\xbc\\xd5G<a\\xbaU\\x868<\\xd5i\\x97\\xb8\\xebM\\x08\\xa9.\\x17\\xbf\\x02\\xa9H:\\x91W$9C\\x91TX\\xe0\\xe3&\\xad\\x08\\x81\\xcf&\\xa2\\'\\x07\\xe9R\\xc82I\\xa8H\\xad\\x10\\x85\\xc8\\xc5D\\xdc\\xb5;\\x9aa\\xf6\\xa6\\x84\\x1d\\xbaS\\t\\xc3{R\\x93\\xc1\\xa6\\x9e\\xd4\\xc4)\\xc6\\xdei\\x8d\\xc7ZwZcR\\x10\\xc6\\xe9\\xefL\\xc7\"\\x9cFX\\x9aB+D =*0y\\xe2\\x9f\\xc9\\x15\\x1bu\\xabBd\\xaa\\x07z\\x14|\\xf4\\x8a\\xdf.1RFy\\xcdZ$s\\x8c\\x0f\\xc2\\xa2\\x03\\x9a\\x99\\xceG\\xd2\\x925\\xf9\\xe9\\x88T\\xca\\x9fj\\xb2\\x879\\xa8[9\\x03\\xb5J\\x84\\xe3\\x15Hc\\x8d&s\\xda\\x93<\\xd1I\\x88\\x90\\x1a\\x90\\x1f\\x97\\x9e\\xb5\\x08\\x184\\xf0{T\\xb1\\x92%L=*\\x18\\xc9\\xcf4\\xf2\\xd9j\\x86\\x04\\xa8\\xc7}J\\xdc\\x9a\\x8a \\x08\\xc9\\xebS\\xaa\\xe3\\x04\\xf4\\xa6\\x91\\x0c\\x9a%\\x0c\\x9d)J\\xf3\\x8aX\\x9b\\nE+\\x1a\\xb4E\\xc8\\xf8\\xcd#\\x1e(\\xe9I\\xf5\\xa6\\xcaDL9\\xcej\\xa4\\xab\\x87\\xabG\\x86?Z\\xa99\\xf9\\xab\\x9eGD\\x08\\x89\\xc9\\xa66s\\x82i\\xc4sL\\xcf5\\x934\\x11\\x9b\\'\\xbe)\\x83\\x9aS\\xc1\\xefH\\xff\\x00w\\xd0\\xd4\\x8c\\x8d\\x86\\xe3Q\\xcc\\xbc`S\\xb3\\xb4\\xd4r\\xe7\\x82)\\x88\\x8fo\\xbdB\\xc3\\'\\x8a\\x9bp\\xcf=j689\\x14\\xc4\\xc8\\x9b\\x91\\xfd)\\xaas\\x93O?v\\xa1\\x07\\x01\\x86)\\x88\\x18\\xe5\\xa9\\x87\\x04\\xd2\\xb6s\\xc54\\x9a\\x04(<\\xd4\\xf1\\x9e\\xad\\xd6\\xaa\\xe7\\x9cU\\x88\\xce\\xd5 \\x9e\\xb4\\x98!\\n\\x96!\\xbd*H\\xdb\\x9esL\\xcf\\xcc=\\xe9\\xd9;\\x80\\x1c\\x13B\\x17R\\xd4/\\x99E[\\x8aL\\xa8lt5Ip\\x01&\\xac&\\x04]z\\xd3-\\x1e\\xb0(4\\x99\\xe6\\x97\\xadr\\x16\\x14\\xb9\\xa4\\x1dh\\xa0a\\xd2\\x8e\\xf4\\x11\\xc6i\\x051\\x0e\\xa2\\x92\\x96\\x81\\x85(\\xa6\\xd3\\x85!\\x07lR\\x8e\\x94\\x86\\x8ah\\x05&\\x90\\x1a)\\x05\\x00-\\x07\\x9a3I@\\x0bI\\xceh\\xcd&h\\x01M%&i3\\xcd\\x03\\x03I\\xd2\\x91\\x88\\xa6\\x93\\x9ab\\x07\\xe9\\xebP\\x921R\\x13P\\xb9\\xa4\\x02\\x1e\\x86\\xa2a\\x8e\\xb4\\xf2\\xdcTL\\xd9\\xebT\"\\x19\\x0eN}*\\x079\\x1c\\xd4\\xaf\\x9ej\\t9Ri\\x8c\\xa71\\xc3g\\xb5SrX\\xe6\\xad\\xb8\\xc89\\xe9UYv\\xe3\\x8e\\xb5H\\x92\\x06\\xe9Q\\x1e\\x9d*G\\xe9\\xf8\\xd4MT!\\x9dI\\xa67\\x14\\xec\\xf1Q\\xb7\\\\\\xd5\\x00\\x9f\\xca\\x90\\x8fJ\\x0f\\x07=\\xa8\\'\\x83LCwc\\xafjk\\x1c\\xd2\\x13\\xceh\\xc9\\xa0B\\x95\\x04g4\\xc2y\\xf6\\xa7\\x13\\x85\\xa8\\xf29\\x15h\\x91\\xb9\\xe2\\x94\\x8a\\x07\\xe9Js\\x8a\\xd2$\\xb1\\x14S\\x86T\\xd2.\\x07\\x14\\x85\\x8e8\\xabD\\x92\\x83\\xb8\\xd2\\xe7\\x07\\xafJE\\xe3\\x14\\xd3\\x92i\\x81qFFM(\\x1c\\xe0T\\x02R\\x1b\\x1d\\x85O\\x11\\xce)\\x816\\xc0\\xa9\\x92*\"Al\\xd4\\x92\\xcd\\xb51U\\xd5\\xbb\\xd0\\xc4O\\xd1Fh\"\\x98\\x1b=h\\xdd\\xde\\xa1\\x8c\\x95\\x1b\\x80)\\xf1\\x83\\xb8\\x9a\\x83=1\\xc5Z\\x89\\xa9\\x05\\xc9\\xe2\\x1e\\x95g\\x8fZ\\xad\\x19\\x1e\\xd52\\x90\\xcd\\x8a\\xa8\\x99\\xc9\\x92\\xa09\\xa7\\x11\\xc5\"\\x9cQ\\x9a\\xb2F7\\x02\\x9b\\x9e3RH28\\xa8\\xf1\\x93\\x8a\\x96Z\\x18\\xeaH\\x06\\xa9J\\x00lU\\xc9\\x1bj\\x1a\\xa4\\xed\\x9e\\xd8\\xacfo\\x026\\xf5\\x15\\x1fPI\\xa5\\'\\x9f\\xad\\x07\\xb6+\\x16l\\x88\\x8f\\x07\\xfaR741\\xebMc\\xc7Z@F\\xdc\\x9ac\\ny\\x1d\\xc0\\xa66s\\xcd0#t\\xe3\"\\xa3<\\xd4\\xaf\\x8d\\xa3\\x9e\\xb5\\x11\\xc6\\x05\\x0cC=j\\x16NMM\\xd3\\x8fZc\\x82[\\x03\\xf2\\xa0DEOB3L\\xdb\\xcdt3\\xd8G\\x06\\x9e7\\x0f\\xdec%\\xab\\x04\\x11\\xb8\\xe3\\xa5\\t\\x89\\xa20\\x07\\xd0\\xd3\\x86\\x7f\\x0c\\xd0\\xc3\\x9fsJ\\xa3\\x8e\\x94\\xc4H\\x87<\\x9ay99\\xa8\\xc7\\xca\\xa6\\x9e\\xab\\x91\\x9a\\x06L\\xb8b\\x00\\xfdjp\\x1bq\\xf4\\x03\\xb5@0\\x16\\xae \\xdb\\x16\\xe1\\x8eh\\x03\\xd5:\\xd0\\x0fj\\x01\\xa4<W!\\xa0\\xb9\\xe6\\x96\\x93\\xad\\x00\\xd3\\x18\\xe0x\\xa2\\x94\\xaf\\x19\\x14\\xda\\x04-\\x14\\x94R\\x01is\\xcd!\\xa2\\x98\\x0bI\\x9a8\\xa3\\xbd \\x16\\x96\\x9b\\x9a\\\\\\xd0\\x01Hi\\r\\x14\\xc0\\x05&h\\xe9K@\\r\\xe9HzR\\xb52\\x98\\x0b\\xda\\xa3-\\x82E<\\x9a\\x88\\x9c\\xf5\\xa0\\x05\\xceNi\\x92\\x0ehSQ\\xbbP\\x03[\\x8c\\xd4.2}\\xa9\\xe5\\xba\\xe6\\xa2$\\xe34\\xd0\\x86\\xb7\"\\xab\\xb9\\xe6\\x9e\\xed\\x83\\xe9PH\\xd9\\x14\\xc0\\xad7R\\xd5U\\x98\\x11V]\\x83\\x0e\\x9cU7\\xe3\\x8e\\xc6\\xa9\\x08\\x85\\xfeV9\\xa8\\\\\\xf7\\x15$\\x83\\'$\\xf1PH@\\x1cS@394\\xb8\\xe6\\xa3\\xe0})w\\xe6\\xa8@~\\xef\\xd6\\x98\\x0eF)Y\\xf8\\xa8\\xc1\\xc8<\\xd3B\\x14\\x8c\\x8ar\\xa1\\xc6i\\x9b\\xb0}i\\xfb\\x8684\\xc45\\x868\\xa8\\xb2\\x01\\xa7J\\xe7<\\xd4lN:U\\xa4!I\\x14\\x9b\\xbbS{R\\x8cU\\xc4\\x86<v\\xa0\\x8e\\xc3\\x8a\\x13\\x93R\\x11\\x8a\\xb4\\xc9\\x05\\xc9\\xe0R\\xe0g\\xde\\x9a8\\xa7\\xe0\\xe6\\x9a\\x10\\x98\\xc9\\xf7\\xa9\\xa3\\xe3\\x90j2\\xa4\\x1c\\x8a\\x91s\\x81T1\\\\\\xe4\\xf3\\xd6\\x91M#u\\xa5\\x1di\\x00\\xfe\\xf4\\xe8\\xc6\\xe7\\x02\\x91i\\xd1\\x90\\xb2f\\xa5\\x88\\x91\\x86\\xd1\\x9ar7\\x19\\x14\\xc9\\x1c0\\xc0\\xa4C\\xc9\\xf4\\xa9\\x06[\\x89\\xf2q\\xda\\xadE\\xc6\\x0ey\\xaa1#\\x13\\x9a\\xbb\\x119\\xc9\\xe6\\xb4\\x89\\x9c\\x8b[\\x06\\xdfzgF\\xa93\\x85\\xcdFy\\xe7\\xbdQ(y\\xfb\\xb5\\x16\\xdeq\\xde\\x97q\\x14\\x99\\xa4Z+K\\x92*7U\\xd9\\xefO\\x9b\\xefb\\xa3f\\x01k\\x9eGDJd\\xf2E4\\x93\\x8aRrh\\x1d\\xc5f\\xcd\\x91\\t\\xf9\\xba\\xd3\\x0f\\x0b\\x8a\\x96@:\\xe2\\xa0c\\x9a\\x81\\x88NG\\x06\\xa3,\\x0esNjcU\\x08\\x89\\x89\\xe7\\xad!9\\xe9R0\\'\\x8a\\x84\\x9c\\x1cS\\x10\\xdes\\xcd5\\x8e9\\xf4\\xe6\\xa48#\\x8a\\x8d\\xc6x\\xa0\\r\\x8dF\\xf1&\\xb2\\x8c\\xa3\\x03\\x95\\x00\\x8a\\xc3A\\xc9\\'\\xb5HT\\xb2\\xe2\\x9b\\xb7\\x14\\x92\\xb1,z\\xc5\\xbcg\\xb5\\x04`\\x91\\xe9Vc\\x1ba\\xc8\\xebU\\xa4?14\\xec!b\\x19c\\x9eEH\\x00\\x07\\x15\\x1cg\\x9cb\\xa5\\x02\\x81\\x8b\\x8d\\xc4\\x1fz\\xb42J\\x8c\\xf1\\x8a\\x81G\\x19?\\x95J\\x9e\\xf4\\xc0\\xf5l\\xd2\\xf0i\\xb9\\xa0\\x1c\\x1a\\xe35\\x14\\x9a\\x8a7>a\\x15\\'z\\x8dS\\xe7\\'\\x14\\xc4Z\\x8d\\x86)\\x99\\xe6\\x98\\x0e\\r\\x04\\xd3`;4\\xb4\\xdaZ@.h\\xa4\\xa5\\xa0\\x05\\xa4\\xa34\\x86\\x80\\x174\\xbd\\xa9\\xb4f\\x80\\x16\\x934\\x1a;S\\x004\\x03E3=\\xa8\\x01\\xec8\\xa8\\xea@x\\xa8\\xc9\\xa0\\x045\\x03d\\x13R\\xb1\\xe2\\xa3l\\x1eh\\x10\\xdc\\xe2\\x98\\xd8\\xcd+\\x1a\\x8f\\'<\\xd3C\\x18p*6n\\xe4\\xd3\\x9f\\x15\\t$\\x9a\\x04B\\xe7\\'\\xadB\\xc6\\xa6n\\xa7\\xb0\\xa8\\x1b\\xa9\\xa6\"\\x12:\\xf6\\xc5T\\x97\\x1b\\xb1VY\\xf0\\rTc\\x86>\\xf5H\\x08\\\\\\x10sU\\xe5\\\\\\x01\\x8fZ\\xb1#q\\x93U\\x9b9\\xeb\\x9ahCF9\\xcd@OZ{\\x92\\x063\\xf8\\xd4\\x07\\xa6)\\xa1\\nX\\x8e\\x86\\x90\\x13\\x8ai>\\xd4\\xa0\\xd5\\x88\\x18\\x91K\\xbb\\x8c\\xd3\\x18\\xd3\\t\\xc50$-\\x91\\x83\\xd6\\x9b\\xda\\x98_\\xbfj\\\\\\xf1T\\x89\\x0e\\xf4\\xe5\\xe2\\x91W4\\xe21V\\x84\\xc7\\x03\\xcei\\xe4\\xd4`\\xe3\\xad;w8\\xaa _\\xa5<04\\xd1\\xd7\\x14\\xb8\\xc7\"\\x98\\x89\\xe2\\xe4d\\xd2\\xbf_lS#\\x90/\\x06\\x82\\xf9n\\xbcU\\\\a\\xf5\\xa4\\xc9\\xa0\\x93\\xebGS\\xedJ\\xe0N\\x87\"\\x95\\x861\\x93M\\x8b\\x80E9\\xd8m\\xcfzL\\x04\\xec*H\\xf0s\\xf5\\xa8\\x81\\xc7SR)\\x00\\x1aBf\\xb6\\x9f\\n0i\\x18d\\x0e*iT,\\x9f(\\xe3\\x15\\x16\\x9f:,L\\x8c\\xd8>\\xb4\\xad&\\xf7$\\x1e+Te\"E|\\x8ei8\\x14\\x80\\xf1HM2V\\xe0\\xc6\\x99\\x9eO<R9\\xc8\\xc5 ;G5&\\xb1\"\\x93\\xd7\\xaej\\xac\\x8f\\xc5M3\\xfc\\xe7\\x19\\xc5Vs\\xf2\\x9c\\x9a\\xe7\\x96\\xe7D\\x08\\x89\\xa3~F;\\x9aa>\\xb4\\x0e\\x06k#d#\\x93\\xde\\xa1 \\xf3R\\x93\\x9e\\t\\xa8\\xc89\\xfa\\xd2\\x18\\xd3Q6z\\xd4\\xc7\\xa1\\x18\\xa8\\xdb8\\xa6!\\x99\\xdc\\xbcu\\xcd@\\xc1\\x84\\x9c\\xa9\\xc5N\\xbc5I(\\x07\\xa8\\xe9L\\x92\\xb2\\x8e\\xe6\\x98G\\xe7NrA\\x04\\nLes\\x8eh\\x10\\xe5\\x1f-5\\x97\\'\\x1d\\xa9Q\\xb0pi\\xd8\\xa0\\x91\\xd9!H\\xa8\\xca\\x82\\xd8\\xa9\\x0e\\x08\\xe2\\x98\\x0e\\r\\x03\\x1d\\xb0g\\x8awL\\x0e\\xf4\\x83\\xd6\\x95yl\\x1a\\x00r\\x9cqR\\x8e\\x07\\x1dj!\\xf7\\xfaqR/\\'\\xf9\\xd0\\x84z\\xb6E!\\xa4\\xa0\\xd7!\\xa8\\xec\\xf1I\\xde\\x90\\x1a\\\\\\xd3\\x01OZJL\\xd1\\x9a`;4u\\xa4\\xa0\\x1cR\\x01\\xebHN9\\xa4\\xcd!9\\xa0\\x07f\\x97<S\\x01\\xa0\\x9ah\\x07\\xd2\\x1a3\\xc5!oJ\\x003\\xcdH\\x835\\t\\xe3\\x9a\\x927\\x03\\x19\\xa6\\xb7\\x02G\\x8f\\x8c\\x8a\\xac\\xdc\\x1a\\xb9\\xbc\\x11Ud\\xc1cCB\\x1b\\xba\\x934\\x86\\x934\\x0ck\\xd4d\\xf1O$\\xfaTm@\\x0cf s\\xd0S\\x1d\\x81Zq\\xc7z\\x85\\xcf\\x07\\x14\\x00\\xc2\\xdc\\xd4l\\xc4\\x1e)\\xcc*&9\\xa6!$m\\xc2\\xab\\x16\\xa9\\x1c\\xe0\\xf1P\\xb1\\xa0\\x08\\\\d\\xe2\\xaa\\xb1\\xe7\\xe9\\xc5[\\x94\\xed\\xc1\\xf5\\xaa\\xc4\\x01\\x9c\\xf5\\xcdR\\x13+\\xb9\\xe7\\x15X\\x9d\\xaey\\xe2\\xa7\\x99\\xb9\\xaa\\xcey8\\x14\\xd1#$\\xeaj.1\\x9aS\\x9c\\xf3L\\xedT\\x02\\x1e\\x94\\xde\\x94\\xb9\\xcd1\\xb9\\xa6\\x80By\\xa4c\\xc1\\xa3\\xb9\\xe6\\x94U\\x08\\x8b \\xfe\\x14\\xbb\\x8d+`\\x1e1L\\xf5\\xe7\\xad\\x08D\\xc8\\xc0\\xf1On{\\xf1Q#{S\\x89\\xeb\\xf5\\xad.K\\x14\\x1f\\xc2\\x97\\xb8\"\\x9a\\xbdzS\\xbbU\\xa2I\\x86;\\x1eiA\\xea\\rC\\xbb\\x90sN,q\\xe9LD\\x99\\xa7\\xe3\"\\xa2W\\xeci\\xfb\\xbd(\\x01\\xe7\\xad(\\xc50\\x10N3F\\xec\\x1a\\x00\\x91I\\x07\\x14\\x8f\\xeb\\xdb4\\xd1\\xd74\\x13\\xc6\\r\\x00=\\x1c\\x1cq\\xcdJ\\x0eX\\xfa\\x1a\\xae\\x87\\x06\\xa7B\\x08\\xa4\"\\xdc~\\xd5r/\\xb9\\x83T#8=j\\xea6FkX\\xb39\\x12\\x96\\xc1\\xa0\\x9afs\\xd6\\x9a[\\x07\\x14\\xc9\\xb0\\xf2p)\\x99=sF\\xfc\\x8cS\\x03ps\\xd6\\xb3\\x934\\x89\\x1c\\xbc\\xd5g\\xfb\\xb5,\\x8c:Uv8$V\\x12: G\\xd4\\xd2\\x10E*\\xf3\\xde\\x9ep8\\xefY\\xb3tB\\xc3\\xa1\\xc5&M9\\xb3M\\xceE!\\x8cnNsH\\xc3\\x83\\x9ap8\\'\"\\x97\\x19\\xa6K!`Cf\\x96V\\xcf9\\xa5\\x94\\x1d\\xd8\\xcdB\\xdc\\x01\\xcd2H\\xd8\\x8c\\xe2\\x99\\xcf\\xafJRsLf\\xc7n\\xb4\\x08\\x14\\x8d\\xc3=\\xeal\\x8cUpzT\\xaa\\xdf.8\\xcd\\x02c\\x8fji\\xcf4\\xcd\\xcd\\xb8\\xf3N\\x06\\x90\\x87\\x03\\x82jQ\\x8e\\x0fz\\x80\\x1c\\x93\\xc5K\\x17Z,2S\\xc7Zzgh\\xa8\\xc8$\\xe352\\'\\x00\\xb7 S\\x11\\xea9\\xa5\\x14\\xdaZ\\xe55\\n3GZJ\\x10\\x0bE\\x14P\\x02\\x83GJN\\xf4\\xb4\\x00f\\x9b\\x9eh\\xa4\\xefL\\x07\\xd2Rg\\x8a@rh\\x01\\xf9\\xa2\\x92\\x8a\\x00)\\x9b\\x8eqO&\\xa3n\\xb4\\x01(b)\\xa4\\xf3@<SA\\xa6\\x00i\\x01\\xa1\\x8d0\\x1a\\x00W\\xebQ\\x92;S\\xa4>\\x9d*\"x\\xe2\\x93\\x19\\x19l\\x92*6\\xe9Nc\\xcd7#\\xbd1\\x117\\x18\\xcf\\xa5@\\xcd\\x9e*yH\\xdb\\xefU\\x89<\\xf1LCX\\r\\xb9\\xefP\\x13\\x8c\\xe6\\xa6\\'\\x83P\\xc8\\x00\\xe7\\x14\\xc0\\x86V\\xe7\\x9f\\xca\\xab;q\\x8cT\\xef\\xd3\"\\xaa\\xb8;\\xbd\\xa9\\xa1\\x10HrwUy>R{\\n\\x9d\\xfa\\x1c\\xd5Y[9\\xefM\\t\\x91\\xb1\\xe7\\xd74\\xce\\xe7\\xde\\x8ac\\x16\\x15d\\x88N\\r<\\x00G5\\x0eqNW\\xe3\\xad0\\x14\\x8c\\x13I\\xbb\\x1dhf\\xef\\xe9Q\\xb1\\x1f\\x9d\\x17\\x00cH\\xbf1\\xa4\\xef\\x8a\\x9a5\\xe3\\x9e\\xf5B\\x18\\x01\\x18\\xf4\\xa5\\xe6\\x9f\\x81\\x93Jq\\x8e\\xb5B\\x18\\t\\xe8i\\xe1K\\x0c\\xf6\\xa6\\x1c\\x13VP|\\xbcU\\xa2lW\\x1c6\\rK\\x9c\\xe74\\xc7?9\"\\x97p g\\xf2\\xa0\\x91qK\\xbb\\x1cTD\\xfaQ\\x9e\\xf4\\xee\\x04\\xe1\\xb1\\xc9<\\xd2\\x96\\xcd@\\x18\\xe3\\xda\\x9c\\x0e;\\xd1q\\x93\\xe7\\x1c\\xf6\\xa5$\\x12Nj \\xd9L\\x13H\\t\\xcf\\'\\x8a.\\x04\\xcav\\x91\\x9a\\x98\\x12\\x07Z\\xae\\xdc\\x0c\\xd3\\x91\\xfb\\x1a\\x04\\xcbq\\xb9\\xeb\\x9c\\x8a\\xb8\\x8e@\\x15\\x9a\\xb9\\x1c\\xe7\\xad]\\x89\\xb2\\x98\\xc5TL\\xe4X\\xdesH\\x1f\\xd6\\xa2\\r\\xcd)n8\\xab$y sM\\r\\x9ei\\xb9\\xe3\\x1d\\xe9\\xbb\\xb0\\x07\\xb5f\\xcd\\x10\\xc9\\t\\'=\\xea\\x19N>\\xb4\\xe6`\\x1f\\x8a\\x81\\xcf\\xcd\\xd6\\xb2\\x91\\xbcE\\x19\\xe9\\xebO-\\xf2\\x8c\\xf5\\x14\\xc4 \\x9aF8\\xe2\\xb3f\\xe8\\x0b\\x13\\x9aB0=\\r\\x1d\\xe9\\x1b\\x90})\\x144\\x9e(\\x07\\xe4\\xe2\\x98\\xc3\\x8e)\\x03\\x11\\xc5$K\\tN\\xe3\\xf8T\\x0c\\xd8\\x1di\\xcd\\xeb\\x9a\\x89\\x8eW\\x14\\xc9\\x1aOz\\x8c\\xe0\\x83\\xcd\\x0cx\\xf64\\x05\\xa1\\x12\\x18\\xc1\\xa7\\x13\\xe9L\\xc5\\x03\\xae3L\\x07\\x8c\\x92E=\\x14\\x12i\\xa0d\\xd4\\xb1\\x8f\\x9b\\xf9R\\x10\\x1cg\\x18\\xe6\\xa4A\\x81Ll\\x17\\xa7n\\xf9sL\\x07\\xaeY\\xaa\\xd2\\xf4\\x02\\x99m\\x11d\\xdczS\\x9cm<\\x1es@\\x1e\\x9bK\\xda\\x9bFs\\\\\\xa6\\x80\\xa6\\x94\\x9a\\x07\\x06\\x83@\\x06i\\xc2\\x99J:\\xd0\\x02\\x9e\\x94\\x03\\xc5)9\\xa6\\xe6\\x98\\x08\\xc7\\x1d(\\x074\\x8cx\\xa6\\xa1\\xe6\\x90\\x12SG\\x06\\x97<\\xd3I\\xa6\\x03\\xf3Fi\\xa0\\xd0M\\x00)4\\xd2y\\xa4\\xc8\\xa0\\x9ei\\x80\\xec\\xd3s\\xcei3A4\\x001\\xcd74\\x1ei\\xa4\\xe2\\x90\\x04\\x87\\xd2\\xa3\\x1d)KdS\\x01\\xa6\"&\\xe3\\x8a\\x8d\\xce\\x07\\x15+\\x90:Ur\\xddi\\x80\\xd9\\x1f#\\x02\\xa0\\'\\xd4\\xd4\\x8cO5\\t \\xb74\\x00\\xc6b)\\x8c\\xd9\\x14\\xe9\\x08\\xddQ\\x1e\\x86\\x98\\x99\\x0c\\x84\\x90@5]\\xf3\\xb7\\x9e\\x95a\\xc6}\\xaa\\tM\\x02*7\\x00\\x8e\\xf5RB\\x01\\xeb\\xde\\xadHx\\xe2\\xa99\\xc9\\xabB\\x1a\\xc7\\x03\\xf1\\xa8\\xc9\\xeei\\xcd\\xc05\\x19\\xe6\\x98\\x86\\xb61L\\xe4g\\x1d\\xe9\\xfc\\xd3Z\\x98\\r\\xdf\\x91\\xcd\\x19\\x06\\x98N\\x0e){S\\x01G\\xde\\x15:\\xc9\\xf2\\xd5l\\x8c\\xd3\\x83\\x11T\\x98\\x999|\\xb0\\xc7J\\x1aN9\\xa6 \\xdc2i[\\xb7\\xa5R\\x10\\xdd\\xdf7\\x02\\xac\\xac\\x98Z\\xab\\xefO\\x0f\\x81\\xefN\\xe2\\x1c\\xcd\\xbb\\x9aB\\xde\\x94\\xd7?\\x9506O\\x14\\xc9\\xb1.r3J\\x0eG&\\xa3\\x07\\x07\\x9ax\\xe3\\xde\\x98\\x0f<\\x1a2i\\xbb\\xbd\\xa8\\'?\\x9d\\x00HO\\xcb\\xc8\\xa5C\\x93P\\xee8\\xc59I\\x1c\\xd2\\x02}\\xc7\\x1c\\xd1\\xdf9\\xa8\\xcbg\\x8ax8=i\\x89\\x96a\\x94\\x1e*\\xc2\\xb7\\xa1\\xefTAPs\\xd3\\xe9V\\xa2`F\\xee\\xe6\\xae,\\x86Z\\x04\\x1c\\x1aB\\xd8\\xe9Q\\x83\\x8ainrh\\xb8\\xac<\\xb9\\xebH_\\x1c\\x9e\\x94\\xc6=j2\\xd9\\xe2\\xa5\\xb2\\xd0\\xae\\xd9={T%\\xc6y\\xa4v \\xd33\\x91\\xd2\\xb3f\\xd1%\\x07\\x91\\xe9AbMD\\x0f8\\xe6\\x9eO\\xa1\\xac\\x99\\xd1\\x11\\xd4\\x85\\xba\\x81M\\x06\\x93\\xbd\\x05\\x014\\xd7\\xe1r:\\xd3\\x89\\xe2\\x98\\xc7\\x8a\\tdd\\xd4G\\xaf\\xb7j\\xb6\\x91n\\x19\\xa8fA\\x1b\\x101A\\x0c\\xad\\xd6\\x9e\\x17\\xda\\x9aG\\xebR\\x8e\\x98\\xa0\\x92\\x16^zR\\x0f\\xbd\\x8cT\\xad\\xc0\\xa8\\xc9<\\x11L\\x07\\x8c\\xd4\\x83\\x035\\x1a\\xf5\\xa9\\x14\\xf5\\xc5\\x02`z\\xfb\\xd3\\x91w\\x1c54\\xf1\\xf8\\xd3\\xa3$`\\xd0\\x08\\xd6LG\\x00P;UF`Z\\x94\\xcc|\\xa0;\\xd3# \\x1c\\xe3\\x8e\\xf4\\r\\x1e\\x9eO\\x14\\x03\\xcd\\x14\\x82\\xb9M\\x07\\xd2\\x1a\\t\\xe2\\x90P \\x06\\x8esHz\\xd1\\x9a`;4\\x1ai8\\xa7\\x1eE\\x00!\\xe4S\\x07\\x07\\x9a}FsH\\x07\\xe7\\x8aL\\xd2g4U\\x00\\xb9\\xa0\\x9am- \\nL\\xd2\\x9a\\x8c\\x9a\\x00p4\\x13H:SX\\xe0\\xd3\\x01I\\xa6\\xb3qI\\x9c\\xd25 \\x1b\\x9cS\\t\\x1c\\x91\\xd6\\x82i\\xa5\\xb1N\\xc2#f\\xcej3\\xcd9\\x8f5\\x13\\xb7<\\x1a\\xa0\\x19!\\xe9P1\\xe7\\x8a{\\x1c\\xf6\\xa8\\xc9\\xc1\\xa4\\x03wq\\xd2\\xa3c\\xcd8\\xb5F\\xc4\\x1ad\\xb26 \\x1c\\x1e\\x95\\x04\\xed\\x93\\xc7\\xa59\\xf9\\'\\x8e\\x95^BNA\\xf4\\xa6\\x80\\xa9,\\x84\\x93\\xb4g\\x15\\\\\\x8e\\xa4\\xd4\\xef\\xf7\\xbd*\\xbb7\\xe5T\\x80k\\x1e*&\\xc6x\\xa7\\xb1\\xcdFrz\\xd3\\x10\\x99\\xe7\\x14\\x8f\\xc8\\xa44\\x80\\x8d\\xbdi\\x88\\x8d\\x81\\xddO\\xa0\\x9aC\\xc74\\xc0n\\x074\\xbd\\xfa\\xd1\\xd0\\xe0\\xd2\\xaf\\xde\\xa0C\\xd0\\x90)I$\\xf4\\xa9\\xe3U\\xc6\\x08\\x15\\x0c\\xa3\\xe6\\xe0\\xf7\\xabB\\x19\\x9e\\xfd\\xa8#<\\xd2v\\xcei@\\xa6 c\\xda\\x91\\x06O\\xd2\\x94\\xf2)c^M0\\x1e\\x17\"\\x80?\\x01O\\x1d8\\xa5\\x03<S\\xb8\\xac7\\x1di)\\xcc0:\\xd3x#\\x8aW\\x01\\x08\\x04\\xd3\\x87Ni\\x00\\xc1\\xa1\\xb3\\x9e(\\x18\\xa4\\xf3S*\\x86\\x1dj\\x15>\\xb5\"|\\xbd\\xfb\\xd0&N\\xa0\\x03\\xcdN\\xbc\\x0cUu`jPXU\\xa2\\t\\xb7c\\x8aBx\\xe2\\x9b\\xbb\\x8c\\xe6\\x908\\xf5\\xa2\\xe2\\xb0\\xe0\\xc0\\xaf\\xd6\\xa3\\x93\\x81\\x9a\\t\\xa6\\xb7\\xcc:\\xd2e\\xa4F\\xdc\\xf5\\xa4\\x07\\x02\\x95\\xba\\xd2\\x7fZ\\xc9\\xb3X\\x88I\\xea\\x07\\x02\\x9c\\xa7\\x9af)G\\xadC\\xdc\\xde#\\xfbR\\x92)\\xb9\\xe2\\x83\\xd2\\x91cI\\xc54\\x90E.2\\rF\\xe7\\x02\\x82\\x19~1\\x88\\xb3T\\xae\\x08$\\x8a\\x96+\\x90\\x13\\x07\\x9e*\\xbc\\xad\\xb8\\xe4S \\x84\\x9a]\\xdd\\x85F[\\xafLQ\\x93B\\x10\\xe6$\\xe3\\xdb\\xbd\"\\xf0h=)\\x061\\xd6\\x98\\x12\\x0cb\\x9e\\x87\\x03\\x8a\\x8f\\xa0\\xa7.1\\xcd\\x0c\\x96I\\xf7\\xba\\x9aQ\\xc7\\x14\\xc5\\xceMH1\\x9c\\xd0!\\xf9\\'\\x02\\x9c\\xa7\\x19\\xf7\\xa6\\xafsN\\xdd\\x86\\x14\\r\\x1e\\xa5\\xfc\\xe8\\xc6)\\x07Zy\\xe4W)\\xa8\\xde\\xd4f\\x938\\xa0\\xd0!O\\xd6\\x93\\xa74\\x123Hs@\\x0b\\xda\\x80i)3@\\x0e\\xcf4\\xd6\\xe6\\x8a3L\\x00Pi(\\xa0\\x034\\xa0\\xd2\\x1aa&\\x80\\x1eM0\\x9a\\\\\\xf1M\\xe8Fi\\x80\\xee\\xd4\\xc2iKpj2h\\x10\\xa0\\xd29\\xc8\\xa4-Lf\\xc9\\xc5\\x00!5\\x1b\\x1ezS\\xbbTo\\xebM\\x00\\xc75\\x0b0\\xdb\\x8a\\x95\\xb8\\xaa\\xecy\\xa0\\x06\\x93\\xc5F\\xed\\x81Nc\\xc1\\xa8\\\\\\x9c\\xf3\\xd2\\x98\\x86\\x87\\xc1\\xcd1\\xdb\\x19\\xc1\\xa2OJ\\x88\\xb7j`\\xc69\\xc5@y5+\\x9e>\\x95\\x06x4\\xc0\\xad*\\xf3\\x9fJ\\x85\\xf9\\x06\\xa6pzv\\xefP\\x91\\x8eM4\"\\x03\\xc0\\xa6rG\\xebS}\\xea\\x88\\x8c\\xf4\\xe2\\xa9\\x08\\x8b\\x8e\\xf4\\xdcc\\x81N8\\xc99\\xa8\\xc9=\\x8d1\\x07\\xf3\\xa5\\xcf\\x02\\x9b\\x9c\\n=\\xe8\\xb8\\x80\\xf54\\x06\\xc3{RS\\x0fP9\\xa0\\x0b\\xf16S \\xf7\\xa6J\\xc0\\xd4\\x03v\\xde\\r;>\\xa6\\xa91\\x06y\\xa5Ry4\\x84\\xf3\\xc5\\x03\\xa7\\xf8\\xd5\\x00\\xf0>\\\\v\\xa7\\xaa\\xe3\\x90i\\x80ddT\\x8b@\\x85\\xcd\\x05\\xb9\\xc5#p8\\xa6\\x13\\xd6\\x80\\x1e\\xc7\\x8c\\xd3r:\\xf5\\xa6\\x8c\\xe3\\x19\\xa0\\xf4\\xf7\\xa0d\\x99\\x18\\xe2\\x90\\xb0\\xe8z\\xd4y\\xc59\\xb9\\x19\\xa0C\\x85H\\x18\\x1a\\x89\\x0f\\xe5O\\xc6y\\xa0\\t\\x97 {\\xd4\\xc1\\xb2*\\x05\\xe7\\x83N$\\x8e\\x95W%\\xa2B\\xff\\x00\\x8d!o\\x97=\\xea>\\xb4\\xa4\\xd3\\x10\\xed\\xd4\\xe2~Z\\x8c\\x9csM-\\x8czT\\xb2\\xd12\\xe3\\x1e\\xb4\\xd6P\\x01\\xa4\\r\\x91\\xc5\\x1egoJ\\xcd\\x97\\x11\\x07#\\xde\\x8e\\x99\\xcd\\x00\\xe7\\x9aZ\\x93h\\x8bC{SzQ\\xfc\\xe8,\\x00\\xa8d=\\xaaRH\\x1e\\xf5\\x03\\x1aBb.E5\\xdb\\x07\\x14s\\xf8S[8\\xe6\\x9a!\\x91\\x923\\x81@\\xe2\\x809\\xe4S\\x8a\\xfe\\x14\\x08\\\\\\xe2\\x9b\\xd7\\xb5\\x14\\x9d\\xf8\\xa6!\\xe0\\xd3\\x81\\x18\\xcdG\\xda\\x80\\xdd\\x05\\x04\\xb2tc\\xd4\\xf7\\xa9\\x06\\x00\\xc7~\\xb5][\\x9c\\x03\\x8a\\x98\\x1e}\\xe9\\x01*\\x9e\\r(\\xe9\\x91\\xc9\\xa8\\xb2\\x0f\\x14\\xa8\\xc4\\x1c\\xf3@\\x91\\xea\\xb9\\xe2\\x9c\\x1b\\x8ae-`j\\x04\\xd1\\x9a1A\\x18\\xa9\\xb8\\t\\x9aZJRi\\x80\\x99\\xa5\\xa6\\x9a3@\\x0bE\\x14\\x1a\\x003I\\x9a3I\\xde\\x98\\x08N\\r&h\\xcf8\\xa4\\xa4\\x02\\xe7\\x9ai\\xa5<RS\\x01\\r4\\xf3N=i\\xa78\\xa0\\x06\\xb5F\\xc7\\x06\\x9c\\xdcb\\xa3bs\\xc5\\x02\\x14\\x9a\\x8d\\x8f\\xbf\\x14\\x1c\\x8a\\x88\\xe7\\xbd0\\x15\\xfaUv\\xc0\\xa9X\\xe4c\\xb5B\\xc3\\xf2\\xa0\\x08\\xdc\\xd4\\x12u\\xa9e\\'\\x8cT.9\\xe6\\x98\\xac1\\x8dF\\xe0u\\xa7\\x91Q\\xbf\\x1d)\\x81\\x13\\xf3MP\\x07Z\\x1f\\xa5\\'\\x18\\x1e\\xfd\\xa9\\xa1\\x11K\\x1e\\x0eET\\x90u\\x15y\\x8a\\x85\\xf9\\xea\\x94\\x9fx\\x91\\xd35I\\x01X\\x9cTL\\xc4S\\xe5\\x18n\\x0fZ\\x85\\xb2F\\x07ST!\\xacs\\xc57\\xd2\\x97\\xafzJ\\x04\\x06\\x81A\\xfdi=9\\xa0A\\x8c\\x1c\\x9aB9\\xc8\\xab\\x96\\xf1+\\xa9\\'\\x93L\\x9e\\x0f(\\xe4t\\xa2\\xc0B3Jq\\x9a00\\r\\x1d)\\xa6!\\xd8\\xc7\\xd0\\xd1\\x8aU\\x19\\xed@\\xc6x\\xaa\\xb8\\x0e^\\x0f5 \\x15\\x1e}i\\xe1\\x80\\x1c\\xd0\\x00\\xe7\\x8a\\x84\\x9ei\\xec\\xd8\\xe6\\xa2$\\x13L\\x07\\x81\\x81\\x9c\\xd2\\x8cv\\xa8\\xc3b\\x94\\x9fJ\\x00q\\xe7\\xa5\\x00\\xd3w`\\xf5\\xe2\\x9d\\x8e\\xfd\\xa8\\x01\\xddO\\x06\\xac&1\\x8a\\xae\\xa7\\x07\\xaf56p8\\xa0C\\xc0\\xc5\\nsH\\x1ct\\xcf4\\x9d\\r4&\\x80\\x9eh\\xddA#\\xd6\\x9b\\x9e\\xa4\\nb\\x14\\x9f\\xca\\x93\\xef\\x0c\\x13M\\x1c\\xf7\\xa7\\x0e\\xb9\\xa9-\\x0eF\\xdb\\xc55\\xdb\\x9c\\xd1\\x9e\\rFOl\\xd42\\x91\"1\\'\\x04\\xfe50\\xc6x\\xaa\\xe9\\x82r\\rL\\xa7\\x07\\xebR\\xcdb<\\xf1\\xcd3#\\x1c\\xd2\\x9ezt\\xa8\\xb2y\\xf74\\x1a\\x0ec\\xc7Z\\x8f\\x00\\x9c\\nS\\xcd,|J\\xbc~\\x14\\x89e\\x95\\xb6\\xca\\x0e\\xe7\\x15Nh\\xccd\\x83[q\\xa8\\xd9\\x9e\\xf5\\x9dy\\x86c\\xea:\\xd3\\xb9\\x17(\\x81\\xc7?\\x851\\x8e\\x0e)\\xe7\\x81\\xeej&\\xa6\\x01\\x9ej@\\xa0\\x9ej%8\\x1d\\xeaP\\xc3\\x1dh&\\xe3\\x08\\xc74\\x80\\x9f\\xc2\\x9ey\\xe0\\xf4\\x14\\xd3\\xc5!1\\xc0\\x91\\xde\\xa5V\\x05~\\x95\\x08Z\\x91F3\\x8e\\xf40\\x1e\\x1b\\xda\\x9f\\x93\\xd4S:sN_\\xbb@#\\xff\\xd9\\nE\\n\\x0eimage/filename\\x123\\n1\\n/114_jpg.rf.0079ef9da096d6f7587a20025d6c713c.jpg\\n\\x18\\n\\x0cimage/format\\x12\\x08\\n\\x06\\n\\x04jpeg\\n\\x16\\n\\x0cimage/height\\x12\\x06\\x1a\\x04\\n\\x02\\x80\\x05\\n\"\\n\\x16image/object/bbox/xmax\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00,?\\n\"\\n\\x16image/object/bbox/xmin\\x12\\x08\\x12\\x06\\n\\x0433\\xaf>\\n\"\\n\\x16image/object/bbox/ymax\\x12\\x08\\x12\\x06\\n\\x04ff\\xc2>\\n\"\\n\\x16image/object/bbox/ymin\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99a>\\n!\\n\\x18image/object/class/label\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n2\\n\\x17image/object/class/text\\x12\\x17\\n\\x15\\n\\x13DEFECT- Layer-shift\\n\\x15\\n\\x0bimage/width\\x12\\x06\\x1a\\x04\\n\\x02\\x80\\x05', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.&nbsp;Set Up Training Configuration"
      ],
      "metadata": {
        "id": "eGEUZYAMEZ6f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2MAcgJ53STW"
      },
      "source": [
        "In this section, we'll set up the model and training configuration. We'll specifiy which pretrained TensorFlow model we want to use from the [TensorFlow 2 Object Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Each model also comes with a configuration file that points to file locations, sets training parameters (such as learning rate and total number of training steps), and more. We'll modify the configuration file for our custom training job.\n",
        "\n",
        "The first section of code lists out some models availabe in the TF2 Model Zoo and defines some filenames that will be used later to download the model and config file. This makes it easy to manage which model you're using and to add other models to the list later.\n",
        "\n",
        "Set the \"chosen_model\" variable to match the name of the model you'd like to train with. It's currently set to use the popular \"ssd-mobilenet-v2\" model. Click play on the next block once the chosen model has been set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN0EUEa3e5Un"
      },
      "outputs": [],
      "source": [
        "# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n",
        "chosen_model = 'ssd-mobilenet-v2-fpnlite-640'\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd-mobilenet-v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "    },\n",
        "    'ssd-mobilenet-v2-fpnlite-320': {\n",
        "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "      'ssd-mobilenet-v2-fpnlite-640': {\n",
        "        'model_name': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # The centernet model isn't working as of 9/10/22\n",
        "    #'centernet-mobilenet-v2': {\n",
        "    #    'model_name': 'centernet_mobilenetv2fpn_512x512_coco17_od',\n",
        "    #    'base_pipeline_file': 'pipeline.config',\n",
        "    #    'pretrained_checkpoint': 'centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz',\n",
        "    #}\n",
        "}\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the pretrained model file and configuration file by clicking Play on the following section."
      ],
      "metadata": {
        "id": "JMG3EEPqPggV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG4TmJUVrYQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f627e75-0d8f-47b7-d35d-893a5b81eea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/mymodel\n",
            "--2024-12-24 17:13:47--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.197.207, 74.125.135.207, 74.125.142.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.197.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20518283 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.57M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-12-24 17:13:47 (201 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n",
            "\n",
            "--2024-12-24 17:13:47--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4684 (4.6K) [text/plain]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-24 17:13:47 (59.7 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config’ saved [4684/4684]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create \"mymodel\" folder for holding pre-trained weights and configuration files\n",
        "%mkdir /content/models/mymodel/\n",
        "%cd /content/models/mymodel/\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFAlqNrPn5y3"
      },
      "source": [
        "Now that we've downloaded our model and config file, we need to modify the configuration file with some high-level training parameters. The following variables are used to control training steps:\n",
        "\n",
        "num_steps: We standardized the process by using 4375 steps, which corresponds to 25 epochs, based on our current testing with a small dataset.\n",
        "\n",
        "batch_size: We used the same batch size for comparison across all models, specifically testing with a batch size of 16.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lYDvJN-n69v"
      },
      "outputs": [],
      "source": [
        "# Set training parameters for the model\n",
        "num_steps = 4375\n",
        "\n",
        "if chosen_model == 'efficientdet-d0':\n",
        "  batch_size = 4\n",
        "else:\n",
        "  batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_ki9jOqxn7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8cc80e-a366-4666-f16a-ab874009df49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total classes: 4\n"
          ]
        }
      ],
      "source": [
        "# Set file locations and get number of classes for config file\n",
        "pipeline_fname = '/content/models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "print('Total classes:', num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwPyaIAXxyKu"
      },
      "source": [
        "Next, we'll rewrite the config file to use the training parameters we just specified. The following section of code will automatically replace the necessary parameters in the downloaded .config file and save it as our custom \"pipeline_file.config\" file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eA5ht3_yukT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83a0576-25a1-4d71-853c-3456901d237a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/mymodel\n",
            "writing custom configuration file\n"
          ]
        }
      ],
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "%cd /content/models/mymodel\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .08', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .026666', s)\n",
        "\n",
        "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
        "    if chosen_model == 'efficientdet-d0':\n",
        "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
        "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
        "      s = re.sub('min_dimension', 'height', s)\n",
        "      s = re.sub('max_dimension', 'width', s)\n",
        "\n",
        "    f.write(s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDySP7TLzdCM"
      },
      "source": [
        "(Optional) If you're curious, you can display the configuration file's contents here in the browser by running the line of code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEsOLOMHzBqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860ce463-a40c-4672-bda0-40a538f4ce26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# SSD with Mobilenet v2 FPN-lite (go/fpn-lite) feature extractor, shared box\n",
            "# predictor and focal loss (a mobile version of Retinanet).\n",
            "# Retinanet: see Lin et al, https://arxiv.org/abs/1708.02002\n",
            "# Trained on COCO, initialized from Imagenet classification checkpoint\n",
            "# Train on TPU-8\n",
            "#\n",
            "# Achieves 28.2 mAP on COCO17 Val\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "    num_classes: 4\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    anchor_generator {\n",
            "      multiscale_anchor_generator {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        anchor_scale: 4.0\n",
            "        aspect_ratios: [1.0, 2.0, 0.5]\n",
            "        scales_per_octave: 2\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 640\n",
            "        width: 640\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      weight_shared_convolutional_box_predictor {\n",
            "        depth: 128\n",
            "        class_prediction_bias_init: -4.6\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              stddev: 0.01\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            scale: true,\n",
            "            decay: 0.997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "        num_layers_before_predictor: 4\n",
            "        share_prediction_tower: true\n",
            "        use_depthwise: true\n",
            "        kernel_size: 3\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2_fpn_keras'\n",
            "      use_depthwise: true\n",
            "      fpn {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        additional_layer_depth: 128\n",
            "      }\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          random_normal_initializer {\n",
            "            stddev: 0.01\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          scale: true,\n",
            "          decay: 0.997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "      override_base_feature_extractor_hyperparams: true\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          alpha: 0.25\n",
            "          gamma: 2.0\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  fine_tune_checkpoint_version: V2\n",
            "  fine_tune_checkpoint: \"/content/models/mymodel/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  batch_size: 16\n",
            "  sync_replicas: true\n",
            "  startup_delay_steps: 0\n",
            "  replicas_to_aggregate: 8\n",
            "  num_steps: 4375\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_crop_image {\n",
            "      min_object_covered: 0.0\n",
            "      min_aspect_ratio: 0.75\n",
            "      max_aspect_ratio: 3.0\n",
            "      min_area: 0.75\n",
            "      max_area: 1.0\n",
            "      overlap_thresh: 0.0\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: .08\n",
            "          total_steps: 50000\n",
            "          warmup_learning_rate: .026666\n",
            "          warmup_steps: 1000\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  label_map_path: \"/content/labelmap.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/train.tfrecord\"\n",
            "  }\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  label_map_path: \"/content/labelmap.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/val.tfrecord\"\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# (Optional) Display the custom configuration file's contents\n",
        "!cat /content/models/mymodel/pipeline_file.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXpnXYC908Zl"
      },
      "source": [
        "Finally, let's set the locations of the configuration file and model output directory as variables so we can reference them when we call the training command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMlaN3rs3zLe"
      },
      "outputs": [],
      "source": [
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = '/content/models/mymodel/pipeline_file.config'\n",
        "model_dir = '/content/training/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.&nbsp;Train Custom TFLite Detection Model"
      ],
      "metadata": {
        "id": "-19zML6oEO7l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cuQpPJL2pUq"
      },
      "source": [
        "Model training is performed using the \"model_main_tf2.py\" script from the TF Object Detection API. Training will take anywhere from 2 to 6 hours, depending on the model, batch size, and number of training steps. We've already defined all the parameters and arguments used by `model_main_tf2.py` in previous sections of this Colab. Just click Play on the following block to begin training!\n",
        "\n",
        "\n",
        "\n",
        "> *Note: It takes a few minutes for the program to display any training messages, because it only displays logs once every 100 steps. If it seems like nothing is happening, just wait a couple minutes.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQTfZChVzzpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5483c82d-a241-497a-e158-8f7a2916e1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "2024-12-24 17:22:32.386174: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I1224 17:22:32.394652 140257418444800 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 4375\n",
            "I1224 17:22:32.399585 140257418444800 config_util.py:552] Maybe overwriting train_steps: 4375\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1224 17:22:32.399771 140257418444800 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1224 17:22:32.563053 140257418444800 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/train.tfrecord']\n",
            "I1224 17:22:32.567539 140257418444800 dataset_builder.py:162] Reading unweighted datasets: ['/content/train.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/train.tfrecord']\n",
            "I1224 17:22:32.567737 140257418444800 dataset_builder.py:79] Reading record datasets for input file: ['/content/train.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1224 17:22:32.567826 140257418444800 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1224 17:22:32.567896 140257418444800 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1224 17:22:32.570496 140257418444800 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1224 17:22:32.594127 140257418444800 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1224 17:22:40.484773 140257418444800 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1224 17:22:43.056684 140257418444800 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1224 17:22:44.396981 140257418444800 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "I1224 17:22:55.258579 140251650541120 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1224 17:23:07.844776 140251650541120 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "2024-12-24 17:23:16.274279: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1224 17:23:22.449928 140257418444800 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1224 17:23:22.451850 140257418444800 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1224 17:23:22.454802 140257418444800 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1224 17:23:22.456010 140257418444800 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1224 17:23:22.458889 140257418444800 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1224 17:23:22.460092 140257418444800 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1224 17:23:22.462969 140257418444800 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1224 17:23:22.464171 140257418444800 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1224 17:23:22.467020 140257418444800 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1224 17:23:22.468915 140257418444800 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1224 17:23:23.151587 140251667326528 deprecation.py:541] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I1224 17:23:24.010237 140251667326528 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1224 17:23:32.645787 140251667326528 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1224 17:23:42.356539 140251667326528 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1224 17:23:51.433166 140251667326528 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Step 100 per-step time 1.944s\n",
            "I1224 17:26:37.120423 140257418444800 model_lib_v2.py:705] Step 100 per-step time 1.944s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.44532877,\n",
            " 'Loss/localization_loss': 0.4591177,\n",
            " 'Loss/regularization_loss': 0.15164664,\n",
            " 'Loss/total_loss': 1.0560931,\n",
            " 'learning_rate': 0.0319994}\n",
            "I1224 17:26:37.120846 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.44532877,\n",
            " 'Loss/localization_loss': 0.4591177,\n",
            " 'Loss/regularization_loss': 0.15164664,\n",
            " 'Loss/total_loss': 1.0560931,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 1.353s\n",
            "I1224 17:28:52.445561 140257418444800 model_lib_v2.py:705] Step 200 per-step time 1.353s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2857097,\n",
            " 'Loss/localization_loss': 0.40579024,\n",
            " 'Loss/regularization_loss': 0.15182106,\n",
            " 'Loss/total_loss': 0.843321,\n",
            " 'learning_rate': 0.0373328}\n",
            "I1224 17:28:52.445931 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.2857097,\n",
            " 'Loss/localization_loss': 0.40579024,\n",
            " 'Loss/regularization_loss': 0.15182106,\n",
            " 'Loss/total_loss': 0.843321,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 1.347s\n",
            "I1224 17:31:07.126372 140257418444800 model_lib_v2.py:705] Step 300 per-step time 1.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25006598,\n",
            " 'Loss/localization_loss': 0.29928118,\n",
            " 'Loss/regularization_loss': 0.15197411,\n",
            " 'Loss/total_loss': 0.70132124,\n",
            " 'learning_rate': 0.0426662}\n",
            "I1224 17:31:07.126722 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.25006598,\n",
            " 'Loss/localization_loss': 0.29928118,\n",
            " 'Loss/regularization_loss': 0.15197411,\n",
            " 'Loss/total_loss': 0.70132124,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 1.343s\n",
            "I1224 17:33:21.400339 140257418444800 model_lib_v2.py:705] Step 400 per-step time 1.343s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26306924,\n",
            " 'Loss/localization_loss': 0.23191182,\n",
            " 'Loss/regularization_loss': 0.15206763,\n",
            " 'Loss/total_loss': 0.6470487,\n",
            " 'learning_rate': 0.047999598}\n",
            "I1224 17:33:21.400757 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.26306924,\n",
            " 'Loss/localization_loss': 0.23191182,\n",
            " 'Loss/regularization_loss': 0.15206763,\n",
            " 'Loss/total_loss': 0.6470487,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 1.347s\n",
            "I1224 17:35:36.077894 140257418444800 model_lib_v2.py:705] Step 500 per-step time 1.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2673523,\n",
            " 'Loss/localization_loss': 0.2771223,\n",
            " 'Loss/regularization_loss': 0.1521768,\n",
            " 'Loss/total_loss': 0.6966514,\n",
            " 'learning_rate': 0.053333}\n",
            "I1224 17:35:36.078251 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.2673523,\n",
            " 'Loss/localization_loss': 0.2771223,\n",
            " 'Loss/regularization_loss': 0.1521768,\n",
            " 'Loss/total_loss': 0.6966514,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 1.343s\n",
            "I1224 17:37:50.416019 140257418444800 model_lib_v2.py:705] Step 600 per-step time 1.343s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24865532,\n",
            " 'Loss/localization_loss': 0.2249357,\n",
            " 'Loss/regularization_loss': 0.15222853,\n",
            " 'Loss/total_loss': 0.62581956,\n",
            " 'learning_rate': 0.0586664}\n",
            "I1224 17:37:50.416482 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.24865532,\n",
            " 'Loss/localization_loss': 0.2249357,\n",
            " 'Loss/regularization_loss': 0.15222853,\n",
            " 'Loss/total_loss': 0.62581956,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 1.338s\n",
            "I1224 17:40:04.242826 140257418444800 model_lib_v2.py:705] Step 700 per-step time 1.338s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19198962,\n",
            " 'Loss/localization_loss': 0.19594876,\n",
            " 'Loss/regularization_loss': 0.15219754,\n",
            " 'Loss/total_loss': 0.5401359,\n",
            " 'learning_rate': 0.0639998}\n",
            "I1224 17:40:04.243179 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.19198962,\n",
            " 'Loss/localization_loss': 0.19594876,\n",
            " 'Loss/regularization_loss': 0.15219754,\n",
            " 'Loss/total_loss': 0.5401359,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 1.347s\n",
            "I1224 17:42:18.943092 140257418444800 model_lib_v2.py:705] Step 800 per-step time 1.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.30832875,\n",
            " 'Loss/localization_loss': 0.19973768,\n",
            " 'Loss/regularization_loss': 0.15229023,\n",
            " 'Loss/total_loss': 0.66035664,\n",
            " 'learning_rate': 0.069333196}\n",
            "I1224 17:42:18.943469 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.30832875,\n",
            " 'Loss/localization_loss': 0.19973768,\n",
            " 'Loss/regularization_loss': 0.15229023,\n",
            " 'Loss/total_loss': 0.66035664,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 1.346s\n",
            "I1224 17:44:33.503006 140257418444800 model_lib_v2.py:705] Step 900 per-step time 1.346s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25479954,\n",
            " 'Loss/localization_loss': 0.22592057,\n",
            " 'Loss/regularization_loss': 0.1524236,\n",
            " 'Loss/total_loss': 0.6331437,\n",
            " 'learning_rate': 0.074666604}\n",
            "I1224 17:44:33.503410 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.25479954,\n",
            " 'Loss/localization_loss': 0.22592057,\n",
            " 'Loss/regularization_loss': 0.1524236,\n",
            " 'Loss/total_loss': 0.6331437,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.344s\n",
            "I1224 17:46:47.883461 140257418444800 model_lib_v2.py:705] Step 1000 per-step time 1.344s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.28867885,\n",
            " 'Loss/localization_loss': 0.23293027,\n",
            " 'Loss/regularization_loss': 0.1524282,\n",
            " 'Loss/total_loss': 0.67403734,\n",
            " 'learning_rate': 0.08}\n",
            "I1224 17:46:47.883882 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.28867885,\n",
            " 'Loss/localization_loss': 0.23293027,\n",
            " 'Loss/regularization_loss': 0.1524282,\n",
            " 'Loss/total_loss': 0.67403734,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.355s\n",
            "I1224 17:49:03.397605 140257418444800 model_lib_v2.py:705] Step 1100 per-step time 1.355s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2279895,\n",
            " 'Loss/localization_loss': 0.23594211,\n",
            " 'Loss/regularization_loss': 0.15246777,\n",
            " 'Loss/total_loss': 0.6163994,\n",
            " 'learning_rate': 0.07999918}\n",
            "I1224 17:49:03.398003 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.2279895,\n",
            " 'Loss/localization_loss': 0.23594211,\n",
            " 'Loss/regularization_loss': 0.15246777,\n",
            " 'Loss/total_loss': 0.6163994,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.347s\n",
            "I1224 17:51:18.100837 140257418444800 model_lib_v2.py:705] Step 1200 per-step time 1.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22481528,\n",
            " 'Loss/localization_loss': 0.18359101,\n",
            " 'Loss/regularization_loss': 0.15241674,\n",
            " 'Loss/total_loss': 0.560823,\n",
            " 'learning_rate': 0.079996705}\n",
            "I1224 17:51:18.101199 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.22481528,\n",
            " 'Loss/localization_loss': 0.18359101,\n",
            " 'Loss/regularization_loss': 0.15241674,\n",
            " 'Loss/total_loss': 0.560823,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.344s\n",
            "I1224 17:53:32.546380 140257418444800 model_lib_v2.py:705] Step 1300 per-step time 1.344s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26543993,\n",
            " 'Loss/localization_loss': 0.20271303,\n",
            " 'Loss/regularization_loss': 0.15222593,\n",
            " 'Loss/total_loss': 0.62037885,\n",
            " 'learning_rate': 0.0799926}\n",
            "I1224 17:53:32.546742 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.26543993,\n",
            " 'Loss/localization_loss': 0.20271303,\n",
            " 'Loss/regularization_loss': 0.15222593,\n",
            " 'Loss/total_loss': 0.62037885,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 1.344s\n",
            "I1224 17:55:46.931195 140257418444800 model_lib_v2.py:705] Step 1400 per-step time 1.344s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17136052,\n",
            " 'Loss/localization_loss': 0.1825599,\n",
            " 'Loss/regularization_loss': 0.15200996,\n",
            " 'Loss/total_loss': 0.5059304,\n",
            " 'learning_rate': 0.07998685}\n",
            "I1224 17:55:46.931567 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.17136052,\n",
            " 'Loss/localization_loss': 0.1825599,\n",
            " 'Loss/regularization_loss': 0.15200996,\n",
            " 'Loss/total_loss': 0.5059304,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.343s\n",
            "I1224 17:58:01.206349 140257418444800 model_lib_v2.py:705] Step 1500 per-step time 1.343s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16074285,\n",
            " 'Loss/localization_loss': 0.14319144,\n",
            " 'Loss/regularization_loss': 0.15177062,\n",
            " 'Loss/total_loss': 0.4557049,\n",
            " 'learning_rate': 0.07997945}\n",
            "I1224 17:58:01.206719 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.16074285,\n",
            " 'Loss/localization_loss': 0.14319144,\n",
            " 'Loss/regularization_loss': 0.15177062,\n",
            " 'Loss/total_loss': 0.4557049,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.342s\n",
            "I1224 18:00:15.403822 140257418444800 model_lib_v2.py:705] Step 1600 per-step time 1.342s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2661042,\n",
            " 'Loss/localization_loss': 0.22915442,\n",
            " 'Loss/regularization_loss': 0.15150686,\n",
            " 'Loss/total_loss': 0.6467655,\n",
            " 'learning_rate': 0.079970405}\n",
            "I1224 18:00:15.404242 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.2661042,\n",
            " 'Loss/localization_loss': 0.22915442,\n",
            " 'Loss/regularization_loss': 0.15150686,\n",
            " 'Loss/total_loss': 0.6467655,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.344s\n",
            "I1224 18:02:29.825704 140257418444800 model_lib_v2.py:705] Step 1700 per-step time 1.344s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19516715,\n",
            " 'Loss/localization_loss': 0.19914116,\n",
            " 'Loss/regularization_loss': 0.15131122,\n",
            " 'Loss/total_loss': 0.54561955,\n",
            " 'learning_rate': 0.07995972}\n",
            "I1224 18:02:29.826117 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.19516715,\n",
            " 'Loss/localization_loss': 0.19914116,\n",
            " 'Loss/regularization_loss': 0.15131122,\n",
            " 'Loss/total_loss': 0.54561955,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.351s\n",
            "I1224 18:04:44.910520 140257418444800 model_lib_v2.py:705] Step 1800 per-step time 1.351s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18725604,\n",
            " 'Loss/localization_loss': 0.10556449,\n",
            " 'Loss/regularization_loss': 0.15102234,\n",
            " 'Loss/total_loss': 0.44384286,\n",
            " 'learning_rate': 0.0799474}\n",
            "I1224 18:04:44.910887 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.18725604,\n",
            " 'Loss/localization_loss': 0.10556449,\n",
            " 'Loss/regularization_loss': 0.15102234,\n",
            " 'Loss/total_loss': 0.44384286,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.340s\n",
            "I1224 18:06:58.884271 140257418444800 model_lib_v2.py:705] Step 1900 per-step time 1.340s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15778531,\n",
            " 'Loss/localization_loss': 0.15921566,\n",
            " 'Loss/regularization_loss': 0.15067546,\n",
            " 'Loss/total_loss': 0.46767646,\n",
            " 'learning_rate': 0.07993342}\n",
            "I1224 18:06:58.884654 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.15778531,\n",
            " 'Loss/localization_loss': 0.15921566,\n",
            " 'Loss/regularization_loss': 0.15067546,\n",
            " 'Loss/total_loss': 0.46767646,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.349s\n",
            "I1224 18:09:13.802891 140257418444800 model_lib_v2.py:705] Step 2000 per-step time 1.349s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21378711,\n",
            " 'Loss/localization_loss': 0.24871722,\n",
            " 'Loss/regularization_loss': 0.15030484,\n",
            " 'Loss/total_loss': 0.6128092,\n",
            " 'learning_rate': 0.07991781}\n",
            "I1224 18:09:13.803250 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.21378711,\n",
            " 'Loss/localization_loss': 0.24871722,\n",
            " 'Loss/regularization_loss': 0.15030484,\n",
            " 'Loss/total_loss': 0.6128092,\n",
            " 'learning_rate': 0.07991781}\n",
            "INFO:tensorflow:Step 2100 per-step time 1.355s\n",
            "I1224 18:11:29.304188 140257418444800 model_lib_v2.py:705] Step 2100 per-step time 1.355s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17177536,\n",
            " 'Loss/localization_loss': 0.13800876,\n",
            " 'Loss/regularization_loss': 0.14991358,\n",
            " 'Loss/total_loss': 0.4596977,\n",
            " 'learning_rate': 0.07990056}\n",
            "I1224 18:11:29.304658 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.17177536,\n",
            " 'Loss/localization_loss': 0.13800876,\n",
            " 'Loss/regularization_loss': 0.14991358,\n",
            " 'Loss/total_loss': 0.4596977,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Step 2200 per-step time 1.354s\n",
            "I1224 18:13:44.667577 140257418444800 model_lib_v2.py:705] Step 2200 per-step time 1.354s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.275508,\n",
            " 'Loss/localization_loss': 0.29927585,\n",
            " 'Loss/regularization_loss': 0.14952953,\n",
            " 'Loss/total_loss': 0.7243133,\n",
            " 'learning_rate': 0.07988167}\n",
            "I1224 18:13:44.667942 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.275508,\n",
            " 'Loss/localization_loss': 0.29927585,\n",
            " 'Loss/regularization_loss': 0.14952953,\n",
            " 'Loss/total_loss': 0.7243133,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Step 2300 per-step time 1.343s\n",
            "I1224 18:15:58.967151 140257418444800 model_lib_v2.py:705] Step 2300 per-step time 1.343s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25338772,\n",
            " 'Loss/localization_loss': 0.27513364,\n",
            " 'Loss/regularization_loss': 0.14912455,\n",
            " 'Loss/total_loss': 0.6776459,\n",
            " 'learning_rate': 0.07986114}\n",
            "I1224 18:15:58.967519 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.25338772,\n",
            " 'Loss/localization_loss': 0.27513364,\n",
            " 'Loss/regularization_loss': 0.14912455,\n",
            " 'Loss/total_loss': 0.6776459,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 1.343s\n",
            "I1224 18:18:13.259248 140257418444800 model_lib_v2.py:705] Step 2400 per-step time 1.343s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16503325,\n",
            " 'Loss/localization_loss': 0.121052094,\n",
            " 'Loss/regularization_loss': 0.14877039,\n",
            " 'Loss/total_loss': 0.43485573,\n",
            " 'learning_rate': 0.07983897}\n",
            "I1224 18:18:13.259622 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.16503325,\n",
            " 'Loss/localization_loss': 0.121052094,\n",
            " 'Loss/regularization_loss': 0.14877039,\n",
            " 'Loss/total_loss': 0.43485573,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Step 2500 per-step time 1.350s\n",
            "I1224 18:20:28.280665 140257418444800 model_lib_v2.py:705] Step 2500 per-step time 1.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18556817,\n",
            " 'Loss/localization_loss': 0.15452085,\n",
            " 'Loss/regularization_loss': 0.14836901,\n",
            " 'Loss/total_loss': 0.48845804,\n",
            " 'learning_rate': 0.079815164}\n",
            "I1224 18:20:28.281011 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.18556817,\n",
            " 'Loss/localization_loss': 0.15452085,\n",
            " 'Loss/regularization_loss': 0.14836901,\n",
            " 'Loss/total_loss': 0.48845804,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Step 2600 per-step time 1.345s\n",
            "I1224 18:22:42.774811 140257418444800 model_lib_v2.py:705] Step 2600 per-step time 1.345s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22743036,\n",
            " 'Loss/localization_loss': 0.22936267,\n",
            " 'Loss/regularization_loss': 0.14794382,\n",
            " 'Loss/total_loss': 0.6047368,\n",
            " 'learning_rate': 0.07978972}\n",
            "I1224 18:22:42.776083 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.22743036,\n",
            " 'Loss/localization_loss': 0.22936267,\n",
            " 'Loss/regularization_loss': 0.14794382,\n",
            " 'Loss/total_loss': 0.6047368,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 1.342s\n",
            "I1224 18:24:56.915073 140257418444800 model_lib_v2.py:705] Step 2700 per-step time 1.342s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16545151,\n",
            " 'Loss/localization_loss': 0.14613493,\n",
            " 'Loss/regularization_loss': 0.14749093,\n",
            " 'Loss/total_loss': 0.45907736,\n",
            " 'learning_rate': 0.07976264}\n",
            "I1224 18:24:56.915563 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.16545151,\n",
            " 'Loss/localization_loss': 0.14613493,\n",
            " 'Loss/regularization_loss': 0.14749093,\n",
            " 'Loss/total_loss': 0.45907736,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Step 2800 per-step time 1.346s\n",
            "I1224 18:27:11.462659 140257418444800 model_lib_v2.py:705] Step 2800 per-step time 1.346s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.124187976,\n",
            " 'Loss/localization_loss': 0.11786998,\n",
            " 'Loss/regularization_loss': 0.14713499,\n",
            " 'Loss/total_loss': 0.38919294,\n",
            " 'learning_rate': 0.07973392}\n",
            "I1224 18:27:11.463034 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.124187976,\n",
            " 'Loss/localization_loss': 0.11786998,\n",
            " 'Loss/regularization_loss': 0.14713499,\n",
            " 'Loss/total_loss': 0.38919294,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 1.347s\n",
            "I1224 18:29:26.173401 140257418444800 model_lib_v2.py:705] Step 2900 per-step time 1.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1403332,\n",
            " 'Loss/localization_loss': 0.13537581,\n",
            " 'Loss/regularization_loss': 0.1467721,\n",
            " 'Loss/total_loss': 0.42248112,\n",
            " 'learning_rate': 0.07970358}\n",
            "I1224 18:29:26.173757 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.1403332,\n",
            " 'Loss/localization_loss': 0.13537581,\n",
            " 'Loss/regularization_loss': 0.1467721,\n",
            " 'Loss/total_loss': 0.42248112,\n",
            " 'learning_rate': 0.07970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 1.347s\n",
            "I1224 18:31:40.827756 140257418444800 model_lib_v2.py:705] Step 3000 per-step time 1.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17182675,\n",
            " 'Loss/localization_loss': 0.08476811,\n",
            " 'Loss/regularization_loss': 0.1463339,\n",
            " 'Loss/total_loss': 0.40292877,\n",
            " 'learning_rate': 0.0796716}\n",
            "I1224 18:31:40.828102 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.17182675,\n",
            " 'Loss/localization_loss': 0.08476811,\n",
            " 'Loss/regularization_loss': 0.1463339,\n",
            " 'Loss/total_loss': 0.40292877,\n",
            " 'learning_rate': 0.0796716}\n",
            "INFO:tensorflow:Step 3100 per-step time 1.354s\n",
            "I1224 18:33:56.261163 140257418444800 model_lib_v2.py:705] Step 3100 per-step time 1.354s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16236804,\n",
            " 'Loss/localization_loss': 0.15533996,\n",
            " 'Loss/regularization_loss': 0.14586443,\n",
            " 'Loss/total_loss': 0.46357244,\n",
            " 'learning_rate': 0.07963799}\n",
            "I1224 18:33:56.261530 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.16236804,\n",
            " 'Loss/localization_loss': 0.15533996,\n",
            " 'Loss/regularization_loss': 0.14586443,\n",
            " 'Loss/total_loss': 0.46357244,\n",
            " 'learning_rate': 0.07963799}\n",
            "INFO:tensorflow:Step 3200 per-step time 1.346s\n",
            "I1224 18:36:10.888946 140257418444800 model_lib_v2.py:705] Step 3200 per-step time 1.346s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1796873,\n",
            " 'Loss/localization_loss': 0.1336112,\n",
            " 'Loss/regularization_loss': 0.14542882,\n",
            " 'Loss/total_loss': 0.45872736,\n",
            " 'learning_rate': 0.07960275}\n",
            "I1224 18:36:10.889376 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.1796873,\n",
            " 'Loss/localization_loss': 0.1336112,\n",
            " 'Loss/regularization_loss': 0.14542882,\n",
            " 'Loss/total_loss': 0.45872736,\n",
            " 'learning_rate': 0.07960275}\n",
            "INFO:tensorflow:Step 3300 per-step time 1.350s\n",
            "I1224 18:38:25.881536 140257418444800 model_lib_v2.py:705] Step 3300 per-step time 1.350s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13661268,\n",
            " 'Loss/localization_loss': 0.107764855,\n",
            " 'Loss/regularization_loss': 0.14500219,\n",
            " 'Loss/total_loss': 0.38937974,\n",
            " 'learning_rate': 0.07956588}\n",
            "I1224 18:38:25.881878 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.13661268,\n",
            " 'Loss/localization_loss': 0.107764855,\n",
            " 'Loss/regularization_loss': 0.14500219,\n",
            " 'Loss/total_loss': 0.38937974,\n",
            " 'learning_rate': 0.07956588}\n",
            "INFO:tensorflow:Step 3400 per-step time 1.345s\n",
            "I1224 18:40:40.335372 140257418444800 model_lib_v2.py:705] Step 3400 per-step time 1.345s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13722393,\n",
            " 'Loss/localization_loss': 0.13211927,\n",
            " 'Loss/regularization_loss': 0.14456175,\n",
            " 'Loss/total_loss': 0.41390496,\n",
            " 'learning_rate': 0.079527386}\n",
            "I1224 18:40:40.335718 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.13722393,\n",
            " 'Loss/localization_loss': 0.13211927,\n",
            " 'Loss/regularization_loss': 0.14456175,\n",
            " 'Loss/total_loss': 0.41390496,\n",
            " 'learning_rate': 0.079527386}\n",
            "INFO:tensorflow:Step 3500 per-step time 1.339s\n",
            "I1224 18:42:54.213575 140257418444800 model_lib_v2.py:705] Step 3500 per-step time 1.339s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20132,\n",
            " 'Loss/localization_loss': 0.13812287,\n",
            " 'Loss/regularization_loss': 0.1441007,\n",
            " 'Loss/total_loss': 0.48354357,\n",
            " 'learning_rate': 0.07948727}\n",
            "I1224 18:42:54.213931 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.20132,\n",
            " 'Loss/localization_loss': 0.13812287,\n",
            " 'Loss/regularization_loss': 0.1441007,\n",
            " 'Loss/total_loss': 0.48354357,\n",
            " 'learning_rate': 0.07948727}\n",
            "INFO:tensorflow:Step 3600 per-step time 1.345s\n",
            "I1224 18:45:08.730561 140257418444800 model_lib_v2.py:705] Step 3600 per-step time 1.345s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19792585,\n",
            " 'Loss/localization_loss': 0.17107268,\n",
            " 'Loss/regularization_loss': 0.14382005,\n",
            " 'Loss/total_loss': 0.5128186,\n",
            " 'learning_rate': 0.079445526}\n",
            "I1224 18:45:08.730899 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.19792585,\n",
            " 'Loss/localization_loss': 0.17107268,\n",
            " 'Loss/regularization_loss': 0.14382005,\n",
            " 'Loss/total_loss': 0.5128186,\n",
            " 'learning_rate': 0.079445526}\n",
            "INFO:tensorflow:Step 3700 per-step time 1.348s\n",
            "I1224 18:47:23.498647 140257418444800 model_lib_v2.py:705] Step 3700 per-step time 1.348s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15334558,\n",
            " 'Loss/localization_loss': 0.09845585,\n",
            " 'Loss/regularization_loss': 0.14339782,\n",
            " 'Loss/total_loss': 0.39519924,\n",
            " 'learning_rate': 0.07940216}\n",
            "I1224 18:47:23.499048 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.15334558,\n",
            " 'Loss/localization_loss': 0.09845585,\n",
            " 'Loss/regularization_loss': 0.14339782,\n",
            " 'Loss/total_loss': 0.39519924,\n",
            " 'learning_rate': 0.07940216}\n",
            "INFO:tensorflow:Step 3800 per-step time 1.344s\n",
            "I1224 18:49:37.939656 140257418444800 model_lib_v2.py:705] Step 3800 per-step time 1.344s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18567,\n",
            " 'Loss/localization_loss': 0.10930373,\n",
            " 'Loss/regularization_loss': 0.14295228,\n",
            " 'Loss/total_loss': 0.437926,\n",
            " 'learning_rate': 0.079357184}\n",
            "I1224 18:49:37.940008 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.18567,\n",
            " 'Loss/localization_loss': 0.10930373,\n",
            " 'Loss/regularization_loss': 0.14295228,\n",
            " 'Loss/total_loss': 0.437926,\n",
            " 'learning_rate': 0.079357184}\n",
            "INFO:tensorflow:Step 3900 per-step time 1.348s\n",
            "I1224 18:51:52.772923 140257418444800 model_lib_v2.py:705] Step 3900 per-step time 1.348s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16554965,\n",
            " 'Loss/localization_loss': 0.12408143,\n",
            " 'Loss/regularization_loss': 0.14257212,\n",
            " 'Loss/total_loss': 0.43220317,\n",
            " 'learning_rate': 0.07931058}\n",
            "I1224 18:51:52.773256 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.16554965,\n",
            " 'Loss/localization_loss': 0.12408143,\n",
            " 'Loss/regularization_loss': 0.14257212,\n",
            " 'Loss/total_loss': 0.43220317,\n",
            " 'learning_rate': 0.07931058}\n",
            "INFO:tensorflow:Step 4000 per-step time 1.340s\n",
            "I1224 18:54:06.807989 140257418444800 model_lib_v2.py:705] Step 4000 per-step time 1.340s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15313222,\n",
            " 'Loss/localization_loss': 0.13270074,\n",
            " 'Loss/regularization_loss': 0.14211638,\n",
            " 'Loss/total_loss': 0.4279493,\n",
            " 'learning_rate': 0.07926236}\n",
            "I1224 18:54:06.808362 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.15313222,\n",
            " 'Loss/localization_loss': 0.13270074,\n",
            " 'Loss/regularization_loss': 0.14211638,\n",
            " 'Loss/total_loss': 0.4279493,\n",
            " 'learning_rate': 0.07926236}\n",
            "INFO:tensorflow:Step 4100 per-step time 1.345s\n",
            "I1224 18:56:21.337953 140257418444800 model_lib_v2.py:705] Step 4100 per-step time 1.345s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18900579,\n",
            " 'Loss/localization_loss': 0.19252944,\n",
            " 'Loss/regularization_loss': 0.14163576,\n",
            " 'Loss/total_loss': 0.523171,\n",
            " 'learning_rate': 0.07921253}\n",
            "I1224 18:56:21.338310 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.18900579,\n",
            " 'Loss/localization_loss': 0.19252944,\n",
            " 'Loss/regularization_loss': 0.14163576,\n",
            " 'Loss/total_loss': 0.523171,\n",
            " 'learning_rate': 0.07921253}\n",
            "INFO:tensorflow:Step 4200 per-step time 1.347s\n",
            "I1224 18:58:36.035542 140257418444800 model_lib_v2.py:705] Step 4200 per-step time 1.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14135328,\n",
            " 'Loss/localization_loss': 0.112761125,\n",
            " 'Loss/regularization_loss': 0.14120954,\n",
            " 'Loss/total_loss': 0.39532393,\n",
            " 'learning_rate': 0.07916109}\n",
            "I1224 18:58:36.035893 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.14135328,\n",
            " 'Loss/localization_loss': 0.112761125,\n",
            " 'Loss/regularization_loss': 0.14120954,\n",
            " 'Loss/total_loss': 0.39532393,\n",
            " 'learning_rate': 0.07916109}\n",
            "INFO:tensorflow:Step 4300 per-step time 1.336s\n",
            "I1224 19:00:49.641074 140257418444800 model_lib_v2.py:705] Step 4300 per-step time 1.336s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18792407,\n",
            " 'Loss/localization_loss': 0.13467039,\n",
            " 'Loss/regularization_loss': 0.14076194,\n",
            " 'Loss/total_loss': 0.4633564,\n",
            " 'learning_rate': 0.07910804}\n",
            "I1224 19:00:49.641485 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.18792407,\n",
            " 'Loss/localization_loss': 0.13467039,\n",
            " 'Loss/regularization_loss': 0.14076194,\n",
            " 'Loss/total_loss': 0.4633564,\n",
            " 'learning_rate': 0.07910804}\n",
            "INFO:tensorflow:Step 4400 per-step time 1.343s\n",
            "I1224 19:03:03.919528 140257418444800 model_lib_v2.py:705] Step 4400 per-step time 1.343s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19198383,\n",
            " 'Loss/localization_loss': 0.18535127,\n",
            " 'Loss/regularization_loss': 0.14033452,\n",
            " 'Loss/total_loss': 0.5176696,\n",
            " 'learning_rate': 0.07905338}\n",
            "I1224 19:03:03.919884 140257418444800 model_lib_v2.py:708] {'Loss/classification_loss': 0.19198383,\n",
            " 'Loss/localization_loss': 0.18535127,\n",
            " 'Loss/regularization_loss': 0.14033452,\n",
            " 'Loss/total_loss': 0.5176696,\n",
            " 'learning_rate': 0.07905338}\n"
          ]
        }
      ],
      "source": [
        "# Run training!\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to stop training early, just click Stop a couple times or right-click on the code block and select \"Interrupt Execution\". Otherwise, training will stop by itself once it reaches the specified number of training steps.\n"
      ],
      "metadata": {
        "id": "WHxbX4ZpzXIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --checkpoint_dir={model_dir}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke7EXbpoPXHA",
        "outputId": "707bfa23-5e1d-4e3c-b023-40809945dd91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1224 20:21:09.876762 20353550192640 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I1224 20:21:09.876990 20353550192640 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1224 20:21:09.877079 20353550192640 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I1224 20:21:09.877162 20353550192640 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1224 20:21:09.877277 20353550192640 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2024-12-24 20:21:10.593749: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/val.tfrecord']\n",
            "I1224 20:21:10.761078 20353550192640 dataset_builder.py:162] Reading unweighted datasets: ['/content/val.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/val.tfrecord']\n",
            "I1224 20:21:10.761347 20353550192640 dataset_builder.py:79] Reading record datasets for input file: ['/content/val.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1224 20:21:10.761453 20353550192640 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1224 20:21:10.761523 20353550192640 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1224 20:21:10.763612 20353550192640 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1224 20:21:10.787188 20353550192640 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1224 20:21:14.287397 20353550192640 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1224 20:21:15.136837 20353550192640 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/training/\n",
            "I1224 20:21:17.624392 20353550192640 checkpoint_utils.py:136] Waiting for new checkpoint at /content/training/\n",
            "INFO:tensorflow:Found new checkpoint at /content/training/ckpt-5\n",
            "I1224 20:21:17.625626 20353550192640 checkpoint_utils.py:145] Found new checkpoint at /content/training/ckpt-5\n",
            "/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "I1224 20:21:24.303839 20353550192640 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1224 20:21:38.357043 20353550192640 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "2024-12-24 20:21:42.903191: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1224 20:21:44.322247 20353550192640 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I1224 20:21:44.332522 20353550192640 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W1224 20:21:44.446818 20353550192640 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I1224 20:21:52.738005 20353550192640 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I1224 20:21:57.977620 20353550192640 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Performing evaluation on 256 images.\n",
            "I1224 20:22:02.035609 20353550192640 coco_evaluation.py:293] Performing evaluation on 256 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1224 20:22:02.038427 20353550192640 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I1224 20:22:02.055189 20353550192640 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.93s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.29s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.791\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.457\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.377\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
            "INFO:tensorflow:Eval metrics at step 4000\n",
            "I1224 20:22:03.303832 20353550192640 model_lib_v2.py:1015] Eval metrics at step 4000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.428383\n",
            "I1224 20:22:03.312288 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.428383\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.790562\n",
            "I1224 20:22:03.313723 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.790562\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.457477\n",
            "I1224 20:22:03.315024 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.457477\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.268693\n",
            "I1224 20:22:03.316197 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.268693\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.365411\n",
            "I1224 20:22:03.317406 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.365411\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.454753\n",
            "I1224 20:22:03.318609 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.454753\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.377381\n",
            "I1224 20:22:03.319799 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.377381\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.539011\n",
            "I1224 20:22:03.321000 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.539011\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.565147\n",
            "I1224 20:22:03.322197 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.565147\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.298889\n",
            "I1224 20:22:03.323420 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.298889\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.538151\n",
            "I1224 20:22:03.324599 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.538151\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.567511\n",
            "I1224 20:22:03.325839 20353550192640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.567511\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.248497\n",
            "I1224 20:22:03.326787 20353550192640 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.248497\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.350320\n",
            "I1224 20:22:03.327731 20353550192640 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.350320\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.142111\n",
            "I1224 20:22:03.328688 20353550192640 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.142111\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.740928\n",
            "I1224 20:22:03.329699 20353550192640 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.740928\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/training/\n",
            "I1224 20:26:17.725873 20353550192640 checkpoint_utils.py:136] Waiting for new checkpoint at /content/training/\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/model_main_tf2.py\", line 81, in main\n",
            "    model_lib_v2.eval_continuously(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py\", line 1135, in eval_continuously\n",
            "    for latest_checkpoint in tf.train.checkpoints_iterator(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 194, in checkpoints_iterator\n",
            "    new_checkpoint_path = wait_for_new_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 143, in wait_for_new_checkpoint\n",
            "    time.sleep(seconds_to_sleep)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 316, in run\n",
            "    if isinstance(exc, SystemExit) and not exc.code:\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --checkpoint_dir={model_dir}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STTnjuEWW51p",
        "outputId": "69545df5-95b1-412a-ebfd-fca8d3e63f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1224 20:31:38.480057 15338946584576 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I1224 20:31:38.480277 15338946584576 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1224 20:31:38.480415 15338946584576 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I1224 20:31:38.480499 15338946584576 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1224 20:31:38.480593 15338946584576 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2024-12-24 20:31:40.227512: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/val.tfrecord']\n",
            "I1224 20:31:40.409865 15338946584576 dataset_builder.py:162] Reading unweighted datasets: ['/content/val.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/val.tfrecord']\n",
            "I1224 20:31:40.410136 15338946584576 dataset_builder.py:79] Reading record datasets for input file: ['/content/val.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1224 20:31:40.410239 15338946584576 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1224 20:31:40.410341 15338946584576 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1224 20:31:40.412512 15338946584576 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1224 20:31:40.436449 15338946584576 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1224 20:31:43.934421 15338946584576 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1224 20:31:44.801056 15338946584576 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/training/\n",
            "I1224 20:31:47.921509 15338946584576 checkpoint_utils.py:136] Waiting for new checkpoint at /content/training/\n",
            "INFO:tensorflow:Found new checkpoint at /content/training/ckpt-5\n",
            "I1224 20:31:47.923065 15338946584576 checkpoint_utils.py:145] Found new checkpoint at /content/training/ckpt-5\n",
            "/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "I1224 20:31:53.772956 15338946584576 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1224 20:32:07.613387 15338946584576 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "2024-12-24 20:32:12.238133: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1224 20:32:13.495584 15338946584576 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I1224 20:32:13.511142 15338946584576 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W1224 20:32:13.697230 15338946584576 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I1224 20:32:21.874186 15338946584576 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I1224 20:32:27.655884 15338946584576 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Performing evaluation on 256 images.\n",
            "I1224 20:32:31.481836 15338946584576 coco_evaluation.py:293] Performing evaluation on 256 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1224 20:32:31.485398 15338946584576 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I1224 20:32:31.504770 15338946584576 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.69s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.29s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.791\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.457\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.377\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
            "INFO:tensorflow:Eval metrics at step 4000\n",
            "I1224 20:32:32.515283 15338946584576 model_lib_v2.py:1015] Eval metrics at step 4000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.428383\n",
            "I1224 20:32:32.521548 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.428383\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.790562\n",
            "I1224 20:32:32.522950 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.790562\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.457477\n",
            "I1224 20:32:32.524212 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.457477\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.268693\n",
            "I1224 20:32:32.525409 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.268693\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.365411\n",
            "I1224 20:32:32.526627 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.365411\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.454753\n",
            "I1224 20:32:32.527971 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.454753\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.377381\n",
            "I1224 20:32:32.529189 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.377381\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.539011\n",
            "I1224 20:32:32.530375 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.539011\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.565147\n",
            "I1224 20:32:32.531562 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.565147\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.298889\n",
            "I1224 20:32:32.532755 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.298889\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.538151\n",
            "I1224 20:32:32.533941 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.538151\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.567511\n",
            "I1224 20:32:32.535140 15338946584576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.567511\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.248497\n",
            "I1224 20:32:32.536089 15338946584576 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.248497\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.350320\n",
            "I1224 20:32:32.537059 15338946584576 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.350320\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.142111\n",
            "I1224 20:32:32.538018 15338946584576 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.142111\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.740928\n",
            "I1224 20:32:32.538978 15338946584576 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.740928\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/training/\n",
            "I1224 20:36:48.020407 15338946584576 checkpoint_utils.py:136] Waiting for new checkpoint at /content/training/\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/model_main_tf2.py\", line 81, in main\n",
            "    model_lib_v2.eval_continuously(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py\", line 1135, in eval_continuously\n",
            "    for latest_checkpoint in tf.train.checkpoints_iterator(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 194, in checkpoints_iterator\n",
            "    new_checkpoint_path = wait_for_new_checkpoint(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 143, in wait_for_new_checkpoint\n",
            "    time.sleep(seconds_to_sleep)\n",
            "KeyboardInterrupt\n",
            "Exception ignored in atexit callback: <function load_source.<locals>.<lambda> at 0xdf25d9b3d00>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/loader.py\", line 58, in <lambda>\n",
            "    atexit.register(lambda: _remove_file(file_name))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/loader.py\", line 35, in _remove_file\n",
            "    os.remove(file_name)\n",
            "KeyboardInterrupt: \n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path=/content/models/mymodel/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config \\\n",
        "    --model_dir=/content/models/mymodel/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8 \\\n",
        "    --checkpoint_dir=/content/models/mymodel/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint \\\n",
        "    --alsologtostderr \\\n",
        "    --eval_timeout=60\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2MnYLphdJm7",
        "outputId": "802bf4b9-c68c-4941-d9e8-8fe439d2097c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/models/research/object_detection/model_main_tf2.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.&nbsp;Convert Model to TensorFlow Lite"
      ],
      "metadata": {
        "id": "kPg8oMnQDYKl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spQXdq8Y63pj"
      },
      "source": [
        "Alright! Our model is all trained up and ready to be used for detecting objects. First, we need to export the model graph (a file that contains information about the architecture and weights) to a TensorFlow Lite-compatible format. We'll do this using the `export_tflite_graph_tf2.py` script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaUU8tBlHifd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b09fac-587d-4c64-c99e-5890522a3a92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/custom_model_lite’: File exists\n",
            "2024-12-24 19:35:58.348422: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I1224 19:36:02.747991 133598810677248 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1224 19:36:07.708127 133598810677248 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "2024-12-24 19:36:09.286826: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "I1224 19:36:10.063146 133598810677248 api.py:441] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x79817858e020>, because it is not built.\n",
            "W1224 19:36:11.661472 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x79817858e020>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x79817858eda0>, because it is not built.\n",
            "W1224 19:36:12.015704 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x79817858eda0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9fa65f0>, because it is not built.\n",
            "W1224 19:36:12.015965 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9fa65f0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9fa4340>, because it is not built.\n",
            "W1224 19:36:12.016211 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9fa4340>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x79815c167130>, because it is not built.\n",
            "W1224 19:36:12.016346 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x79815c167130>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9fb1b40>, because it is not built.\n",
            "W1224 19:36:12.016474 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9fb1b40>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9fb2980>, because it is not built.\n",
            "W1224 19:36:12.016575 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9fb2980>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7980e9fb15a0>, because it is not built.\n",
            "W1224 19:36:12.016663 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7980e9fb15a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9fb0eb0>, because it is not built.\n",
            "W1224 19:36:12.016756 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9fb0eb0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x79815c31c880>, because it is not built.\n",
            "W1224 19:36:12.016851 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x79815c31c880>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x79815c31f730>, because it is not built.\n",
            "W1224 19:36:12.016948 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x79815c31f730>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x79815c31d1e0>, because it is not built.\n",
            "W1224 19:36:12.017039 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x79815c31d1e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x79815c31f7c0>, because it is not built.\n",
            "W1224 19:36:12.017133 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x79815c31f7c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x79817858f370>, because it is not built.\n",
            "W1224 19:36:12.017232 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x79817858f370>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9e1d0c0>, because it is not built.\n",
            "W1224 19:36:12.017350 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9e1d0c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9e0b010>, because it is not built.\n",
            "W1224 19:36:12.017464 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9e0b010>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9e0b850>, because it is not built.\n",
            "W1224 19:36:12.017566 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9e0b850>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9e09b70>, because it is not built.\n",
            "W1224 19:36:12.017660 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9e09b70>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9e0bbe0>, because it is not built.\n",
            "W1224 19:36:12.017749 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9e0bbe0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9e0aad0>, because it is not built.\n",
            "W1224 19:36:12.017836 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9e0aad0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9e0a2f0>, because it is not built.\n",
            "W1224 19:36:12.017926 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9e0a2f0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x79817858f3a0>, because it is not built.\n",
            "W1224 19:36:12.018016 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x79817858f3a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9f0b550>, because it is not built.\n",
            "W1224 19:36:12.018103 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9f0b550>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x798138754f70>, because it is not built.\n",
            "W1224 19:36:12.018190 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x798138754f70>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x798138756b00>, because it is not built.\n",
            "W1224 19:36:12.018275 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x798138756b00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x798138755480>, because it is not built.\n",
            "W1224 19:36:12.018387 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x798138755480>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x798138757fa0>, because it is not built.\n",
            "W1224 19:36:12.018497 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x798138757fa0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x798138755f30>, because it is not built.\n",
            "W1224 19:36:12.018606 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x798138755f30>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x798138757f10>, because it is not built.\n",
            "W1224 19:36:12.018694 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x798138757f10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x79817858f3d0>, because it is not built.\n",
            "W1224 19:36:12.018780 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x79817858f3d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x798138757ca0>, because it is not built.\n",
            "W1224 19:36:12.018871 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x798138757ca0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9f7eb90>, because it is not built.\n",
            "W1224 19:36:12.018955 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9f7eb90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9f7f790>, because it is not built.\n",
            "W1224 19:36:12.019060 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9f7f790>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9f7d180>, because it is not built.\n",
            "W1224 19:36:12.019159 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9f7d180>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9f7d9f0>, because it is not built.\n",
            "W1224 19:36:12.019249 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9f7d9f0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9f7f820>, because it is not built.\n",
            "W1224 19:36:12.019352 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9f7f820>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9f7d900>, because it is not built.\n",
            "W1224 19:36:12.019472 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980e9f7d900>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9f7fa00>, because it is not built.\n",
            "W1224 19:36:12.019574 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980e9f7fa00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980ec0f1bd0>, because it is not built.\n",
            "W1224 19:36:12.019666 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980ec0f1bd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980ec0f1900>, because it is not built.\n",
            "W1224 19:36:12.019760 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980ec0f1900>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980ec0f0100>, because it is not built.\n",
            "W1224 19:36:12.019849 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980ec0f0100>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980ec0f2e60>, because it is not built.\n",
            "W1224 19:36:12.019935 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980ec0f2e60>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980ec0f0160>, because it is not built.\n",
            "W1224 19:36:12.020016 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980ec0f0160>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980ec0f1d80>, because it is not built.\n",
            "W1224 19:36:12.020101 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7980ec0f1d80>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980ec0f29e0>, because it is not built.\n",
            "W1224 19:36:12.040811 133598810677248 save_impl.py:71] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7980ec0f29e0>, because it is not built.\n",
            "W1224 19:36:29.818122 133598810677248 save.py:260] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 104). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/custom_model_lite/saved_model/assets\n",
            "I1224 19:36:34.639609 133598810677248 builder_impl.py:779] Assets written to: /content/custom_model_lite/saved_model/assets\n"
          ]
        }
      ],
      "source": [
        "# Make a directory to store the trained TFLite model\n",
        "!mkdir /content/custom_model_lite\n",
        "output_directory = '/content/custom_model_lite'\n",
        "\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = '/content/training'\n",
        "\n",
        "!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_NuapO2VROu"
      },
      "source": [
        "Next, we'll take the exported graph and use the `TFLiteConverter` module to convert it to `.tflite` FlatBuffer format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsE_uVjlsz3u"
      },
      "outputs": [],
      "source": [
        "# Convert exported graph file into TFLite model file\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/custom_model_lite/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('/content/custom_model_lite/detect.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.&nbsp;Test TensorFlow Lite Model and Calculate mAP"
      ],
      "metadata": {
        "id": "RDQrtQhvC3oG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtSmUZcxIAvt"
      },
      "source": [
        "We've trained our custom model and converted it to TFLite format. But how well does it actually perform at detecting objects in images? This is where the images we set aside in the **test** folder come in. The model never saw any test images during training, so its performance on these images should be representative of how it will perform on new images from the field.\n",
        "\n",
        "### 7.1 Inference test images\n",
        "The following code defines a function to run inference on test images. It loads the images, loads the model and labelmap, runs the model on each image, and displays the result. It also optionally saves detection results as text files so we can use them to calculate model mAP score.\n",
        "\n",
        "This code is based off the [TFLite_detection_image.py](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_image.py) script from my [TensorFlow Lite Object Detection repository on GitHub](https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi); feel free to use it as a starting point for your own application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4WtI8i5K96w"
      },
      "outputs": [],
      "source": [
        "# Script to run custom TFLite model on test images to detect objects\n",
        "# Source: https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_image.py\n",
        "\n",
        "# Import packages\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import importlib.util\n",
        "from tensorflow.lite.python.interpreter import Interpreter\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "### Define function for inferencing with TFLite model and displaying results\n",
        "\n",
        "def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath='/content/results', txt_only=False):\n",
        "\n",
        "  # Grab filenames of all images in test folder\n",
        "  images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n",
        "\n",
        "  # Load the label map into memory\n",
        "  with open(lblpath, 'r') as f:\n",
        "      labels = [line.strip() for line in f.readlines()]\n",
        "\n",
        "  # Load the Tensorflow Lite model into memory\n",
        "  interpreter = Interpreter(model_path=modelpath)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  # Get model details\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "  height = input_details[0]['shape'][1]\n",
        "  width = input_details[0]['shape'][2]\n",
        "\n",
        "  float_input = (input_details[0]['dtype'] == np.float32)\n",
        "\n",
        "  input_mean = 127.5\n",
        "  input_std = 127.5\n",
        "\n",
        "  # Randomly select test images\n",
        "  images_to_test = random.sample(images, num_test_images)\n",
        "\n",
        "  # Loop over every image and perform detection\n",
        "  for image_path in images_to_test:\n",
        "\n",
        "      # Load image and resize to expected shape [1xHxWx3]\n",
        "      image = cv2.imread(image_path)\n",
        "      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      imH, imW, _ = image.shape\n",
        "      image_resized = cv2.resize(image_rgb, (width, height))\n",
        "      input_data = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "      # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
        "      if float_input:\n",
        "          input_data = (np.float32(input_data) - input_mean) / input_std\n",
        "\n",
        "      # Perform the actual detection by running the model with the image as input\n",
        "      interpreter.set_tensor(input_details[0]['index'],input_data)\n",
        "      interpreter.invoke()\n",
        "\n",
        "      # Retrieve detection results\n",
        "      boxes = interpreter.get_tensor(output_details[1]['index'])[0] # Bounding box coordinates of detected objects\n",
        "      classes = interpreter.get_tensor(output_details[3]['index'])[0] # Class index of detected objects\n",
        "      scores = interpreter.get_tensor(output_details[0]['index'])[0] # Confidence of detected objects\n",
        "\n",
        "      detections = []\n",
        "\n",
        "      # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
        "      for i in range(len(scores)):\n",
        "          if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n",
        "\n",
        "              # Get bounding box coordinates and draw box\n",
        "              # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
        "              ymin = int(max(1,(boxes[i][0] * imH)))\n",
        "              xmin = int(max(1,(boxes[i][1] * imW)))\n",
        "              ymax = int(min(imH,(boxes[i][2] * imH)))\n",
        "              xmax = int(min(imW,(boxes[i][3] * imW)))\n",
        "\n",
        "              cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
        "\n",
        "              # Draw label\n",
        "              object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
        "              label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
        "              labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n",
        "              label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
        "              cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
        "              cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text\n",
        "\n",
        "              detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n",
        "\n",
        "\n",
        "      # All the results have been drawn on the image, now display the image\n",
        "      if txt_only == False: # \"text_only\" controls whether we want to display the image results or just save them in .txt files\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        plt.figure(figsize=(12,16))\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "\n",
        "      # Save detection results in .txt files (for calculating mAP)\n",
        "      elif txt_only == True:\n",
        "\n",
        "        # Get filenames and paths\n",
        "        image_fn = os.path.basename(image_path)\n",
        "        base_fn, ext = os.path.splitext(image_fn)\n",
        "        txt_result_fn = base_fn +'.txt'\n",
        "        txt_savepath = os.path.join(savepath, txt_result_fn)\n",
        "\n",
        "        # Write results to text file\n",
        "        # (Using format defined by https://github.com/Cartucho/mAP, which will make it easy to calculate mAP)\n",
        "        with open(txt_savepath,'w') as f:\n",
        "            for detection in detections:\n",
        "                f.write('%s %.4f %d %d %d %d\\n' % (detection[0], detection[1], detection[2], detection[3], detection[4], detection[5]))\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next block sets the paths to the test images and models and then runs the inferencing function. If you want to use more than 10 images, change the `images_to_test` variable. Click play to run inferencing!"
      ],
      "metadata": {
        "id": "-CJI4A0f_zqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Calculate mAP\n",
        "Now we have a visual sense of how our model performs on test images, but how can we quantitatively measure its accuracy?\n",
        "\n",
        "One popular methord for measuring object detection model accuracy is \"mean average precision\" (mAP). Basically, the higher the mAP score, the better your model is at detecting objects in images. To learn more about mAP, read through this [article from Roboflow](https://blog.roboflow.com/mean-average-precision/).\n",
        "\n",
        "We'll use the mAP calculator tool at https://github.com/Cartucho/mAP to determine our model's mAP score. First, we need to clone the repository and remove its existing example data. We'll also download a script I wrote for interfacing with the calculator."
      ],
      "metadata": {
        "id": "N_ckqeWqBF0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll copy the images and annotation data from the **test** folder to the appropriate folders inside the cloned repository. These will be used as the \"ground truth data\" that our model's detection results will be compared to.\n"
      ],
      "metadata": {
        "id": "qn22nGGqH5T6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The calculator tool expects annotation data in a format that's different from the Pascal VOC .xml file format we're using. Fortunately, it provides an easy script, `convert_gt_xml.py`, for converting to the expected .txt format.\n",
        "\n"
      ],
      "metadata": {
        "id": "u6aro817DGzx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, we've set up the ground truth data, but now we need actual detection results from our model. The detection results will be compared to the ground truth data to calculate the model's accuracy in mAP.\n",
        "\n",
        "The inference function we defined in Step 7.1 can be used to generate detection data for all the images in the **test** folder. We'll use it the same as before, except this time we'll tell it to save detection results into the `detection-results` folder.\n",
        "\n",
        "Click Play to run the following code block!"
      ],
      "metadata": {
        "id": "mnIUacAlLP0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's calculate mAP! One popular style for reporting mAP is the COCO metric for mAP @ 0.50:0.95. Basically, this means that mAP is calculated at several IoU thresholds between 0.50 and 0.95, and then the result from each threshold is averaged to get a final mAP score. [Learn more here!](https://blog.roboflow.com/mean-average-precision/)\n",
        "\n",
        "I wrote a script to run the calculator tool at each IoU threshold, average the results, and report the final accuracy score. It reports mAP for each class and overall mAP. Click Play on the following two blocks to calculate mAP!"
      ],
      "metadata": {
        "id": "e_QRnTqNPX4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score reported at the end is your model's overall mAP score. Ideally, it should be above 50% (0.50). If it isn't, you can increase your model's accuracy by adding more images to your dataset. See my [dataset video](https://www.youtube.com/watch?v=v0ssiOY6cfg) for tips on how to capture good training images and improve accuracy."
      ],
      "metadata": {
        "id": "R9HPoOBVKvxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.&nbsp;Deploy TensorFlow Lite Model"
      ],
      "metadata": {
        "id": "5i40ve0SCLaE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phT8vvzriqQp"
      },
      "source": [
        "Now that your custom model has been trained and converted to TFLite format, it's ready to be downloaded and deployed in an application! This section shows how to download the model and provides links to instructions for deploying it on the Raspberry Pi, your PC, or other edge devices."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1. Download TFLite model\n",
        "\n",
        "Run the two following cells to copy the labelmap files into the model folder, compress it into a zip folder, and then download it. The zip folder contains the `detect.tflite` model and `labelmap.txt` labelmap files that are needed to run the model in your application."
      ],
      "metadata": {
        "id": "zq3L2IoP4VHp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awZMQGVqMpVL"
      },
      "outputs": [],
      "source": [
        "# Move labelmap and pipeline config files into TFLite model folder and zip it up\n",
        "!cp /content/labelmap.txt /content/custom_model_lite\n",
        "!cp /content/labelmap.pbtxt /content/custom_model_lite\n",
        "!cp /content/models/mymodel/pipeline_file.config /content/custom_model_lite\n",
        "\n",
        "%cd /content\n",
        "!zip -r custom_model_lite.zip custom_model_lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVPfAGbNPV56"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/custom_model_lite.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `custom_model_lite.zip` file containing the model will download into your Downloads folder. It's ready to be deployed on your device!"
      ],
      "metadata": {
        "id": "9Kb3ZBsMq95l"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4VAvZo8qE4u5",
        "sxb8_h-QFErO",
        "eydREUsMGUUR",
        "eGEUZYAMEZ6f",
        "-19zML6oEO7l",
        "kPg8oMnQDYKl",
        "RDQrtQhvC3oG",
        "5i40ve0SCLaE",
        "WoptFnAhCSrR",
        "5VI_Gh5dCd7w"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}